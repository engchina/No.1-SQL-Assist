"""SelectAIé€£æºãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«.

ã“ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã¯ã€SelectAIã®Profileã‚’ç®¡ç†ã™ã‚‹UIã‚’æä¾›ã—ã¾ã™ã€‚
"""

import logging
import json
import re
import os
import asyncio
from datetime import datetime
from dotenv import find_dotenv, load_dotenv  # noqa: E402
from pathlib import Path
from time import time

import gradio as gr
import pandas as pd
import numpy as np
from sklearn.linear_model import LogisticRegression
import joblib
import oci
from oci.generative_ai_inference import GenerativeAiInferenceClient
from oci.generative_ai_inference.models import EmbedTextDetails

from utils.common_util import remove_comments

from utils.management_util import (
    get_table_list,
    get_view_list,
    get_table_details,
    get_view_details,
)

from utils.sql_learning_util import build_sql_learning_tab

logger = logging.getLogger(__name__)
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
)

# Load environment variables
load_dotenv(find_dotenv())

# Initialize OCI GenAI client for classifier training
_generative_ai_inference_client = None
_COMPARTMENT_ID = None

try:
    logger.info("Initializing OCI GenAI client for classifier...")
    
    # Get compartment ID from environment
    _COMPARTMENT_ID = os.getenv("OCI_COMPARTMENT_OCID")
    if not _COMPARTMENT_ID:
        logger.error("OCI_COMPARTMENT_OCID environment variable is not set")
        raise ValueError("OCI_COMPARTMENT_OCID is required")
    
    logger.info(f"Compartment ID: {_COMPARTMENT_ID[:20]}...")
    
    # Get OCI config
    CONFIG_PROFILE = os.getenv("OCI_CONFIG_PROFILE", "DEFAULT")
    oci_config_file = os.path.expanduser("~/.oci/config")
    
    if not os.path.exists(oci_config_file):
        logger.error(f"OCI config file not found: {oci_config_file}")
        raise FileNotFoundError(f"OCI config file not found: {oci_config_file}")
    
    logger.info(f"Loading OCI config from: {oci_config_file}, profile: {CONFIG_PROFILE}")
    config = oci.config.from_file(oci_config_file, CONFIG_PROFILE)
    
    # Get region from config or environment
    region = config.get("region")
    if not region:
        from utils.oci_util import get_region
        region = get_region()
    
    logger.info(f"Using region: {region}")
    
    # Construct endpoint
    endpoint = os.getenv(
        "OCI_GENAI_ENDPOINT",
        f"https://inference.generativeai.{region}.oci.oraclecloud.com"
    )
    logger.info(f"GenAI endpoint: {endpoint}")
    
    # Initialize client
    _generative_ai_inference_client = GenerativeAiInferenceClient(
        config=config,
        service_endpoint=endpoint,
        retry_strategy=oci.retry.NoneRetryStrategy(),
        timeout=(10, 240)
    )
    
    logger.info("OCI GenAI client initialized successfully")
    
except Exception as e:
    logger.error(f"Failed to initialize OCI GenAI client for classifier: {e}")
    logger.error("Please ensure the following:")
    logger.error("  1. OCI_COMPARTMENT_OCID environment variable is set")
    logger.error("  2. ~/.oci/config file exists with valid credentials")
    logger.error("  3. OCI credentials have proper permissions")
    import traceback
    logger.error(traceback.format_exc())
    _generative_ai_inference_client = None
    _COMPARTMENT_ID = None


_DEFAULT_FEW_SHOT_PROMPT = (
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
    "âš ï¸ CRITICAL INSTRUCTION (NOT PART OF QUESTION):\n"
    "\n"
    "The examples above demonstrate the EXACT patterns you MUST follow.\n"
    "MANDATORY REQUIREMENTS:\n"
    "- Study the example queries - they define the REQUIRED style and format\n"
    "- Follow the SAME patterns for similar questions\n"
    "- Adopt ALL functions shown in examples (even if unrecognized/new)\n"
    "- When questions are similar to examples, mirror the example's structure precisely\n"
    "\n"
    "Examples OVERRIDE all other instructions.\n"
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
    "\n"
    "â–¼ ACTUAL QUESTION:\n"
)

_TABLE_DF_CACHE = {"df": None, "ts": 0.0}
_VIEW_DF_CACHE = {"df": None, "ts": 0.0}

def _get_table_df_cached(pool, force: bool = False, ttl: int = 120) -> pd.DataFrame:
    try:
        now = time()
        if (not force) and _TABLE_DF_CACHE.get("df") is not None and now - float(_TABLE_DF_CACHE.get("ts", 0.0)) < ttl:
            return _TABLE_DF_CACHE["df"]
        df = get_table_list(pool)
        _TABLE_DF_CACHE["df"] = df
        _TABLE_DF_CACHE["ts"] = now
        return df
    except Exception as e:
        logger.error(f"_get_table_df_cached error: {e}")
        return pd.DataFrame(columns=["Table Name"])  

def _get_view_df_cached(pool, force: bool = False, ttl: int = 120) -> pd.DataFrame:
    try:
        now = time()
        if (not force) and _VIEW_DF_CACHE.get("df") is not None and now - float(_VIEW_DF_CACHE.get("ts", 0.0)) < ttl:
            return _VIEW_DF_CACHE["df"]
        df = get_view_list(pool)
        _VIEW_DF_CACHE["df"] = df
        _VIEW_DF_CACHE["ts"] = now
        return df
    except Exception as e:
        logger.error(f"_get_view_df_cached error: {e}")
        return pd.DataFrame(columns=["View Name"])  

def _get_table_names(pool):
    try:
        df = _get_table_df_cached(pool)
        if not df.empty and "Table Name" in df.columns:
            return df["Table Name"].tolist()
    except Exception as e:
        logger.error(f"_get_table_names error: {e}")
    return []


def _get_view_names(pool):
    try:
        df = _get_view_df_cached(pool)
        if not df.empty and "View Name" in df.columns:
            return df["View Name"].tolist()
    except Exception as e:
        logger.error(f"_get_view_names error: {e}")
    return []


def _profiles_dir() -> Path:
    d = Path("profiles")
    d.mkdir(parents=True, exist_ok=True)
    return d


def _sanitize_name(name: str) -> str:
    s = name.strip()
    s = re.sub(r"\s+", "_", s)
    s = re.sub(r"[^\w\-ã-ã‚“ã‚¡-ãƒ¶ä¸€-é¾¥ã€…ãƒ¼ï¼-ï¼™ï¼¡-ï¼ºï½-ï½š]", "", s)
    return s or f"profile_{datetime.now().strftime('%Y%m%d_%H%M%S')}"


def _profile_path(name: str) -> Path:
    return _profiles_dir() / f"{_sanitize_name(name)}.json"


def _save_profiles_to_json(pool):
    """ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±ã‚’selectai.jsonãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã™ã‚‹"""
    try:
        profiles_data = [
            {
                "profile": "",
                "business_domain": ""
            }
        ]
        with pool.acquire() as conn:
            with conn.cursor() as cursor:
                cursor.execute(
                    "SELECT PROFILE_NAME, DESCRIPTION FROM USER_CLOUD_AI_PROFILES ORDER BY PROFILE_NAME"
                )
                rows = cursor.fetchall() or []
                for r in rows:
                    try:
                        name = r[0]
                        if str(name).strip().upper() == "OCI_CRED$PROF":
                            continue
                        desc_val = r[1]
                        desc = desc_val.read() if hasattr(desc_val, "read") else str(desc_val or "")
                        profiles_data.append({
                            "profile": str(name),
                            "business_domain": str(desc)
                        })
                    except Exception as e:
                        logger.error(f"_save_profiles_to_json row error: {e}")
        
        # profiles/selectai.json ã«ä¿å­˜
        json_path = _profiles_dir() / "selectai.json"
        with json_path.open("w", encoding="utf-8") as f:
            json.dump(profiles_data, f, ensure_ascii=False, indent=2)
        logger.info(f"Saved {len(profiles_data)} profiles to {json_path}")
    except Exception as e:
        logger.error(f"_save_profiles_to_json error: {e}")


def _load_profiles_from_json():
    try:
        json_path = _profiles_dir() / "selectai.json"
        if not json_path.exists():
            return [("", "")]
        with json_path.open("r", encoding="utf-8") as f:
            profiles_data = json.load(f)
        result = []
        for p in profiles_data:
            bd = str(p.get("business_domain", "") or "").strip()
            pf = str(p.get("profile", "") or "").strip()
            result.append((bd, pf))
        if not result:
            return [("", "")]
        return result
    except Exception as e:
        logger.error(f"_load_profiles_from_json error: {e}")
        return [("", "")]

def _dev_profile_names():
    try:
        pairs = _load_profiles_from_json()
        return [(str(bd), str(pf)) for bd, pf in pairs]
    except Exception:
        return [("", "")]

def _profile_names():
    try:
        pairs = _load_profiles_from_json()
        return [(str(bd), str(pf)) for bd, pf in pairs]
    except Exception:
        return [("", "")]

def _predict_business_domain_label(text):
    try:
        mname = "business_domain"
        sp_root = Path("./models")
        model_path = sp_root / f"{mname}.joblib"
        meta_path = sp_root / f"{mname}.meta.json"
        if not model_path.exists() or not meta_path.exists():
            return ""
        with meta_path.open("r", encoding="utf-8") as f:
            meta = json.load(f)
        embed_model = (
            str(meta.get("embed_model", "cohere.embed-v4.0"))
            if isinstance(meta, dict)
            else "cohere.embed-v4.0"
        )
        classifier = joblib.load(model_path)
        embed_text_detail = EmbedTextDetails(
            compartment_id=_COMPARTMENT_ID,
            inputs=[str(text or "")],
            serving_mode=oci.generative_ai_inference.models.OnDemandServingMode(model_id=embed_model),
            truncate="END",
            input_type="CLASSIFICATION",
        )
        embed_text_response = _generative_ai_inference_client.embed_text(embed_text_detail)
        embedding = np.array(embed_text_response.data.embeddings[0])
        prediction = classifier.predict([embedding])
        return str(prediction[0]).strip().lower()
    except Exception:
        return ""

def _map_domain_to_profile(predicted_domain, choices):
    try:
        profile_json_path = Path("./profiles/selectai.json")
        if not predicted_domain or not profile_json_path.exists():
            return gr.Dropdown(choices=choices, value=choices[0][1])
        with profile_json_path.open("r", encoding="utf-8") as f:
            profiles = json.load(f)
        matched_profile = ""
        for item in profiles:
            bd_item = str(item.get("business_domain", "")).strip().lower()
            if bd_item == predicted_domain:
                matched_profile = str(item.get("profile", "")).strip()
                break
        if matched_profile:
            val_lower = matched_profile.strip().lower()
            exists = any(str(val).strip().lower() == val_lower for _, val in choices)
            if not exists:
                bd_display = ""
                for item in profiles:
                    if str(item.get("profile", "")).strip().lower() == val_lower:
                        bd_display = str(item.get("business_domain", "")).strip()
                        break
                choices.append((bd_display, matched_profile))
            return gr.Dropdown(choices=choices, value=matched_profile)
        return gr.Dropdown(choices=choices, value=choices[0][1])
    except Exception:
        return gr.Dropdown(choices=choices, value=choices[0][1])

def get_db_profiles(pool) -> pd.DataFrame:
    try:
        with pool.acquire() as conn:
            with conn.cursor() as cursor:
                cursor.execute(
                    "SELECT PROFILE_NAME, DESCRIPTION, STATUS FROM USER_CLOUD_AI_PROFILES ORDER BY PROFILE_NAME"
                )
                rows = cursor.fetchall() or []
                plain_rows = []
                for r in rows:
                    try:
                        name = r[0]
                        desc_val = r[1]
                        st = r[2]
                        desc = desc_val.read() if hasattr(desc_val, "read") else str(desc_val or "")
                        plain_rows.append([name, desc, st])
                    except Exception:
                        plain_rows.append([str(r[0]), str(r[1] or ""), str(r[2] or "")])
                if plain_rows:
                    df = pd.DataFrame(plain_rows, columns=["Profile Name", "Business Domain", "Status"]).sort_values("Profile Name")
                else:
                    df = pd.DataFrame(columns=["Profile Name", "Business Domain", "Status"]).sort_values("Profile Name")
                df = df[df["Profile Name"].astype(str).str.strip().str.upper() != "OCI_CRED$PROF"]

        table_names = set(_get_table_names(pool))
        view_names = set(_get_view_names(pool))
        # business_domain_col is already populated from DESCRIPTION
        tables_col = []
        views_col = []
        regions_col = []
        models_col = []
        for _, r in df.iterrows():
            name = str(r["Profile Name"]) if "Profile Name" in df.columns else str(r.iloc[0])
            attrs = _get_profile_attributes(pool, name) or {}
            obj_list = attrs.get("object_list") or []
            t_list = sorted([o.get("name") for o in obj_list if o.get("name") in table_names])
            v_list = sorted([o.get("name") for o in obj_list if o.get("name") in view_names])
            tables_col.append(", ".join(t_list))
            views_col.append(", ".join(v_list))
            regions_col.append(str(attrs.get("region") or ""))
            models_col.append(str(attrs.get("model") or ""))
        if len(df) > 0:
            df.insert(2, "Tables", tables_col)
            df.insert(3, "Views", views_col)
            df.insert(4, "Region", regions_col)
            df.insert(5, "Model", models_col)
        else:
            df = pd.DataFrame(columns=["Profile Name", "Business Domain", "Tables", "Views", "Region", "Model", "Status"])  
        return df
    except Exception as e:
        logger.error(f"get_db_profiles error: {e}")
        return pd.DataFrame(columns=["Profile Name", "Tables", "Views", "Region", "Model", "Status"]) 


def _get_profile_attributes(pool, name: str) -> dict:
    attrs = {}
    try:
        with pool.acquire() as conn:
            with conn.cursor() as cursor:
                cursor.execute(
                    "SELECT ATTRIBUTE_NAME, ATTRIBUTE_VALUE FROM USER_CLOUD_AI_PROFILE_ATTRIBUTES WHERE PROFILE_NAME = :name",
                    name=name,
                )
                rows = cursor.fetchall() or []
                for k, v in rows:
                    try:
                        s = v.read() if hasattr(v, "read") else str(v)
                    except Exception:
                        s = str(v)
                    try:
                        attrs[k.lower()] = json.loads(s)
                    except Exception:
                        attrs[k.lower()] = s
    except Exception as e:
        logger.error(f"_get_profile_attributes error: {e}")
    return attrs


def _resolve_profile_name(pool, display_name: str) -> str:
    try:
        df = get_db_profiles(pool)
        s = str(display_name or "").strip()
        if isinstance(df, pd.DataFrame) and not df.empty:
            if "Business Domain" in df.columns:
                m = df[df["Business Domain"].astype(str) == s]
                if len(m) > 0:
                    return str(m.iloc[0]["Profile Name"]) if "Profile Name" in m.columns else str(m.iloc[0][0])
            if "Profile Name" in df.columns:
                m2 = df[df["Profile Name"].astype(str) == s]
                if len(m2) > 0:
                    return s
        return s
    except Exception:
        return str(display_name or "")


def _generate_create_sql_from_attrs(name: str, attrs: dict, description: str = "") -> str:
    try:
        attr_str = json.dumps(attrs, ensure_ascii=False)
    except Exception as e:
        logger.error(f"_generate_create_sql_from_attrs serialize error: {e}")
        attr_str = "{}"
    desc_str = str(description or "").replace("'", "''")
    sql = (
        f"BEGIN DBMS_CLOUD_AI.DROP_PROFILE(profile_name => '{name}'); EXCEPTION WHEN OTHERS THEN NULL; END;\n"
        f"BEGIN DBMS_CLOUD_AI.CREATE_PROFILE(profile_name => '{name}', attributes => '{attr_str}', description => '{desc_str}'); END;"
    )
    return sql


def delete_profile(name: str) -> None:
    try:
        p = _profile_path(name)
        if p.exists():
            p.unlink()
    except Exception as e:
        logger.error(f"delete_profile error: {e}")


def build_selectai_profile(pool, name, tables, views):
    profile = {
        "profile_name": name or f"profile_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
        "generated_at": datetime.now().isoformat(timespec="seconds"),
        "tables": [],
        "views": [],
    }

    for t in tables or []:
        try:
            col_df, ddl = get_table_details(pool, t)
            cols = []
            if not col_df.empty:
                for _, row in col_df.iterrows():
                    cols.append({
                        "name": row.get("Column Name"),
                        "type": row.get("Data Type"),
                        "nullable": row.get("Nullable"),
                        "comments": row.get("Comments"),
                    })
            profile["tables"].append({
                "name": t,
                "columns": cols,
                "ddl": ddl,
            })
        except Exception as e:
            logger.warning(f"Failed to load table {t}: {e}")

    for v in views or []:
        try:
            col_df, ddl = get_view_details(pool, v)
            cols = []
            if not col_df.empty:
                for _, row in col_df.iterrows():
                    cols.append({
                        "name": row.get("Column Name"),
                        "type": row.get("Data Type"),
                        "nullable": row.get("Nullable"),
                        "comments": row.get("Comments"),
                    })
            profile["views"].append({
                "name": v,
                "columns": cols,
                "ddl": ddl,
            })
        except Exception as e:
            logger.warning(f"Failed to load view {v}: {e}")

    return json.dumps(profile, ensure_ascii=False, indent=2)


def create_db_profile(
    pool,
    name: str,
    compartment_id: str,
    region: str,
    model: str,
    embedding_model: str,
    max_tokens: int,
    enforce_object_list: bool,
    comments: bool,
    annotations: bool,
    tables: list,
    views: list,
    business_domain: str,
):
    attrs = {
        "provider": "oci",
        "credential_name": "OCI_CRED",
        "oci_compartment_id": compartment_id,
        "region": region,
        "model": model,
        "embedding_model": embedding_model,
        "max_tokens": int(max_tokens) if max_tokens is not None else 1024,
        "enforce_object_list": enforce_object_list,
        "comments": "true" if comments else "false",
        "annotations": "true" if annotations else "false",
        "temperature": 0.0,
        "object_list": [],
    }

    # gpt-* ãƒ¢ãƒ‡ãƒ«ã®å ´åˆã¯ provider ã¨ credential_name ã‚’å¤‰æ›´
    if str(model).startswith("gpt-"):
        if "provider" in attrs:
            del attrs["provider"]
        # attrs["provider"] = "openai"
        env_path = find_dotenv()
        load_dotenv(env_path, override=True)
        base_url = os.getenv("OPENAI_BASE_URL", "")
        
        # provider_endpoint ã®æ•´å½¢: ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã¨ /v1 ã‚µãƒ•ã‚£ãƒƒã‚¯ã‚¹ã‚’é™¤å»
        endpoint = base_url.replace("https://", "").replace("http://", "")
        if endpoint.endswith("/v1"):
            endpoint = endpoint[:-3]
        if endpoint.endswith("/"):
            endpoint = endpoint[:-1]
            
        if ":" in endpoint:
             endpoint = endpoint.split(":")[0]

        attrs["provider_endpoint"] = endpoint
        attrs["credential_name"] = "OPENAI_CRED"
        # openai provider usually doesn't need region/compartment in attributes 
        # but keeping them might not hurt or might be ignored.
        # However, for safety and cleaner config:
        if "oci_compartment_id" in attrs:
            del attrs["oci_compartment_id"]
        if "region" in attrs:
            del attrs["region"]

    for t in tables or []:
        attrs["object_list"].append({"owner": "ADMIN", "name": t})
    for v in views or []:
        attrs["object_list"].append({"owner": "ADMIN", "name": v})

    attr_str = json.dumps(attrs, ensure_ascii=False)
    
    if "provider_endpoint" in attrs:
        logger.info(f"provider_endpoint: {attrs['provider_endpoint']}")

    with pool.acquire() as conn:
        with conn.cursor() as cursor:
            try:
                cursor.execute(
                    "BEGIN DBMS_CLOUD_AI.DROP_PROFILE(profile_name => :name); EXCEPTION WHEN OTHERS THEN NULL; END;",
                    name=name,
                )
            except Exception as e:
                logger.warning(f"DROP_PROFILE failed: {e}")
            cursor.execute(
                "BEGIN DBMS_CLOUD_AI.CREATE_PROFILE(profile_name => :name, attributes => :attrs, description => :desc); END;",
                name=name,
                attrs=attr_str,
                desc=str(business_domain or ""),
            )
            logger.info(f"Created profile: {name}")


def _predict_domain_and_set_profile(text):
    try:
        ch = _load_profiles_from_json() or [("", "")]
        def _predict_business_domain(text_input: str):
            mname = "business_domain"
            sp_root = Path("./models")
            model_path = sp_root / f"{mname}.joblib"
            meta_path = sp_root / f"{mname}.meta.json"
            if not model_path.exists() or not meta_path.exists():
                return ""
            with meta_path.open("r", encoding="utf-8") as f:
                meta = json.load(f)
            embed_model = (
                str(meta.get("embed_model", "cohere.embed-v4.0"))
                if isinstance(meta, dict)
                else "cohere.embed-v4.0"
            )
            classifier = joblib.load(model_path)
            embed_text_detail = EmbedTextDetails(
                compartment_id=_COMPARTMENT_ID,
                inputs=[str(text_input or "")],
                serving_mode=oci.generative_ai_inference.models.OnDemandServingMode(model_id=embed_model),
                truncate="END",
                input_type="CLASSIFICATION",
            )
            embed_text_response = _generative_ai_inference_client.embed_text(embed_text_detail)
            embedding = np.array(embed_text_response.data.embeddings[0])
            prediction = classifier.predict([embedding])
            return str(prediction[0]).strip().lower()

        def _map_domain_to_profile(predicted_domain: str, choices):
            profile_json_path = Path("./profiles/selectai.json")
            if not predicted_domain or not profile_json_path.exists():
                return gr.Dropdown(choices=choices, value=choices[0][1])
            with profile_json_path.open("r", encoding="utf-8") as f:
                profiles = json.load(f)
            matched_profile = ""
            for item in profiles:
                bd_item = str(item.get("business_domain", "")).strip().lower()
                if bd_item == predicted_domain:
                    matched_profile = str(item.get("profile", "")).strip()
                    break
            if matched_profile:
                val_lower = matched_profile.strip().lower()
                exists = any(str(val).strip().lower() == val_lower for _, val in choices)
                if not exists:
                    bd_display = ""
                    for item in profiles:
                        if str(item.get("profile", "")).strip().lower() == val_lower:
                            bd_display = str(item.get("business_domain", "")).strip()
                            break
                    choices.append((bd_display, matched_profile))
                return gr.Dropdown(choices=choices, value=matched_profile)
            return gr.Dropdown(choices=choices, value=choices[0][1])

        pdomain = _predict_business_domain(text)
        return _map_domain_to_profile(pdomain, ch)
    except Exception:
        ch = _load_profiles_from_json() or [("", "")]
        return gr.Dropdown(choices=ch, value=ch[0][1])

def build_selectai_tab(pool):
    with gr.Tabs():
        with gr.TabItem(label="é–‹ç™ºè€…æ©Ÿèƒ½"):
            with gr.Tabs():
                with gr.TabItem(label="ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ç®¡ç†"):
                    with gr.Accordion(label="1. ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§", open=True):
                        profile_refresh_btn = gr.Button("ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’å–å¾—", variant="primary")
                        profile_refresh_status = gr.Markdown(visible=False)
                        profile_list_df = gr.Dataframe(
                            label="ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§(è¡Œã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦è©³ç´°ã‚’è¡¨ç¤º)",
                            interactive=False,
                            wrap=True,
                            value=pd.DataFrame(columns=["Profile Name", "Business Domain", "Tables", "Views", "Region", "Model", "Status"]),
                            headers=["Profile Name", "Business Domain", "Tables", "Views", "Region", "Model", "Status"],
                            visible=False,
                            elem_id="profile_list_df",
                        )
                        profile_list_style = gr.HTML(visible=False)

                    with gr.Accordion(label="2. ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«è©³ç´°ãƒ»å¤‰æ›´", open=True):
                        with gr.Row():
                            with gr.Column(scale=5):
                                with gr.Row():
                                    with gr.Column(scale=1):
                                        gr.Markdown("é¸æŠã•ã‚ŒãŸProfileå", elem_classes="input-label")
                                    with gr.Column(scale=5):
                                        selected_profile_name = gr.Textbox(show_label=False, interactive=True, container=False)
                            with gr.Column(scale=5):
                                with gr.Row():
                                    with gr.Column(scale=1):
                                        gr.Markdown("æ¥­å‹™ãƒ‰ãƒ¡ã‚¤ãƒ³å", elem_classes="input-label")
                                    with gr.Column(scale=5):
                                        business_domain_text = gr.Textbox(show_label=False, value="", interactive=True, container=False)
                        with gr.Row():
                            with gr.Column(scale=1):
                                gr.Markdown("Profile ä½œæˆSQL", elem_classes="input-label")
                            with gr.Column(scale=9):
                                profile_json_text = gr.Textbox(
                                    show_label=False,
                                    lines=5,
                                    max_lines=10,
                                    show_copy_button=True,
                                    container=False,
                                )
                        selected_profile_original_name = gr.State("")
                        with gr.Row():
                            profile_update_btn = gr.Button("å¤‰æ›´ã‚’ä¿å­˜", variant="primary")
                            profile_delete_btn = gr.Button("é¸æŠã—ãŸProfileã‚’å‰Šé™¤", variant="stop")
                        with gr.Row():
                            profile_action_status = gr.Markdown(visible=False)

                    with gr.Accordion(label="3. ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ", open=True):
                        with gr.Row():
                            with gr.Column(scale=5):
                                with gr.Row():
                                    with gr.Column(scale=1):
                                        gr.Markdown("Profileå", elem_classes="input-label")
                                    with gr.Column(scale=5):
                                        profile_name = gr.Textbox(
                                            show_label=False,
                                            value=f"profile_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                                            container=False,
                                        )
                            with gr.Column(scale=5):
                                with gr.Row():
                                    with gr.Column(scale=1):
                                        gr.Markdown("æ¥­å‹™ãƒ‰ãƒ¡ã‚¤ãƒ³å", elem_classes="input-label")
                                    with gr.Column(scale=5):
                                        business_domain_input = gr.Textbox(show_label=False, placeholder="ä¾‹: é¡§å®¢ç®¡ç†ã€å£²ä¸Šåˆ†æ ç­‰", container=False)

                        with gr.Row():
                            refresh_btn = gr.Button("ãƒ†ãƒ¼ãƒ–ãƒ«ãƒ»ãƒ“ãƒ¥ãƒ¼ä¸€è¦§ã‚’å–å¾—", variant="primary")
                        with gr.Row():
                            refresh_status = gr.Markdown(visible=False)

                        with gr.Row():
                            with gr.Column():
                                gr.Markdown("###### ãƒ†ãƒ¼ãƒ–ãƒ«é¸æŠ")
                                tables_input = gr.CheckboxGroup(label="ãƒ†ãƒ¼ãƒ–ãƒ«é¸æŠ", show_label=False, choices=[], visible=False)
                            with gr.Column():
                                gr.Markdown("###### ãƒ“ãƒ¥ãƒ¼é¸æŠ")
                                views_input = gr.CheckboxGroup(label="ãƒ“ãƒ¥ãƒ¼é¸æŠ", show_label=False, choices=[], visible=False)

                        with gr.Row():
                            with gr.Column(scale=1):
                                gr.Markdown("OCI Compartment OCID", elem_classes="input-label")
                            with gr.Column(scale=9):
                                compartment_id_input = gr.Textbox(show_label=False, placeholder="ocid1.compartment.oc1...", value=os.environ.get("OCI_COMPARTMENT_OCID", ""), container=False)

                        with gr.Row():
                            with gr.Column(scale=5):
                                with gr.Row():
                                    with gr.Column(scale=1):
                                        gr.Markdown("Region", elem_classes="input-label")
                                    with gr.Column(scale=5):
                                        region_input = gr.Dropdown(
                                            show_label=False,
                                            choices=["ap-osaka-1", "us-chicago-1"],
                                            value="us-chicago-1",
                                            interactive=True,
                                            container=False,
                                        )
                            with gr.Column(scale=5):
                                with gr.Row():
                                    with gr.Column(scale=1):
                                        gr.Markdown("")

                        with gr.Row():
                            with gr.Column(scale=5):
                                with gr.Row():
                                    with gr.Column(scale=1):
                                        gr.Markdown("Model", elem_classes="input-label")
                                    with gr.Column(scale=5):
                                        model_input = gr.Dropdown(
                                            show_label=False,
                                            choices=[
                                                "xai.grok-code-fast-1",
                                                "xai.grok-3",
                                                "xai.grok-3-fast",
                                                "xai.grok-4",
                                                "xai.grok-4-fast-non-reasoning",
                                                "meta.llama-4-scout-17b-16e-instruct",
                                                "gpt-4o",
                                                "gpt-5.1",
                                            ],
                                            value="xai.grok-code-fast-1",
                                            interactive=True,
                                            container=False,
                                        )
                            with gr.Column(scale=5):
                                with gr.Row():
                                    with gr.Column(scale=1):
                                        gr.Markdown("Max Tokens", elem_classes="input-label")
                                    with gr.Column(scale=5):
                                        max_tokens_input = gr.Slider(
                                            show_label=False,
                                            minimum=1024,
                                            maximum=16384,
                                            step=1024,
                                            value=4096,
                                            interactive=True,
                                            container=False,
                                        )

                        with gr.Row():
                            with gr.Column(scale=5):
                                with gr.Row():
                                    with gr.Column(scale=1):
                                        gr.Markdown("Embedding_Model", elem_classes="input-label")
                                    with gr.Column(scale=5):
                                        embedding_model_input = gr.Dropdown(
                                            show_label=False,
                                            choices=[
                                                "cohere.embed-v4.0",
                                                "text-embedding-ada-002",
                                                "text-embedding-3-large",
                                            ],
                                            value="cohere.embed-v4.0",
                                            interactive=True,
                                            container=False,
                                        )
                            with gr.Column(scale=5):
                                with gr.Row():
                                    with gr.Column(scale=1):
                                        gr.Markdown("")

                        with gr.Row():
                            with gr.Column(scale=5):
                                with gr.Row():
                                    with gr.Column(scale=1):
                                        gr.Markdown("Enforce_Object_List", elem_classes="input-label")
                                    with gr.Column(scale=5):
                                        enforce_object_list_input = gr.Dropdown(
                                            show_label=False,
                                            choices=["true", "false"],
                                            value="true",
                                            interactive=True,
                                            container=False,
                                        )
                            with gr.Column(scale=5):
                                with gr.Row():
                                    with gr.Column(scale=1):
                                        gr.Markdown("")

                        with gr.Row():
                            with gr.Column(scale=5):
                                with gr.Row():
                                    with gr.Column(scale=1):
                                        gr.Markdown("Comments", elem_classes="input-label")
                                    with gr.Column(scale=5):
                                        comments_input = gr.Dropdown(
                                            show_label=False,
                                            choices=["true", "false"],
                                            value="true",
                                            interactive=True,
                                            container=False,
                                        )
                            with gr.Column(scale=5):
                                with gr.Row():
                                    with gr.Column(scale=1):
                                        gr.Markdown("")

                        with gr.Row():
                            with gr.Column(scale=5):
                                with gr.Row():
                                    with gr.Column(scale=1):
                                        gr.Markdown("Annotations", elem_classes="input-label")
                                    with gr.Column(scale=5):
                                        annotations_input = gr.Dropdown(
                                            show_label=False,
                                            choices=["true", "false"],
                                            value="true",
                                            interactive=True,
                                            container=False,
                                        )
                            with gr.Column(scale=5):
                                with gr.Row():
                                    with gr.Column(scale=1):
                                        gr.Markdown("")

                        with gr.Row():
                            build_btn = gr.Button("ä½œæˆ", variant="primary")

                        with gr.Row():
                            create_info = gr.Markdown(visible=False)               

                def refresh_profiles():
                    try:
                        yield gr.Markdown(value="â³ ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’å–å¾—ä¸­...", visible=True), gr.Dataframe(visible=False, value=pd.DataFrame(columns=["Profile Name", "Business Domain", "Tables", "Views", "Region", "Model", "Status"])), gr.HTML(visible=False)
                        df = get_db_profiles(pool)
                        _save_profiles_to_json(pool)
                        if df is None or df.empty:
                            empty_df = pd.DataFrame(columns=["Profile Name", "Business Domain", "Tables", "Views", "Region", "Model", "Status"])
                            count = 0
                            label_text = f"ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§(è¡Œã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦è©³ç´°ã‚’è¡¨ç¤º) - {count}ä»¶"
                            yield gr.Markdown(value="âœ… å–å¾—å®Œäº†ï¼ˆ0ä»¶ï¼‰", visible=True), gr.Dataframe(value=empty_df, visible=True, label=label_text), gr.HTML(visible=False)
                            return
                        sample = df.head(5)
                        widths = []
                        for col in sample.columns:
                            series = sample[col].astype(str)
                            row_max = series.map(len).max() if len(series) > 0 else 0
                            length = max(len(str(col)), row_max)
                            widths.append(length)
                        total = sum(widths) if widths else 0
                        style_value = ""
                        if total > 0:
                            col_widths = [max(5, int(100 * w / total)) for w in widths]
                            diff = 100 - sum(col_widths)
                            if diff != 0 and len(col_widths) > 0:
                                col_widths[0] = max(5, col_widths[0] + diff)
                            rules = []
                            rules.append("#profile_list_df { width: 100% !important; }")
                            rules.append("#profile_list_df .wrap { overflow-x: auto !important; }")
                            rules.append("#profile_list_df table { table-layout: fixed !important; width: 100% !important; border-collapse: collapse !important; }")
                            for idx, pct in enumerate(col_widths, start=1):
                                rules.append(f"#profile_list_df table th:nth-child({idx}), #profile_list_df table td:nth-child({idx}) {{ width: {pct}% !important; overflow: hidden !important; text-overflow: ellipsis !important; }}")
                            style_value = "<style>" + "\n".join(rules) + "</style>"
                        count = len(df)
                        label_text = f"ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§(è¡Œã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦è©³ç´°ã‚’è¡¨ç¤º) - {count}ä»¶"
                        yield gr.Markdown(visible=True, value=f"âœ… å–å¾—å®Œäº†ï¼ˆ{count}ä»¶ï¼‰"), gr.Dataframe(value=df, visible=True, label=label_text), gr.HTML(visible=bool(style_value), value=style_value)
                    except Exception as e:
                        logger.error(f"refresh_profiles error: {e}")
                        yield gr.Markdown(value=f"âŒ å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}", visible=True), gr.Dataframe(visible=False, value=pd.DataFrame(columns=["Profile Name", "Business Domain", "Tables", "Views", "Region", "Model", "Status"])), gr.HTML(visible=False)
                
                def on_profile_select(evt: gr.SelectData, current_df, compartment_id):
                    try:
                        if isinstance(current_df, dict):
                            try:
                                current_df = pd.DataFrame.from_dict(current_df, orient='tight')
                            except Exception:
                                current_df = pd.DataFrame(current_df)
                        row_index = evt.index[0] if isinstance(evt.index, (list, tuple)) else evt.index
                        if len(current_df) > row_index:
                            name = str(current_df.iloc[row_index, 0])
                            attrs = _get_profile_attributes(pool, name) or {}
                            if compartment_id:
                                attrs.setdefault("oci_compartment_id", compartment_id)
                            desc = ""
                            try:
                                with pool.acquire() as conn2:
                                    with conn2.cursor() as cursor2:
                                        cursor2.execute("SELECT DESCRIPTION FROM USER_CLOUD_AI_PROFILES WHERE PROFILE_NAME = :name", name=name)
                                        r2 = cursor2.fetchone()
                                        if r2:
                                            v = r2[0]
                                            desc = v.read() if hasattr(v, "read") else str(v)
                            except Exception:
                                desc = ""
                            sql = _generate_create_sql_from_attrs(name, attrs, desc)
                            bdn = str(desc or "")
                            return name, bdn, sql, name
                    except Exception as e:
                        logger.error(f"on_profile_select error: {e}")
                        return "", "", f"âŒ èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}", ""
                    return "", "", "", ""

                def delete_selected_profile(name):
                    try:
                        # DBå´ã‚‚å‰Šé™¤
                        with pool.acquire() as conn:
                            with conn.cursor() as cursor:
                                cursor.execute("BEGIN DBMS_CLOUD_AI.DROP_PROFILE(profile_name => :name); END;", name=name)
                        # JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›´æ–°
                        _save_profiles_to_json(pool)
                        return gr.Markdown(visible=True, value=f"ğŸ—‘ï¸ å‰Šé™¤ã—ã¾ã—ãŸ: {name}"), "", "", ""
                    except Exception as e:
                        logger.error(f"delete_selected_profile error: {e}")
                        return gr.Markdown(visible=True, value=f"âŒ å‰Šé™¤ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}"), name, "", ""

                def update_selected_profile(original_name, edited_name, business_domain):
                    try:
                        orig = str(original_name or "").strip()
                        new = str(edited_name or "").strip()
                        bd = str(business_domain or "").strip()
                        if not orig:
                            attrs = {}
                            sql = _generate_create_sql_from_attrs(new or orig, attrs, bd)
                            return gr.Markdown(visible=True, value="âš ï¸ Profileã‚’é¸æŠã—ã¦ãã ã•ã„"), edited_name, gr.Textbox(value=bd), sql, (new or orig or "")
                        if not new:
                            new = orig
                        if not bd:
                            attrs = _get_profile_attributes(pool, orig) or {}
                            sql = _generate_create_sql_from_attrs(orig, attrs, "")
                            return gr.Markdown(visible=True, value="âš ï¸ æ¥­å‹™ãƒ‰ãƒ¡ã‚¤ãƒ³åã‚’å…¥åŠ›ã—ã¦ãã ã•ã„"), new, gr.Textbox(value=bd), sql, orig
                        attrs = _get_profile_attributes(pool, orig) or {}
                        attr_str = json.dumps(attrs, ensure_ascii=False)
                        with pool.acquire() as conn:
                            with conn.cursor() as cursor:
                                try:
                                    cursor.execute("BEGIN DBMS_CLOUD_AI.DROP_PROFILE(profile_name => :name); EXCEPTION WHEN OTHERS THEN NULL; END;", name=new)
                                except Exception as e:
                                    logger.error(f"_am_generate sanitize error: {e}")
                                cursor.execute("BEGIN DBMS_CLOUD_AI.CREATE_PROFILE(profile_name => :name, attributes => :attrs, description => :desc); END;", name=new, attrs=attr_str, desc=bd)
                                if new != orig:
                                    cursor.execute("BEGIN DBMS_CLOUD_AI.DROP_PROFILE(profile_name => :name); END;", name=orig)
                        # JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›´æ–°
                        _save_profiles_to_json(pool)
                        sql = _generate_create_sql_from_attrs(new, attrs, bd)
                        return gr.Markdown(visible=True, value=f"âœ… æ›´æ–°ã—ã¾ã—ãŸ: {new}"), new, gr.Textbox(value=bd), sql, new
                    except Exception as e:
                        logger.error(f"update_selected_profile error: {e}")
                        attrs = _get_profile_attributes(pool, orig or edited_name) or {}
                        sql = _generate_create_sql_from_attrs(new or orig, attrs, bd)
                        return gr.Markdown(visible=True, value=f"âŒ å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}"), edited_name, gr.Textbox(value=bd), sql, (new or orig or "")

                def refresh_sources():
                    return gr.CheckboxGroup(choices=_get_table_names(pool), visible=True), gr.CheckboxGroup(choices=_get_view_names(pool), visible=True)

                def build_profile(name, tables, views, compartment_id, region, model, embedding_model, max_tokens, enforce_object_list, comments, annotations, business_domain):
                    if not tables and not views:
                        yield gr.Markdown(visible=True, value="âš ï¸ ãƒ†ãƒ¼ãƒ–ãƒ«ã¾ãŸã¯ãƒ“ãƒ¥ãƒ¼ã‚’é¸æŠã—ã¦ãã ã•ã„")
                        return
                    bd = str(business_domain or "").strip()
                    if not bd:
                        yield gr.Markdown(visible=True, value="âš ï¸ æ¥­å‹™ãƒ‰ãƒ¡ã‚¤ãƒ³åã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
                        return
                    try:
                        yield gr.Markdown(visible=True, value="â³ ä½œæˆä¸­...")
                        bool_map = {"true": True, "false": False}
                        eol = bool_map.get(str(enforce_object_list).lower(), True)
                        com = bool_map.get(str(comments).lower(), True)
                        ann = bool_map.get(str(annotations).lower(), True)
                        create_db_profile(
                            pool,
                            name,
                            compartment_id,
                            region,
                            model,
                            embedding_model,
                            int(max_tokens) if max_tokens is not None else 1024,
                            eol,
                            com,
                            ann,
                            tables or [],
                            views or [],
                            str(business_domain or ""),
                        )
                        attrs = _get_profile_attributes(pool, name) or {}
                        desc = str(bd)
                        # JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›´æ–°
                        _save_profiles_to_json(pool)
                        sql = _generate_create_sql_from_attrs(name, attrs, desc)
                        yield gr.Markdown(visible=True, value=f"âœ… ä½œæˆã—ã¾ã—ãŸ: {name}")
                    except Exception as e:
                        msg = f"âŒ ä½œæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}"
                        # gpt-* ãƒ¢ãƒ‡ãƒ«ã§ provider_endpoint ãŒåŸå› ã®ã‚¨ãƒ©ãƒ¼ã®å ´åˆã€å€¤ã‚’è¡¨ç¤º
                        if str(model).startswith("gpt-") and "provider_endpoint" in str(e):
                            env_path = find_dotenv()
                            load_dotenv(env_path, override=True)
                            base_url = os.getenv("OPENAI_BASE_URL", "")
                            
                            endpoint = base_url.replace("https://", "").replace("http://", "")
                            if endpoint.endswith("/v1"):
                                endpoint = endpoint[:-3]
                            if endpoint.endswith("/"):
                                endpoint = endpoint[:-1]
                            msg += f"\n\nprovider_endpoint: {endpoint}"
                        
                        yield gr.Markdown(visible=True, value=msg)

                profile_refresh_btn.click(
                    fn=refresh_profiles,
                    outputs=[profile_refresh_status, profile_list_df, profile_list_style],
                )

                profile_list_df.select(
                    fn=on_profile_select,
                    inputs=[profile_list_df, compartment_id_input],
                    outputs=[selected_profile_name, business_domain_text, profile_json_text, selected_profile_original_name],
                )

                def _delete_profile_handler(name):
                    try:
                        yield gr.Markdown(visible=True, value="â³ å‰Šé™¤ä¸­..."), name, gr.Textbox(value=""), gr.Textbox(value="")
                        md, sel_name, bd_text, json_text = delete_selected_profile(name)
                        yield md, sel_name, bd_text, json_text
                    except Exception as e:
                        yield gr.Markdown(visible=True, value=f"âŒ å¤±æ•—: {e}"), name, gr.Textbox(value=""), gr.Textbox(value="")

                def _update_profile_handler(original_name, edited_name, business_domain):
                    try:
                        yield gr.Markdown(visible=True, value="â³ æ›´æ–°ä¸­..."), edited_name, gr.Textbox(value=business_domain), gr.Textbox(value=""), original_name
                        md, sel_name, bd_text, sql_text, orig_out = update_selected_profile(original_name, edited_name, business_domain)
                        yield md, sel_name, bd_text, sql_text, orig_out
                    except Exception as e:
                        yield gr.Markdown(visible=True, value=f"âŒ å¤±æ•—: {e}"), edited_name, gr.Textbox(value=business_domain), gr.Textbox(value=""), original_name

                profile_delete_btn.click(
                    fn=_delete_profile_handler,
                    inputs=[selected_profile_name],
                    outputs=[profile_action_status, selected_profile_name, business_domain_text, profile_json_text],
                ).then(
                    fn=lambda: gr.Dataframe(value=get_db_profiles(pool)),
                    outputs=[profile_list_df],
                )

                profile_update_btn.click(
                    fn=_update_profile_handler,
                    inputs=[selected_profile_original_name, selected_profile_name, business_domain_text],
                    outputs=[profile_action_status, selected_profile_name, business_domain_text, profile_json_text, selected_profile_original_name],
                ).then(
                    fn=lambda: gr.Dataframe(value=get_db_profiles(pool)),
                    outputs=[profile_list_df],
                )

                def refresh_sources_handler():
                    try:
                        yield gr.Markdown(visible=True, value="â³ ãƒ†ãƒ¼ãƒ–ãƒ«ãƒ»ãƒ“ãƒ¥ãƒ¼ä¸€è¦§ã‚’å–å¾—ä¸­..."), gr.CheckboxGroup(visible=False, choices=[]), gr.CheckboxGroup(visible=False, choices=[])
                        t = _get_table_names(pool)
                        v = _get_view_names(pool)
                        yield gr.Markdown(visible=True, value="âœ… å–å¾—å®Œäº†"), gr.CheckboxGroup(choices=t, visible=True), gr.CheckboxGroup(choices=v, visible=True)
                    except Exception as e:
                        logger.error(f"refresh_sources_handler error: {e}")
                        yield gr.Markdown(visible=True, value=f"âŒ å¤±æ•—: {e}"), gr.CheckboxGroup(choices=[]), gr.CheckboxGroup(choices=[])

                refresh_btn.click(
                    fn=refresh_sources_handler,
                    outputs=[refresh_status, tables_input, views_input],
                )

                build_btn.click(
                    fn=build_profile,
                    inputs=[
                        profile_name,
                        tables_input,
                        views_input,
                        compartment_id_input,
                        region_input,
                        model_input,
                        embedding_model_input,
                        max_tokens_input,
                        enforce_object_list_input,
                        comments_input,
                        annotations_input,
                        business_domain_input,
                    ],
                    outputs=[create_info],
                ).then(
                    fn=lambda: gr.Dataframe(value=get_db_profiles(pool)),
                    outputs=[profile_list_df],
                )

                def _profile_names():
                    try:
                        df = get_db_profiles(pool)
                        if isinstance(df, pd.DataFrame) and not df.empty:
                            return [str(x) for x in df["Profile Name"].tolist()]
                    except Exception as e:
                        logger.error(f"_profile_names error: {e}")
                    return []

                def _td_list():
                    try:
                        p = Path("uploads") / "training_data.xlsx"
                        if not p.exists():
                            return pd.DataFrame(columns=["BUSINESS_DOMAIN","TEXT"])
                        df = pd.read_excel(str(p))
                        cols_map = {str(c).upper(): c for c in df.columns.tolist()}
                        bd_col = cols_map.get("BUSINESS_DOMAIN")
                        tx_col = cols_map.get("TEXT")
                        if not bd_col or not tx_col:
                            return pd.DataFrame(columns=["BUSINESS_DOMAIN","TEXT"])
                        out = pd.DataFrame({"BUSINESS_DOMAIN": df[bd_col].astype(str), "TEXT": df[tx_col].astype(str)})
                        return out
                    except Exception as e:
                        logger.error(f"è¨“ç·´ãƒ‡ãƒ¼ã‚¿ä¸€è¦§ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
                        return pd.DataFrame(columns=["BUSINESS_DOMAIN","TEXT"])

                def _td_refresh():
                    try:
                        yield gr.Markdown(visible=True, value="â³ è¨“ç·´ãƒ‡ãƒ¼ã‚¿ä¸€è¦§ã‚’å–å¾—ä¸­..."), gr.Dataframe(visible=False, value=pd.DataFrame())
                        df = _td_list()
                        if df is None or df.empty:
                            count = 0
                            label_text = f"è¨“ç·´ãƒ‡ãƒ¼ã‚¿ä¸€è¦§ - {count}ä»¶"
                            yield gr.Markdown(visible=True, value="âœ… å–å¾—å®Œäº†ï¼ˆ0ä»¶ï¼‰"), gr.Dataframe(visible=True, value=pd.DataFrame(columns=["BUSINESS_DOMAIN","TEXT"]), label=label_text)
                            return
                        try:
                            df_disp = df.copy()
                            df_disp["TEXT"] = df_disp["TEXT"].astype(str).map(lambda s: s if len(s) <= 200 else (s[:200] + " ..."))
                        except Exception as e:
                            logger.error(f"build training data preview failed: {e}")
                            df_disp = df
                        count = len(df_disp)
                        label_text = f"è¨“ç·´ãƒ‡ãƒ¼ã‚¿ä¸€è¦§ - {count}ä»¶"
                        yield gr.Markdown(visible=True, value=f"âœ… å–å¾—å®Œäº†ï¼ˆ{count}ä»¶ï¼‰"), gr.Dataframe(visible=True, value=df_disp, label=label_text)
                    except Exception as e:
                        yield gr.Markdown(visible=True, value=f"âŒ å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}"), gr.Dataframe(visible=False, value=pd.DataFrame())

                def _td_train(embed_model):
                    """å‚ç…§ã‚³ãƒ¼ãƒ‰(No.1-Classifier)ã«åŸºã¥ã„ãŸåˆ†é¡å™¨è¨“ç·´é–¢æ•°"""
                    try:
                        # å›ºå®šã®ãƒ¢ãƒ‡ãƒ«åã‚’ä½¿ç”¨
                        model_name = "business_domain"
                        iterations = 1000  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
                        
                        logger.info("="*50)
                        logger.info("Starting classifier training...")
                        logger.info(f"Embed model: {embed_model}")
                        logger.info(f"Model name: {model_name}")
                        logger.info(f"Iterations: {iterations}")
                        
                        # OCI GenAI ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®ç¢ºèª
                        if not _generative_ai_inference_client or not _COMPARTMENT_ID:
                            error_msg = "OCI GenAI ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ç’°å¢ƒå¤‰æ•°ã‚’ç¢ºèªã—ã¦ãã ã•ã„"
                            logger.error(error_msg)
                            logger.error(f"Client initialized: {_generative_ai_inference_client is not None}")
                            logger.error(f"Compartment ID set: {_COMPARTMENT_ID is not None}")
                            yield gr.Markdown(visible=True, value=f"âŒ {error_msg}")
                            return
                        
                        logger.info("OCI GenAI client check passed")
                        yield gr.Markdown(visible=True, value="â³ å­¦ç¿’é–‹å§‹")
                        
                        # è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
                        p = Path("uploads") / "training_data.xlsx"
                        logger.info(f"Loading training data from: {p}")
                        
                        if not p.exists():
                            error_msg = "è¨“ç·´ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“"
                            logger.error(f"{error_msg}: {p}")
                            yield gr.Markdown(visible=True, value=f"âš ï¸ {error_msg}")
                            return
                        
                        logger.info("Reading Excel file...")
                        df = pd.read_excel(str(p))
                        logger.info(f"Excel file loaded, shape: {df.shape}")
                        
                        cols_map = {str(c).upper(): c for c in df.columns.tolist()}
                        logger.info(f"Columns found: {list(cols_map.keys())}")
                        
                        bd_col = cols_map.get("BUSINESS_DOMAIN")
                        tx_col = cols_map.get("TEXT")
                        
                        if not bd_col or not tx_col:
                            error_msg = "å¿…é ˆåˆ—(BUSINESS_DOMAIN, TEXT)ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"
                            logger.error(error_msg)
                            logger.error(f"Available columns: {list(cols_map.keys())}")
                            yield gr.Markdown(visible=True, value=f"âš ï¸ {error_msg}")
                            return
                        
                        logger.info(f"Using columns - BUSINESS_DOMAIN: {bd_col}, TEXT: {tx_col}")
                        
                        texts = []
                        labels = []
                        for idx, r in df.iterrows():
                            s_txt = str(r.get(tx_col, "") or "")
                            s_bd = str(r.get(bd_col, "") or "")
                            if s_txt:
                                texts.append(s_txt)
                                labels.append(s_bd)
                        
                        if not texts or not labels:
                            error_msg = "è¨“ç·´ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“"
                            logger.error(error_msg)
                            yield gr.Markdown(visible=True, value=f"âš ï¸ {error_msg}")
                            return
                        
                        unique_labels = list(set(labels))
                        logger.info(f"Training data loaded: {len(texts)} samples, {len(unique_labels)} unique labels")
                        logger.info(f"Labels: {unique_labels}")
                        
                        yield gr.Markdown(visible=True, value=f"â³ è¨“ç·´ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†: {len(texts)}ä»¶")
                        
                        # ãƒ¢ãƒ‡ãƒ«ä¿å­˜ãƒ‘ã‚¹ã®æº–å‚™
                        sp_root = Path("./models")
                        sp_root.mkdir(parents=True, exist_ok=True)
                        mname = str(model_name or f"model_{datetime.now().strftime('%Y%m%d_%H%M%S')}").strip()
                        model_path = sp_root / f"{mname}.joblib"
                        
                        logger.info(f"Model will be saved to: {model_path}")
                        
                        # è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚’JSONLå½¢å¼ã§ä¿å­˜
                        td_path = sp_root / f"{mname}_training_data.jsonl"
                        logger.info(f"Saving training data to: {td_path}")
                        with td_path.open("w", encoding="utf-8") as f:
                            for txt, lab in zip(texts, labels):
                                f.write(json.dumps({"text": txt, "label": lab}, ensure_ascii=False) + "\n")
                        logger.info("Training data saved")
                        
                        yield gr.Markdown(visible=True, value="â³ åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã‚’å–å¾—ä¸­...")
                        
                        # åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã®å–å¾—(å‚ç…§ã‚³ãƒ¼ãƒ‰ã«åŸºã¥ã)
                        logger.info("Creating embedding request...")
                        logger.info(f"Using compartment ID: {_COMPARTMENT_ID[:20]}...")
                        logger.info(f"Using model: {embed_model or 'cohere.embed-v4.0'}")
                        logger.info(f"Number of texts to embed: {len(texts)}")
                        
                        embed_text_detail = EmbedTextDetails(
                            compartment_id=_COMPARTMENT_ID,
                            inputs=texts,
                            serving_mode=oci.generative_ai_inference.models.OnDemandServingMode(
                                model_id=str(embed_model or "cohere.embed-v4.0")
                            ),
                            truncate="END",
                            input_type="CLASSIFICATION"
                        )
                        
                        logger.info("Sending embedding request to OCI GenAI...")
                        embed_text_response = _generative_ai_inference_client.embed_text(embed_text_detail)
                        logger.info("Embedding response received")
                        
                        embeddings = np.array(embed_text_response.data.embeddings)
                        logger.info(f"Embeddings shape: {embeddings.shape}")
                        
                        yield gr.Markdown(visible=True, value=f"â³ åŸ‹ã‚è¾¼ã¿å–å¾—å®Œäº†: {embeddings.shape}")
                        
                        # å­¦ç¿’å›æ•°ã®å‡¦ç†
                        try:
                            iters = int(iterations or 1)
                        except Exception:
                            iters = 1
                        
                        logger.info(f"Training iterations: {iters}")
                        
                        # LogisticRegressionã«ã‚ˆã‚‹è¨“ç·´(å‚ç…§ã‚³ãƒ¼ãƒ‰ã«åŸºã¥ã)
                        max_iter = max(1000, iters * 100)
                        logger.info(f"Training LogisticRegression classifier with max_iter={max_iter}")
                        yield gr.Markdown(visible=True, value=f"â³ åˆ†é¡å™¨ã‚’è¨“ç·´ä¸­(max_iter={max_iter})...")
                        
                        classifier = LogisticRegression(max_iter=max_iter)
                        classifier.fit(embeddings, labels)
                        
                        logger.info("Classifier training completed")
                        logger.info(f"Classifier classes: {classifier.classes_}")
                        
                        # ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜
                        logger.info(f"Saving model to: {model_path}")
                        joblib.dump(classifier, model_path)
                        logger.info("Model saved successfully")
                        
                        # ãƒ¡ã‚¿æƒ…å ±ã®ä¿å­˜
                        meta_path = sp_root / f"{mname}.meta.json"
                        logger.info(f"Saving metadata to: {meta_path}")
                        meta_info = {
                            "model_name": mname,
                            "labels": sorted(list(set(labels))),
                            "samples": len(texts),
                            "embed_model": str(embed_model or "cohere.embed-v4.0"),
                            "iterations": iters,
                            "created_at": datetime.now().isoformat(timespec="seconds"),
                            "algorithm": "LogisticRegression"
                        }
                        with meta_path.open("w", encoding="utf-8") as f:
                            json.dump(meta_info, f, ensure_ascii=False, indent=2)
                        logger.info("Metadata saved")
                        
                        # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®æ›´æ–°
                        index_path = sp_root / "models.index.json"
                        logger.info(f"Updating model index: {index_path}")
                        try:
                            idx = []
                            if index_path.exists():
                                with index_path.open("r", encoding="utf-8") as f:
                                    idx = json.load(f) or []
                            idx = [x for x in idx if str(x.get("model_name")) != mname]
                            idx.append({
                                "model_name": mname,
                                "labels": sorted(list(set(labels))),
                                "samples": len(texts),
                                "created_at": datetime.now().isoformat(timespec="seconds")
                            })
                            with index_path.open("w", encoding="utf-8") as f:
                                json.dump(idx, f, ensure_ascii=False, indent=2)
                            logger.info("Model index updated")
                        except Exception as e:
                            logger.error(f"ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ›´æ–°ã‚¨ãƒ©ãƒ¼: {e}")
                        
                        success_msg = f"âœ… å­¦ç¿’å®Œäº†: ãƒ¢ãƒ‡ãƒ« '{mname}' ã‚’ä¿å­˜ã—ã¾ã—ãŸ({len(texts)}ä»¶ã€ãƒ©ãƒ™ãƒ«: {', '.join(sorted(list(set(labels))))})"
                        logger.info(success_msg)
                        logger.info("="*50)
                        yield gr.Markdown(visible=True, value=success_msg)
                        
                    except Exception as e:
                        error_msg = f"å­¦ç¿’ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}"
                        logger.error(error_msg)
                        import traceback
                        logger.error(traceback.format_exc())
                        logger.info("="*50)
                        yield gr.Markdown(visible=True, value=f"âŒ {error_msg}")

                # ãƒ©ãƒ™ãƒ«å€™è£œã®æ›´æ–°ã¯å‰Šé™¤

                def _list_models():
                    try:
                        sp_root = Path("./models")
                        out = []
                        if sp_root.exists():
                            # .joblibãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ¢ãƒ‡ãƒ«åã‚’å–å¾—
                            for p in sp_root.glob("*.joblib"):
                                model_name = p.stem
                                out.append(model_name)
                        return sorted(out)
                    except Exception as e:
                        logger.error(f"_list_models error: {e}")
                        return []

                async def _mt_test_async(text, trained_model_name):
                    """å‚ç…§ã‚³ãƒ¼ãƒ‰(No.1-Classifier)ã«åŸºã¥ã„ãŸäºˆæ¸¬é–¢æ•°"""
                    try:
                        # å›ºå®šã®ãƒ¢ãƒ‡ãƒ«åã‚’ä½¿ç”¨
                        trained_model_name = "business_domain"
                                        
                        logger.info("="*50)
                        logger.info("Starting model prediction...")
                        logger.info(f"Model name: {trained_model_name}")
                        logger.info(f"Input text length: {len(str(text or ''))}")
                        
                        # OCI GenAI ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®ç¢ºèª
                        if not _generative_ai_inference_client or not _COMPARTMENT_ID:
                            error_msg = "OCI GenAI ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ç’°å¢ƒå¤‰æ•°ã‚’ç¢ºèªã—ã¦ãã ã•ã„"
                            logger.error(error_msg)
                            return gr.Markdown(visible=True, value=f"âŒ {error_msg}"), gr.Textbox(value="")
                        
                        logger.info("OCI GenAI client check passed")
                        
                        sp_root = Path("./models")
                        mname = str(trained_model_name or "").strip()
                        if not mname:
                            logger.warning("ãƒ¢ãƒ‡ãƒ«ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“")
                            return gr.Markdown(visible=True, value="âš ï¸ ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„"), gr.Textbox(value="")
                        
                        logger.info(f"Using model: {mname}")
                        
                        model_path = sp_root / f"{mname}.joblib"
                        meta_path = sp_root / f"{mname}.meta.json"
                        
                        logger.info(f"Model path: {model_path}")
                        logger.info(f"Meta path: {meta_path}")
                        
                        if not model_path.exists() or not meta_path.exists():
                            error_msg = f"ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ (model: {model_path.exists()}, meta: {meta_path.exists()})"
                            logger.error(error_msg)
                            return gr.Markdown(visible=True, value="â„¹ï¸ ãƒ¢ãƒ‡ãƒ«ãŒæœªå­¦ç¿’ã§ã™ã€‚ã¾ãšã€å­¦ç¿’ã‚’å®Ÿè¡Œã€ã—ã¦ãã ã•ã„"), gr.Textbox(value="")
                        
                        # ãƒ¡ã‚¿æƒ…å ±ã‚’èª­ã¿è¾¼ã¿
                        logger.info("Loading model metadata...")
                        with meta_path.open("r", encoding="utf-8") as f:
                            meta = json.load(f)
                        
                        embed_model = str(meta.get("embed_model", "cohere.embed-v4.0"))
                        logger.info(f"Embed model: {embed_model}")
                        logger.info(f"Model labels: {meta.get('labels', [])}")
                        
                        # ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿
                        logger.info("Loading classifier model...")
                        classifier = joblib.load(model_path)
                        logger.info(f"Classifier loaded, classes: {classifier.classes_}")
                        
                        # ãƒ†ã‚­ã‚¹ãƒˆã®åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã‚’å–å¾—(å‚ç…§ã‚³ãƒ¼ãƒ‰ã«åŸºã¥ã)
                        logger.info("Creating embedding request for input text...")
                        embed_text_detail = EmbedTextDetails(
                            compartment_id=_COMPARTMENT_ID,
                            inputs=[str(text or "")],
                            serving_mode=oci.generative_ai_inference.models.OnDemandServingMode(
                                model_id=embed_model
                            ),
                            truncate="END",
                            input_type="CLASSIFICATION"
                        )
                        
                        logger.info("Sending embedding request to OCI GenAI...")
                        embed_text_response = _generative_ai_inference_client.embed_text(embed_text_detail)
                        logger.info("Embedding response received")
                        
                        embedding = np.array(embed_text_response.data.embeddings[0])
                        logger.info(f"Embedding shape: {embedding.shape}")
                        
                        # äºˆæ¸¬ã‚’å®Ÿè¡Œ(å‚ç…§ã‚³ãƒ¼ãƒ‰ã«åŸºã¥ã)
                        logger.info("Making prediction...")
                        prediction = classifier.predict([embedding])
                        probabilities = classifier.predict_proba([embedding])
                        
                        # çµæœã‚’æ•´å½¢
                        pred = prediction[0]
                        probs = dict(zip(classifier.classes_, probabilities[0].round(3).tolist()))
                        
                        logger.info(f"Prediction: {pred}")
                        logger.info(f"Probabilities: {probs}")
                        
                        lines = [
                            f"prediction: {pred}",
                            "probabilities: " + json.dumps({k: round(v, 3) for k, v in probs.items()}, ensure_ascii=False),
                        ]
                        
                        logger.info("Prediction completed successfully")
                        logger.info("="*50)
                        return gr.Markdown(visible=True, value="\n".join(lines)), gr.Textbox(value=pred)
                        
                    except Exception as e:
                        error_msg = f"ãƒ†ã‚¹ãƒˆã«å¤±æ•—ã—ã¾ã—ãŸ: {e}"
                        logger.error(error_msg)
                        import traceback
                        logger.error(traceback.format_exc())
                        logger.info("="*50)
                        return gr.Markdown(visible=True, value=f"âŒ {error_msg}"), gr.Textbox(value="")

                def _mt_test(text):
                    import asyncio
                    loop = asyncio.new_event_loop()
                    asyncio.set_event_loop(loop)
                    try:
                        # å›ºå®šã®ãƒ¢ãƒ‡ãƒ«åã‚’æ¸¡ã™
                        return loop.run_until_complete(_mt_test_async(text, "business_domain"))
                    finally:
                        loop.close()

                # è¨“ç·´ãƒ‡ãƒ¼ã‚¿è¡Œé¸æŠã®ç·¨é›†æ©Ÿèƒ½ã¯å‰Šé™¤
                def _td_download_excel():
                    try:
                        p = Path("uploads") / "training_data.xlsx"
                        if p.exists():
                            return gr.DownloadButton(value=str(p), visible=True)
                        df = pd.DataFrame(columns=["BUSINESS_DOMAIN","TEXT"])
                        tmp = Path("/tmp") / f"training_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx"
                        with pd.ExcelWriter(tmp) as writer:
                            df.to_excel(writer, sheet_name="training_data", index=False)
                        return gr.DownloadButton(value=str(tmp), visible=True)
                    except Exception:
                        return gr.DownloadButton(visible=False)

                # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã¯å›ºå®šãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’ä½¿ç”¨

                def _td_upload_excel(file_path):
                    try:
                        if not file_path:
                            return gr.Textbox(visible=True, value="ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„")
                        try:
                            df = pd.read_excel(str(file_path))
                        except Exception:
                            return gr.Textbox(visible=True, value="Excelèª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ")
                        cols_map = {str(c).upper(): c for c in df.columns.tolist()}
                        required = {"BUSINESS_DOMAIN","TEXT"}
                        if not required.issubset(set(cols_map.keys())):
                            return gr.Textbox(visible=True, value="åˆ—åã¯ BUSINESS_DOMAIN, TEXT ãŒå¿…è¦ã§ã™")
                        out_df = pd.DataFrame({
                            "BUSINESS_DOMAIN": df[cols_map["BUSINESS_DOMAIN"]],
                            "TEXT": df[cols_map["TEXT"]],
                        })
                        up_dir = Path("uploads")
                        up_dir.mkdir(parents=True, exist_ok=True)
                        dest = up_dir / "training_data.xlsx"
                        if dest.exists():
                            dest.unlink()
                        with pd.ExcelWriter(dest) as writer:
                            out_df.to_excel(writer, sheet_name="training_data", index=False)
                        return gr.Textbox(visible=True, value=f"âœ… ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å®Œäº†: {len(out_df)} ä»¶")
                    except Exception as e:
                        logger.error(f"Excelã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
                        return gr.Textbox(visible=True, value=f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")

                # å‰Šé™¤: ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ã®ã‚¯ãƒªãƒƒã‚¯å‡¦ç†ã¯ä¸è¦ï¼ˆç›´æ¥ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æä¾›ï¼‰
                # ç›´æ¥å›ºå®šãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆã‚¯ãƒªãƒƒã‚¯å‡¦ç†ä¸è¦ï¼‰
                def _delete_model(trained_model_name):
                    try:
                        sp_root = Path("./models")
                        mname = str(trained_model_name or "").strip()
                        if not mname:
                            return gr.Dropdown(choices=_list_models())
                        
                        # .joblibãƒ•ã‚¡ã‚¤ãƒ«ã¨é–¢é€£ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
                        model_path = sp_root / f"{mname}.joblib"
                        meta_path = sp_root / f"{mname}.meta.json"
                        td_path = sp_root / f"{mname}_training_data.jsonl"
                        
                        if model_path.exists():
                            model_path.unlink(missing_ok=True)
                        if meta_path.exists():
                            meta_path.unlink(missing_ok=True)
                        if td_path.exists():
                            td_path.unlink(missing_ok=True)
                        
                        # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‹ã‚‰å‰Šé™¤
                        index_path = sp_root / "models.index.json"
                        try:
                            if index_path.exists():
                                with index_path.open("r", encoding="utf-8") as f:
                                    idx = json.load(f) or []
                                idx = [x for x in idx if str(x.get("model_name")) != mname]
                                with index_path.open("w", encoding="utf-8") as f:
                                    json.dump(idx, f, ensure_ascii=False, indent=2)
                        except Exception as e:
                            logger.error(f"_delete_model_meta error: {e}")
                        
                        return gr.Dropdown(choices=_list_models())
                    except Exception as e:
                        logger.error(f"_delete_model error: {e}")
                        return gr.Dropdown(choices=_list_models())

                with gr.TabItem(label="ãƒ¢ãƒ‡ãƒ«ç®¡ç†"):
                    with gr.Accordion(label="1. è¨“ç·´ãƒ‡ãƒ¼ã‚¿ä¸€è¦§", open=True):
                        with gr.Row():
                            td_refresh_btn = gr.Button("è¨“ç·´ãƒ‡ãƒ¼ã‚¿ä¸€è¦§ã‚’å–å¾—", variant="primary")
                        with gr.Row():
                            td_refresh_status = gr.Markdown(visible=False)
                        with gr.Row():
                            td_list_df = gr.Dataframe(label="è¨“ç·´ãƒ‡ãƒ¼ã‚¿ä¸€è¦§", interactive=False, wrap=True, visible=False)
                        with gr.Row():
                            with gr.Column(scale=1):
                                gr.Markdown("Excelãƒ•ã‚¡ã‚¤ãƒ«", elem_classes="input-label")
                            with gr.Column(scale=5):
                                td_upload_excel_file = gr.File(show_label=False, file_types=[".xlsx"], type="filepath")
                        with gr.Row():
                            with gr.Column():
                                gr.DownloadButton(label="Excelãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", value="./uploads/training_data.xlsx", variant="secondary")
                            with gr.Column():
                                td_upload_excel_btn = gr.Button("Excelã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰(å…¨å‰Šé™¤&æŒ¿å…¥)", variant="stop")
                        with gr.Row():
                            td_upload_result = gr.Textbox(visible=False)
                    with gr.Accordion(label="2. ãƒ¢ãƒ‡ãƒ«å­¦ç¿’", open=True):
                        with gr.Row():
                            with gr.Column(scale=5):
                                with gr.Row():
                                    with gr.Column(scale=1):
                                        gr.Markdown("åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«", elem_classes="input-label")
                                    with gr.Column(scale=5):
                                        td_embed_model = gr.Dropdown(
                                            show_label=False,
                                            choices=["cohere.embed-v4.0"],
                                            value="cohere.embed-v4.0",
                                            interactive=True,
                                            container=False,
                                        )
                            with gr.Column(scale=5):
                                with gr.Row():
                                    with gr.Column(scale=1):
                                        gr.Markdown("")
                        with gr.Row():
                            td_train_btn = gr.Button("å­¦ç¿’ã‚’å®Ÿè¡Œ", variant="primary")
                        with gr.Row():
                            td_train_status = gr.Markdown(visible=False)
                    with gr.Accordion(label="3. ãƒ¢ãƒ‡ãƒ«ãƒ†ã‚¹ãƒˆ", open=True):
                        with gr.Row():
                            with gr.Column(scale=1):
                                gr.Markdown("ãƒ†ã‚­ã‚¹ãƒˆ", elem_classes="input-label")
                            with gr.Column(scale=5):
                                mt_text_input = gr.Textbox(show_label=False, lines=4, max_lines=8, container=False)
                        with gr.Row():
                            with gr.Column(scale=5):
                                with gr.Row():
                                    with gr.Column(scale=1):
                                        gr.Markdown("æ¥­å‹™ãƒ‰ãƒ¡ã‚¤ãƒ³(=ãƒ©ãƒ™ãƒ«)", elem_classes="input-label")
                                    with gr.Column(scale=5):
                                        mt_label_text = gr.Textbox(show_label=False, interactive=False, container=False)
                            with gr.Column(scale=5):
                                with gr.Row():
                                    with gr.Column(scale=1):
                                        gr.Markdown("")
                        with gr.Row():
                            mt_test_btn = gr.Button("ãƒ†ã‚¹ãƒˆ", variant="primary")
                        with gr.Row():                            
                            mt_test_result = gr.Markdown(visible=False)

                    td_refresh_btn.click(
                        fn=_td_refresh,
                        outputs=[td_refresh_status, td_list_df],
                    )
                    td_upload_excel_btn.click(
                        fn=_td_upload_excel,
                        inputs=[td_upload_excel_file],
                        outputs=[td_upload_result],
                    )
                    td_train_btn.click(
                        fn=_td_train,
                        inputs=[td_embed_model],
                        outputs=[td_train_status],
                    )
                    mt_test_btn.click(
                        fn=_mt_test,
                        inputs=[mt_text_input],
                        outputs=[mt_test_result, mt_label_text],
                    )

                with gr.TabItem(label="ç”¨èªé›†ç®¡ç†"):
                    with gr.Accordion(label="1. ç”¨èªé›†", open=True):
                        # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’äº‹å‰ä½œæˆã—ã€ãã®ã¾ã¾ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¯èƒ½ã«ã™ã‚‹
                        up_dir = Path("uploads")
                        up_dir.mkdir(parents=True, exist_ok=True)
                        _p = up_dir / "terms.xlsx"
                        if not _p.exists():
                            _df = pd.DataFrame(columns=["TERM", "DEFINITION"])
                            with pd.ExcelWriter(_p) as _writer:
                                _df.to_excel(_writer, sheet_name="terms", index=False)
    
                        with gr.Row():
                            with gr.Column(scale=1):
                                gr.Markdown("ç”¨èªé›†Excelã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰<br>â„¹ï¸ ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ‰ãƒ­ãƒƒãƒ—ã™ã‚‹ã¨è‡ªå‹•çš„ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¾ã™", elem_classes="input-label")
                            with gr.Column(scale=5):
                                term_upload_file = gr.File(show_label=False, file_types=[".xlsx"], type="filepath", container=True)
                        with gr.Row():
                            term_upload_result = gr.Textbox(label="ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰çµæœ", interactive=False, visible=False)
                        with gr.Row():
                            with gr.Column():
                                gr.DownloadButton(label="ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", value=str(_p), variant="secondary")
                            with gr.Column():
                                term_preview_btn = gr.Button("ç”¨èªé›†ã‚’ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼", variant="primary")
                        with gr.Row():
                            term_preview_status = gr.Markdown(visible=False)
                        with gr.Row():
                            term_preview_df = gr.Dataframe(
                                label="ç”¨èªé›†ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼",
                                interactive=False,
                                wrap=True,
                                visible=False,
                                value=pd.DataFrame(columns=["TERM", "DEFINITION"]),
                            )

                    def _term_list():
                        try:
                            p = Path("uploads") / "terms.xlsx"
                            if not p.exists():
                                return pd.DataFrame(columns=["TERM", "DEFINITION"])
                            df = pd.read_excel(str(p))
                            cols_map = {str(c).upper(): c for c in df.columns.tolist()}
                            t_col = cols_map.get("TERM")
                            d_col = cols_map.get("DEFINITION")
                            if not t_col or not d_col:
                                return pd.DataFrame(columns=["TERM", "DEFINITION"])
                            out = pd.DataFrame({
                                "TERM": df[t_col].astype(str),
                                "DEFINITION": df[d_col].astype(str),
                            })
                            return out
                        except Exception as e:
                            logger.error(f"ç”¨èªé›†ä¸€è¦§ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
                            return pd.DataFrame(columns=["TERM", "DEFINITION"])

                    def _term_refresh():
                        try:
                            yield gr.Markdown(visible=True, value="â³ ç”¨èªé›†ã‚’å–å¾—ä¸­..."), gr.Dataframe(visible=False, value=pd.DataFrame())
                            df = _term_list()
                            if df is None or df.empty:
                                yield gr.Markdown(visible=True, value="âœ… å–å¾—å®Œäº†ï¼ˆãƒ‡ãƒ¼ã‚¿ãªã—ï¼‰"), gr.Dataframe(visible=True, value=pd.DataFrame(columns=["TERM", "DEFINITION"]))
                                return
                            yield gr.Markdown(visible=False), gr.Dataframe(visible=True, value=df)
                        except Exception as e:
                            yield gr.Markdown(visible=True, value=f"âŒ å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}"), gr.Dataframe(visible=False, value=pd.DataFrame())

                    def _term_upload_excel(file_path):
                        try:
                            if not file_path:
                                return gr.Textbox(visible=True, value="ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„")
                            try:
                                df = pd.read_excel(str(file_path))
                            except Exception:
                                return gr.Textbox(visible=True, value="Excelèª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ")
                            cols_map = {str(c).upper(): c for c in df.columns.tolist()}
                            required = {"TERM", "DEFINITION"}
                            if not required.issubset(set(cols_map.keys())):
                                return gr.Textbox(visible=True, value="åˆ—åã¯ TERM, DESCRIPTION ãŒå¿…è¦ã§ã™")
                            out_df = pd.DataFrame({
                                "TERM": df[cols_map["TERM"]],
                                "DEFINITION": df[cols_map["DEFINITION"]],
                            })
                            up_dir = Path("uploads")
                            up_dir.mkdir(parents=True, exist_ok=True)
                            dest = up_dir / "terms.xlsx"
                            if dest.exists():
                                dest.unlink()
                            with pd.ExcelWriter(dest) as writer:
                                out_df.to_excel(writer, sheet_name="terms", index=False)
                            return gr.Textbox(visible=True, value=f"âœ… ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å®Œäº†: {len(out_df)} ä»¶")
                        except Exception as e:
                            logger.error(f"ç”¨èªé›†Excelã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
                            return gr.Textbox(visible=True, value=f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")

                    term_preview_btn.click(
                        fn=_term_refresh,
                        outputs=[term_preview_status, term_preview_df],
                    )

                    # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã¯ãƒœã‚¿ãƒ³è‡ªä½“ã§å®Ÿè¡Œï¼ˆã‚¯ãƒªãƒƒã‚¯ãƒãƒ³ãƒ‰ãƒ©ä¸è¦ï¼‰
                    term_upload_file.change(
                        fn=_term_upload_excel,
                        inputs=[term_upload_file],
                        outputs=[term_upload_result],
                    )

                with gr.TabItem(label="ãƒãƒ£ãƒƒãƒˆãƒ»åˆ†æ") as dev_chat_tab:
                    with gr.Accordion(label="1. ãƒãƒ£ãƒƒãƒˆ", open=True):
                        def _dev_profile_names():
                            try:
                                pairs = _load_profiles_from_json()
                                labels = [str(bd) for bd, _ in pairs]
                                # Gradio Dropdown supports label/value pairs via choices=[(label,value),...]
                                # We return pairs so that display is business_domain, value is profile
                                return [(str(bd), str(pf)) for bd, pf in pairs]
                            except Exception as e:
                                logger.error(f"_dev_profile_names error: {e}")
                            return [("", "")]

                        with gr.Row():
                            with gr.Column(scale=1):
                                gr.Markdown("è‡ªç„¶è¨€èªã®è³ªå•", elem_classes="input-label")
                            with gr.Column(scale=5):
                                dev_prompt_input = gr.Textbox(
                                    show_label=False,
                                    placeholder="ä¾‹: æ±äº¬ã®é¡§å®¢æ•°ã‚’æ•™ãˆã¦",
                                    lines=3,
                                    max_lines=10,
                                    show_copy_button=True,
                                    container=False,
                                )

                        with gr.Row():
                            with gr.Column(scale=5):
                                dev_predict_domain_btn = gr.Button("æ¥­å‹™ãƒ‰ãƒ¡ã‚¤ãƒ³äºˆæ¸¬ â‡’", variant="secondary")
                            with gr.Column(scale=5):
                                # ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«é¸æŠè‚¢ã‚’å–å¾—ã—ã€ç©ºã®å ´åˆã¯ç©ºæ–‡å­—åˆ—ã‚’å«ã‚€ãƒªã‚¹ãƒˆã‚’è¨­å®š
                                _dev_initial_choices = _dev_profile_names()
                                if not _dev_initial_choices:
                                    _dev_initial_choices = [("", "")]
                                dev_profile_select = gr.Dropdown(
                                    show_label=False,
                                    choices=_dev_initial_choices,
                                    value=_dev_initial_choices[0][1] if _dev_initial_choices and isinstance(_dev_initial_choices[0], tuple) else "",
                                    interactive=True,
                                    container=False,
                                )

                        with gr.Row():
                            with gr.Column(scale=1):
                                gr.Markdown("ã‚¯ã‚¨ãƒªæ›¸ãæ›ãˆã‚’æœ‰åŠ¹åŒ–", elem_classes="input-label")
                            with gr.Column(scale=5):
                                dev_enable_query_rewrite = gr.Checkbox(label="", value=False, container=False)
                        
                        with gr.Row():
                            with gr.Accordion(label="ã‚¯ã‚¨ãƒªæ›¸ãæ›ãˆè¨­å®š", open=True, visible=False) as dev_query_rewrite_section:
                                with gr.Row():
                                    with gr.Column(scale=5):
                                        with gr.Row():
                                            with gr.Column(scale=1):
                                                gr.Markdown("æ›¸ãæ›ãˆç”¨ãƒ¢ãƒ‡ãƒ«", elem_classes="input-label")
                                            with gr.Column(scale=5):
                                                dev_rewrite_model_select = gr.Dropdown(
                                                    show_label=False,
                                                    choices=[
                                                        "xai.grok-code-fast-1",
                                                        "xai.grok-3",
                                                        "xai.grok-3-fast",
                                                        "xai.grok-4",
                                                        "xai.grok-4-fast-non-reasoning",
                                                        "meta.llama-4-scout-17b-16e-instruct",
                                                    ],
                                                    value="xai.grok-code-fast-1",
                                                    interactive=True,
                                                    container=False,
                                                )
                                    with gr.Column(scale=5):
                                        with gr.Row():
                                            with gr.Column(scale=1):
                                                gr.Markdown("")
                                with gr.Row():
                                    with gr.Column(scale=1):
                                        gr.Markdown("ã‚¹ãƒ†ãƒƒãƒ—1: ç”¨èªé›†ã‚’åˆ©ç”¨", elem_classes="input-label")
                                    with gr.Column(scale=5):
                                        dev_rewrite_use_glossary = gr.Checkbox(label="", value=True, container=False)
                                with gr.Row():
                                    with gr.Column(scale=1):
                                        gr.Markdown("ã‚¹ãƒ†ãƒƒãƒ—2: ã‚¹ã‚­ãƒ¼ãƒæƒ…å ±ã‚’åˆ©ç”¨", elem_classes="input-label")
                                    with gr.Column(scale=5):
                                        dev_rewrite_use_schema = gr.Checkbox(label="", value=False, container=False)
                                with gr.Row():
                                    dev_rewrite_btn = gr.Button("æ›¸ãæ›ãˆå®Ÿè¡Œ", variant="primary")
                                with gr.Row():
                                    dev_rewrite_status = gr.Markdown(visible=False)
                                with gr.Row():
                                    with gr.Column(scale=1):
                                        gr.Markdown("æ›¸ãæ›ãˆå¾Œã®è³ªå•", elem_classes="input-label")
                                    with gr.Column(scale=5):
                                        dev_rewritten_query = gr.Textbox(
                                            show_label=False,
                                            lines=5,
                                            max_lines=10,
                                            interactive=True,
                                            show_copy_button=True,
                                            container=False,
                                        )

                        with gr.Row():
                            with gr.Column(scale=1):
                                gr.Markdown("è¿½åŠ æŒ‡ç¤ºãƒ»ä¾‹ç¤ºã‚’ä½¿ç”¨", elem_classes="input-label")
                            with gr.Column(scale=5):
                                dev_include_extra_prompt = gr.Checkbox(label="", value=False, container=False)

                        with gr.Row():
                            with gr.Accordion(label="è¿½åŠ æŒ‡ç¤ºãƒ»ä¾‹ç¤ºã‚’è¨­å®š", open=True, visible=False) as dev_extra_prompt_section:
                                with gr.Row():
                                    with gr.Column(scale=1):
                                        dev_extra_prompt = gr.Textbox(
                                            show_label=False,
                                            value=_DEFAULT_FEW_SHOT_PROMPT,
                                            lines=15,
                                            max_lines=15,
                                            show_copy_button=True,
                                            autoscroll=True,
                                            container=False,
                                        )
                            dev_include_extra_prompt.change(lambda v: gr.Accordion(visible=v), inputs=dev_include_extra_prompt, outputs=dev_extra_prompt_section)
                        
                        # Queryè»¢å†™ã®Checkboxå¤‰æ›´ãƒãƒ³ãƒ‰ãƒ©
                        dev_enable_query_rewrite.change(lambda v: gr.Accordion(visible=v), inputs=dev_enable_query_rewrite, outputs=dev_query_rewrite_section)

                        with gr.Row():
                            with gr.Column():
                                dev_chat_clear_btn = gr.Button("ã‚¯ãƒªã‚¢", variant="secondary")
                            with gr.Column():
                                dev_chat_execute_btn = gr.Button("å®Ÿè¡Œ", variant="primary")

                        with gr.Row():
                            dev_chat_status_md = gr.Markdown(visible=False)

                    with gr.Accordion(label="2. å®Ÿè¡Œçµæœ", open=True):
                        dev_chat_result_df = gr.Dataframe(
                            label="å®Ÿè¡Œçµæœ",
                            interactive=False,
                            wrap=True,
                            visible=False,
                            value=pd.DataFrame(),
                            elem_id="selectai_dev_chat_result_df",
                        )
                        dev_chat_result_style = gr.HTML(visible=False)

                    with gr.Accordion(label="3. ç”ŸæˆSQLãƒ»åˆ†æ", open=True):
                        dev_generated_sql_text = gr.Textbox(
                            label="ç”Ÿæˆã•ã‚ŒãŸSQLæ–‡",
                            lines=8,
                            max_lines=15,
                            interactive=True,
                            show_copy_button=True,
                        )

                        gr.Dataframe(
                            label="ä½¿ç”¨ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆä¸€è¦§",
                            interactive=False,
                            wrap=True,
                            visible=False,
                            value=pd.DataFrame(columns=["Name", "Type"]),
                        )

                        with gr.Row():
                            with gr.Column(scale=5):
                                with gr.Row():
                                    with gr.Column(scale=1):
                                        gr.Markdown("ãƒ¢ãƒ‡ãƒ«", elem_classes="input-label")
                                    with gr.Column(scale=5):
                                        dev_analysis_model_input = gr.Dropdown(
                                            show_label=False,
                                            choices=[
                                                "xai.grok-code-fast-1",
                                                "xai.grok-3",
                                                "xai.grok-3-fast",
                                                "xai.grok-4",
                                                "xai.grok-4-fast-non-reasoning",
                                                "meta.llama-4-scout-17b-16e-instruct",
                                                "gpt-4o",
                                                "gpt-5.1",
                                            ],
                                            value="xai.grok-code-fast-1",
                                            interactive=True,
                                            container=False,
                                        )
                            with gr.Column(scale=5):
                                with gr.Row():
                                    with gr.Column(scale=1):
                                        dev_ai_analyze_btn = gr.Button("AIåˆ†æ", variant="primary")

                        with gr.Row():
                            dev_ai_analyze_status = gr.Markdown(visible=False)

                        with gr.Row():
                            with gr.Column():
                                dev_join_conditions_text = gr.Textbox(
                                    label="çµåˆæ¡ä»¶",
                                    lines=6,
                                    max_lines=15,
                                    interactive=False,
                                    show_copy_button=True,
                                )
                            with gr.Column():
                                dev_where_conditions_text = gr.Textbox(
                                    label="Whereæ¡ä»¶",
                                    lines=6,
                                    max_lines=15,
                                    interactive=False,
                                    show_copy_button=True,
                                )

                    with gr.Accordion(label="4. ã‚¯ã‚¨ãƒªã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯", open=False):
                        with gr.Row():
                            with gr.Column(scale=5):
                                with gr.Row():
                                    with gr.Column(scale=1):
                                        gr.Markdown("ç¨®é¡", elem_classes="input-label")
                                    with gr.Column(scale=5):
                                        dev_feedback_type_select = gr.Dropdown(
                                            show_label=False,
                                            choices=["positive", "negative"],
                                            value="positive",
                                            interactive=True,
                                            container=False,
                                        )
                            with gr.Column(scale=5):
                                with gr.Row():
                                    with gr.Column(scale=1):
                                        gr.Markdown("")
                        with gr.Row():
                            with gr.Column(scale=1):
                                gr.Markdown("ä¿®æ­£SQL(response)", elem_classes="input-label")
                            with gr.Column(scale=5):
                                dev_feedback_response_text = gr.Textbox(
                                    show_label=False,
                                    placeholder="æœŸå¾…ã™ã‚‹æ­£ã—ã„SQLã‚’å…¥åŠ›",
                                    lines=4,
                                    max_lines=12,
                                    show_copy_button=True,
                                    interactive=False,
                                    container=False,
                                )

                        with gr.Row():
                            with gr.Column(scale=1):
                                gr.Markdown("ã‚³ãƒ¡ãƒ³ãƒˆ(feedback_content)", elem_classes="input-label")
                            with gr.Column(scale=5):
                                dev_feedback_content_text = gr.Textbox(
                                    show_label=False,
                                    placeholder="è‡ªç„¶è¨€èªã§æ”¹å–„ç‚¹ã‚„æ¡ä»¶ãªã©ã‚’å…¥åŠ›",
                                    lines=4,
                                    max_lines=12,
                                    show_copy_button=True,
                                    interactive=False,
                                    container=False,
                                )


                        with gr.Row():
                            with gr.Column(scale=1):
                                gr.Markdown("ä½¿ç”¨ã•ã‚ŒãŸDBMS_CLOUD_AI.FEEDBACK", elem_classes="input-label")
                            with gr.Column(scale=5):
                                dev_feedback_used_sql_text = gr.Textbox(
                                    show_label=False,
                                    lines=8,
                                    max_lines=15,
                                    interactive=False,
                                    show_copy_button=True,
                                    container=False,
                                )

                        with gr.Row():
                            dev_feedback_send_btn = gr.Button("ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯é€ä¿¡", variant="primary")
                        with gr.Row():
                            dev_feedback_status = gr.Markdown(visible=False)
                        with gr.Row():
                            dev_feedback_result = gr.Markdown(visible=False)

                    def _build_showsql_stmt(prompt: str) -> str:
                        s = str(prompt or "")
                        singles = ["!", "~", "^", "@", "#", "$", "%", "&", ";", ":"]
                        for d in singles:
                            if d not in s:
                                return f"select ai showsql q'{d}{s}{d}'"
                        pairs = [("(", ")"), ("[", "]"), ("{", "}"), ("<", ">")]
                        for o, c in pairs:
                            if o not in s and c not in s:
                                return f"select ai showsql q'{o}{s}{c}'"
                        esc = s.replace("'", "''")
                        return f"select ai showsql '{esc}'"
                    
                    def _get_profile_schema_info(profile_name: str) -> str:
                        """æŒ‡å®šã•ã‚ŒãŸProfileã«é–¢é€£ã™ã‚‹ãƒ†ãƒ¼ãƒ–ãƒ«ã¨VIEWã®DDLã€COMMENTSã‚’å–å¾—ã™ã‚‹.
                        
                        Args:
                            profile_name: Profileå
                        
                        Returns:
                            str: ã‚¹ã‚­ãƒ¼ãƒæƒ…å ±ã®ãƒ†ã‚­ã‚¹ãƒˆ
                        """
                        try:
                            # Profileã®å±æ€§ã‚’å–å¾—
                            prof_name = _resolve_profile_name(pool, profile_name)
                            attrs = _get_profile_attributes(pool, prof_name) or {}
                            obj_list = attrs.get("object_list") or []
                            
                            if not obj_list:
                                return ""
                            
                            schema_parts = []
                            schema_parts.append("=== ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¹ã‚­ãƒ¼ãƒæƒ…å ± ===")
                            
                            # ãƒ†ãƒ¼ãƒ–ãƒ«æƒ…å ±ã‚’å–å¾—
                            table_names = set(_get_table_names(pool))
                            for obj in obj_list:
                                obj_name = obj.get("name")
                                if obj_name in table_names:
                                    try:
                                        table_df = get_table_details(pool, obj_name)
                                        if table_df is not None and not table_df.empty:
                                            schema_parts.append(f"\n--- ãƒ†ãƒ¼ãƒ–ãƒ«: {obj_name} ---")
                                            # ã‚«ãƒ©ãƒ æƒ…å ±
                                            for _, row in table_df.iterrows():
                                                col_name = row.get("Column Name", "")
                                                col_type = row.get("Data Type", "")
                                                col_comment = row.get("Comments", "")
                                                schema_parts.append(f"  - {col_name} ({col_type}): {col_comment}")
                                    except Exception as e:
                                        logger.error(f"Failed to get table details for {obj_name}: {e}")
                            
                            # VIEWæƒ…å ±ã‚’å–å¾—
                            view_names = set(_get_view_names(pool))
                            for obj in obj_list:
                                obj_name = obj.get("name")
                                if obj_name in view_names:
                                    try:
                                        view_df, view_ddl = get_view_details(pool, obj_name)
                                        if view_df is not None and not view_df.empty:
                                            schema_parts.append(f"\n--- VIEW: {obj_name} ---")
                                            # ã‚«ãƒ©ãƒ æƒ…å ±
                                            for _, row in view_df.iterrows():
                                                col_name = row.get("Column Name", "")
                                                col_type = row.get("Data Type", "")
                                                col_comment = row.get("Comments", "")
                                                schema_parts.append(f"  - {col_name} ({col_type}): {col_comment}")
                                    except Exception as e:
                                        logger.error(f"Failed to get view details for {obj_name}: {e}")
                            
                            return "\n".join(schema_parts)
                        except Exception as e:
                            logger.error(f"_get_profile_schema_info error: {e}")
                            return ""
                    
                    def _load_terminology() -> dict:
                        """ç”¨èªé›†ã‚’èª­ã¿è¾¼ã‚€.
                        
                        Returns:
                            dict: {TERM: DESCRIPTION}ã®è¾æ›¸
                        """
                        try:
                            p = Path("uploads") / "terms.xlsx"
                            if not p.exists():
                                return {}
                            df = pd.read_excel(str(p))
                            cols_map = {str(c).upper(): c for c in df.columns.tolist()}
                            t_col = cols_map.get("TERM")
                            d_col = cols_map.get("DEFINITION")
                            if not t_col or not d_col:
                                return {}
                            terms = {}
                            for _, row in df.iterrows():
                                term = str(row[t_col]).strip()
                                desc = str(row[d_col]).strip()
                                if term and desc:
                                    terms[term] = desc
                            return terms
                        except Exception as e:
                            logger.error(f"_load_terminology error: {e}")
                            return {}
                    
                    def _dev_rewrite_query(model_name, profile_name, original_query, use_glossary, use_schema):
                        """é–‹ç™ºè€…å‘ã‘ã‚¯ã‚¨ãƒªæ›¸ãæ›ãˆå‡¦ç†.
                        
                        Args:
                            model_name: ä½¿ç”¨ã™ã‚‹LLMãƒ¢ãƒ‡ãƒ«
                            profile_name: Profileå
                            original_query: å…ƒã®è‡ªç„¶è¨€èªã®è³ªå•
                            use_glossary: ç¬¬1ã‚¹ãƒ†ãƒƒãƒ—ï¼ˆç”¨èªé›†ï¼‰ã‚’å®Ÿè¡Œã™ã‚‹ã‹
                            use_schema: ç¬¬2ã‚¹ãƒ†ãƒƒãƒ—ã‚’å®Ÿè¡Œã™ã‚‹ã‹
                        
                        Yields:
                            tuple: (status_md, rewritten_text)
                        """
                        from utils.chat_util import get_oci_region, get_compartment_id
                        from oci_openai import AsyncOciOpenAI, OciUserPrincipalAuth
                        
                        try:
                            # å…¥åŠ›ãƒã‚§ãƒƒã‚¯
                            if not model_name or not str(model_name).strip():
                                yield gr.Markdown(visible=True, value="âš ï¸ ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„"), gr.Textbox(value="")
                                return
                            if not original_query or not str(original_query).strip():
                                yield gr.Markdown(visible=True, value="âš ï¸ å…ƒã®è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„"), gr.Textbox(value="")
                                return
                            
                            region = get_oci_region()
                            compartment_id = get_compartment_id()
                            if not region or not compartment_id:
                                yield gr.Markdown(visible=True, value="âŒ OCIè¨­å®šãŒä¸è¶³ã—ã¦ã„ã¾ã™"), gr.Textbox(value="")
                                return
                            
                            # ã‚¹ãƒ†ãƒƒãƒ—1/2ãŒä¸¡æ–¹OFFã®å ´åˆã¯è­¦å‘Šã—ã¦çµ‚äº†
                            if (not use_glossary) and (not use_schema):
                                yield gr.Markdown(visible=True, value="âš ï¸ ã‚¹ãƒ†ãƒƒãƒ—1ï¼ˆç”¨èªé›†ï¼‰ã¨ã‚¹ãƒ†ãƒƒãƒ—2ï¼ˆã‚¹ã‚­ãƒ¼ãƒï¼‰ãŒOFFã§ã™ã€‚å°‘ãªãã¨ã‚‚1ã¤ã‚’ONã«ã—ã¦ãã ã•ã„"), gr.Textbox(value="")
                                return
                            
                            step1_result = str(original_query).strip()
                            
                            # ç¬¬1ã‚¹ãƒ†ãƒƒãƒ—: ç”¨èªé›†ã§åˆ†æãƒ»ç½®æ›ï¼ˆONã®å ´åˆã®ã¿ï¼‰
                            if use_glossary:
                                yield gr.Markdown(visible=True, value="â³ ç¬¬1ã‚¹ãƒ†ãƒƒãƒ—: ç”¨èªé›†ã§åˆ†æãƒ»ç½®æ›ä¸­..."), gr.Textbox(value="")
                                
                                terms = _load_terminology()
                                if terms:
                                    # ç”¨èªé›†ã‚’ä½¿ã£ã¦LLMã§åˆ†æ
                                    terms_text = "\n".join([f"- {k}: {v}" for k, v in terms.items()])
                                    step1_prompt = f"""ã‚ãªãŸã¯ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¯ã‚¨ãƒªã®å°‚é–€å®¶ã§ã™ã€‚ä»¥ä¸‹ã®ç”¨èªé›†ã¯ã€ŒAï¼ˆTERMï¼‰â†’Bï¼ˆå®šç¾©ãƒ»æ¨å¥¨è¡¨ç¾ï¼‰ã€ã®æœ€é©åŒ–æŒ‡é‡ã§ã™ã€‚æœ¬ã‚¹ãƒ†ãƒƒãƒ—ã§ã¯æ­£æ–¹å‘ã®æœ€é©åŒ–ã‚’è¡Œã„ã€å…ƒã®è³ªå•ã«å«ã¾ã‚Œã‚‹Aå´ã®ç”¨èªã‚’Bå´ã®æ¨å¥¨è¡¨ç¾ã¸æ˜ç¢ºåŒ–ãƒ»æ­£è¦åŒ–ã—ã¦ãã ã•ã„ã€‚

ç”¨èªé›†:
{terms_text}

å…ƒã®è³ªå•:
{original_query}

æŒ‡ç¤º:
1. TERMï¼ˆAå´ï¼‰ãŒå«ã¾ã‚Œã‚‹å ´åˆã¯ã€ãã®å®šç¾©ãƒ»æ¨å¥¨è¡¨ç¾ï¼ˆBå´ï¼‰ã«ç½®æ›ã—ã€æ„å‘³ã‚’æ˜ç¢ºåŒ–ã—ã¦ãã ã•ã„ã€‚
2. æ›–æ˜§ãªè¡¨ç¾ã¯ã€å¯¾è±¡ãƒ»æ¡ä»¶ãƒ»æœŸé–“ãªã©ã‚’å¯èƒ½ãªé™ã‚Šå…·ä½“çš„ãªè¨€ã„å›ã—ã«æ•´ãˆã¦ãã ã•ã„ã€‚
3. è³ªå•ã®æ„å›³ãƒ»æ¡ä»¶ãƒ»å¯¾è±¡ã¯ç¶­æŒã—ã€ä¸è¦ãªè¿½åŠ ãƒ»å‰Šé™¤ã¯è¡Œã‚ãªã„ã§ãã ã•ã„ã€‚
4. æ•°å€¤ãƒ»æ—¥ä»˜ãƒ»ç¯„å›²ãªã©ã®å…·ä½“å€¤ã¯å¤‰æ›´ã—ãªã„ã§ãã ã•ã„ã€‚
5. å‡ºåŠ›ã¯ä¿®æ­£å¾Œã®è³ªå•æ–‡ã®ã¿ã€‚èª¬æ˜ã‚„å‰ç½®ãã¯ä¸è¦ã§ã™ã€‚

ä¿®æ­£å¾Œã®è³ªå•:"""
                                    
                                    loop = asyncio.new_event_loop()
                                    asyncio.set_event_loop(loop)
                                    try:
                                        messages = [{"role": "user", "content": step1_prompt}]
                                        if str(model_name).startswith("gpt-"):
                                            from openai import AsyncOpenAI
                                            client = AsyncOpenAI()
                                            resp = loop.run_until_complete(
                                                client.chat.completions.create(model=model_name, messages=messages)
                                            )
                                        else:
                                            client = AsyncOciOpenAI(
                                                service_endpoint=f"https://inference.generativeai.{region}.oci.oraclecloud.com",
                                                auth=OciUserPrincipalAuth(),
                                                compartment_id=compartment_id,
                                            )
                                            resp = loop.run_until_complete(
                                                client.chat.completions.create(model=model_name, messages=messages)
                                            )
                                        if resp.choices and len(resp.choices) > 0:
                                            step1_result = resp.choices[0].message.content.strip()
                                    finally:
                                        loop.close()
                            
                            # ç¬¬2ã‚¹ãƒ†ãƒƒãƒ—ãŒç„¡åŠ¹ãªã‚‰ã“ã“ã§çµ‚äº†
                            if not use_schema:
                                yield gr.Markdown(visible=True, value="âœ… å®Œäº†ï¼ˆç¬¬1ã‚¹ãƒ†ãƒƒãƒ—ã®ã¿ï¼‰"), gr.Textbox(value=step1_result)
                                return
                            
                            yield gr.Markdown(visible=True, value="â³ ã‚¹ãƒ†ãƒƒãƒ—2: ã‚¹ã‚­ãƒ¼ãƒæƒ…å ±ã‚’å–ã‚Šè¾¼ã¿ã€è‡ªç„¶è¨€èªã¸æ›¸ãæ›ãˆä¸­..."), gr.Textbox(value=step1_result)
                            
                            # ã‚¹ãƒ†ãƒƒãƒ—2: ã‚¹ã‚­ãƒ¼ãƒæƒ…å ±ã‚’å–ã‚Šè¾¼ã¿ã€è‡ªç„¶è¨€èªã¸æ›¸ãæ›ãˆ
                            if not profile_name or not str(profile_name).strip():
                                yield gr.Markdown(visible=True, value="âš ï¸ Profileã‚’é¸æŠã—ã¦ãã ã•ã„"), gr.Textbox(value=step1_result)
                                return
                            
                            schema_info = _get_profile_schema_info(profile_name)
                            if not schema_info:
                                yield gr.Markdown(visible=True, value="âš ï¸ ã‚¹ã‚­ãƒ¼ãƒæƒ…å ±ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ"), gr.Textbox(value=step1_result)
                                return
                            
                            step2_prompt = f"""ã‚ãªãŸã¯ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¯ã‚¨ãƒªã®å°‚é–€å®¶ã§ã™ã€‚ä»¥ä¸‹ã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¹ã‚­ãƒ¼ãƒæƒ…å ±ã‚’å‚ç…§ã—ã€å…ƒã®è³ªå•ã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãŒã‚ˆã‚Šæ­£ç¢ºã«è§£é‡ˆã§ãã‚‹è‡ªç„¶è¨€èªã¸å¤‰æ›ã—ã¦ãã ã•ã„ã€‚

=== å‚è€ƒã‚¹ã‚­ãƒ¼ãƒæƒ…å ± ===
{schema_info}

=== å…ƒã®è³ªå• ===
{step1_result}

æŒ‡ç¤º:
1. åˆ©ç”¨å¯èƒ½ãªãƒ†ãƒ¼ãƒ–ãƒ«åãƒ»ã‚«ãƒ©ãƒ åãƒ»VIEWåã‚’è‡ªç„¶è¨€èªã®ä¸­ã§æ˜ç¢ºã«ã—ã€æ›–æ˜§ãªç”¨èªã¯ã‚¹ã‚­ãƒ¼ãƒã«åˆã‚ã›ã¦å…·ä½“åŒ–ã—ã¦ãã ã•ã„ã€‚
2. æ¡ä»¶ãƒ»æœŸé–“ãƒ»é›†è¨ˆãªã©ãŒå«ã¾ã‚Œã‚‹å ´åˆã¯ã€è‡ªç„¶è¨€èªã§æ˜ç¢ºã«è¨˜è¿°ã—ã¦ãã ã•ã„ã€‚
3. è³ªå•ã®å…ƒã®æ„å›³ã‚’ä¿ã¡ã¤ã¤ã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ã¨ã£ã¦è§£é‡ˆã—ã‚„ã™ã„è¡¨ç¾ã«ã—ã¦ãã ã•ã„ã€‚
4. SQLã‚„ã‚³ãƒ¼ãƒ‰ã¯çµ¶å¯¾ã«å‡ºåŠ›ã›ãšã€è‡ªç„¶è¨€èªã®ã¿ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚
5. å‡ºåŠ›ã¯å¤‰æ›å¾Œã®è‡ªç„¶è¨€èªã®è³ªå•æ–‡ã®ã¿ã¨ã—ã€èª¬æ˜ã‚„å‰ç½®ãã¯ä¸è¦ã§ã™ã€‚

å¤‰æ›å¾Œã®è‡ªç„¶è¨€èª:"""
                            
                            loop = asyncio.new_event_loop()
                            asyncio.set_event_loop(loop)
                            try:
                                messages = [{"role": "user", "content": step2_prompt}]
                                if str(model_name).startswith("gpt-"):
                                    from openai import AsyncOpenAI
                                    client = AsyncOpenAI()
                                    resp = loop.run_until_complete(
                                        client.chat.completions.create(model=model_name, messages=messages)
                                    )
                                else:
                                    client = AsyncOciOpenAI(
                                        service_endpoint=f"https://inference.generativeai.{region}.oci.oraclecloud.com",
                                        auth=OciUserPrincipalAuth(),
                                        compartment_id=compartment_id,
                                    )
                                    resp = loop.run_until_complete(
                                        client.chat.completions.create(model=model_name, messages=messages)
                                    )
                                if resp.choices and len(resp.choices) > 0:
                                    final_result = str(step1_result) + "\n\n" + resp.choices[0].message.content.strip()
                                else:
                                    final_result = step1_result
                            finally:
                                loop.close()

                            
                            yield gr.Markdown(visible=True, value="âœ… æ›¸ãæ›ãˆå®Œäº†"), gr.Textbox(value=final_result)
                            
                        except Exception as e:
                            logger.error(f"_dev_rewrite_query error: {e}")
                            import traceback
                            logger.error(traceback.format_exc())
                            yield gr.Markdown(visible=True, value=f"âŒ ã‚¨ãƒ©ãƒ¼: {e}"), gr.Textbox(value="")

                    def _dev_step_generate(profile, prompt, extra_prompt, include_extra, enable_rewrite, rewritten_query):
                        """SQLç”Ÿæˆå‡¦ç†.
                        
                        Args:
                            profile: Profileå
                            prompt: å…ƒã®è‡ªç„¶è¨€èªã®è³ªå•
                            extra_prompt: è¿½åŠ æŒ‡ç¤ºãƒ»ä¾‹ç¤º
                            include_extra: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½¿ç”¨ã™ã‚‹ã‹
                            enable_rewrite: Queryè»¢å†™ãŒæœ‰åŠ¹ã‹
                            rewritten_query: æ›¸ãæ›ãˆå¾Œã®è³ªå•
                        
                        Yields:
                            tuple: (status_md, generated_sql_textbox)
                        """
                        # Queryè»¢å†™ãŒæœ‰åŠ¹ãªå ´åˆã¯è»¢å†™å¾Œã®è³ªå•ã‚’ä½¿ç”¨
                        if enable_rewrite and rewritten_query and str(rewritten_query).strip():
                            s = str(rewritten_query).strip()
                        else:
                            s = str(prompt or "").strip()
                        
                        ep = str(extra_prompt or "").strip()
                        inc = bool(include_extra)
                        final = s if not inc or not ep else (ep + "\n\n" + s)
                        
                        if not profile or not str(profile).strip():
                            logger.error("ProfileãŒæœªé¸æŠã§ã™")
                            yield gr.Markdown(visible=True, value="âš ï¸ Profileã‚’é¸æŠã—ã¦ãã ã•ã„"), gr.Textbox(value="")
                            return
                        if not final:
                            logger.error("è³ªå•ãŒæœªå…¥åŠ›ã§ã™")
                            yield gr.Markdown(visible=True, value="âš ï¸ è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„"), gr.Textbox(value="")
                            return
                        
                        q = final
                        if q.endswith(";"):
                            q = q[:-1]
                        
                        try:
                            yield gr.Markdown(visible=True, value="â³ SQLç”Ÿæˆä¸­..."), gr.Textbox(value="")
                            with pool.acquire() as conn:
                                with conn.cursor() as cursor:
                                    try:
                                        prof = _resolve_profile_name(pool, str(profile or ""))
                                        cursor.execute("BEGIN DBMS_CLOUD_AI.SET_PROFILE(profile_name => :name); END;", name=prof)
                                    except Exception as e:
                                        logger.error(f"set profile error: {e}")
                                    
                                    gen_stmt = "select dbms_cloud_ai.generate(prompt=> :q, profile_name=> :name, action=> :a)"
                                    showsql_stmt = _build_showsql_stmt(q)
                                    show_text = ""
                                    show_cells = []
                                    try:
                                        cursor.execute(gen_stmt, q=showsql_stmt, name=prof, a="showsql")
                                        rows = cursor.fetchmany(size=200)
                                        if rows:
                                            for r in rows:
                                                for v in r:
                                                    try:
                                                        s = v.read() if hasattr(v, "read") else str(v)
                                                    except Exception:
                                                        s = str(v)
                                                    if s:
                                                        show_cells.append(s)
                                            show_text = "\n".join(show_cells)
                                    except Exception as e:
                                        logger.error(f"dev showsql generate error: {e}")
                                        # ã‚¨ãƒ©ãƒ¼ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®JSONã‹ã‚‰ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æŠ½å‡ºã—ã¦è¡¨ç¤º
                                        err_msg = str(e)
                                        try:
                                            import re as _re
                                            m = _re.search(r'Error response - ({.*})', err_msg)
                                            if m:
                                                err_json = json.loads(m.group(1))
                                                if "message" in err_json:
                                                    inner_msg = err_json["message"]
                                                    # å†…å´ã®JSONæ–‡å­—åˆ—ã‚’ãƒ‘ãƒ¼ã‚¹
                                                    try:
                                                        inner_json = json.loads(inner_msg)
                                                        if "error" in inner_json:
                                                            err_msg = inner_json["error"]
                                                        elif "code" in inner_json and "message" in inner_json:
                                                            err_msg = f"{inner_json['code']}: {inner_json['message']}"
                                                    except:
                                                        err_msg = inner_msg
                                        except Exception as parse_err:
                                            logger.error(f"Error parsing error message: {parse_err}")
                                            
                                        yield gr.Markdown(visible=True, value=f"âŒ ã‚¨ãƒ©ãƒ¼: {err_msg}"), gr.Textbox(value="")
                                        show_text = ""
                                        return
                                    try:
                                        cursor.execute(showsql_stmt)
                                    except Exception as e:
                                        logger.error(f"dev showsql execute error: {e}")
                                        yield gr.Markdown(visible=True, value=f"âŒ ã‚¨ãƒ©ãƒ¼: {e}"), gr.Textbox(value="")
                                        return
                                    _ = _get_sql_id_for_text(showsql_stmt)
                                    def _extract_sql(text: str) -> str:
                                        if not text:
                                            return ""
                                        m = re.search(r"```sql\s*([\s\S]*?)```", text, flags=re.IGNORECASE)
                                        if m:
                                            s = m.group(1).strip()
                                            return s
                                        m2 = re.search(r"SQL\s*:([\s\S]+)$", text, flags=re.IGNORECASE)
                                        if m2:
                                            s = m2.group(1).strip()
                                            return s
                                        m3 = re.search(r"\b(SELECT|WITH)\b[\s\S]*", text, flags=re.IGNORECASE)
                                        if m3:
                                            s = m3.group(0).strip()
                                            return s
                                        return ""
                                    generated_sql = _extract_sql(show_text)
                                    if not generated_sql and show_cells:
                                        for cell in show_cells:
                                            c = str(cell)
                                            try:
                                                obj = json.loads(c)
                                                if isinstance(obj, dict):
                                                    for k in ["sql", "SQL", "generated_sql", "query", "Query"]:
                                                        if k in obj and obj[k]:
                                                            generated_sql = str(obj[k]).strip()
                                                            break
                                                if generated_sql:
                                                    break
                                            except Exception as e:
                                                logger.error(f"_to_plain JSON decode error: {e}")
                                            m = re.search(r"\b(SELECT|WITH)\b[\s\S]*", c, flags=re.IGNORECASE)
                                            if m:
                                                generated_sql = m.group(0).strip()
                                                break
                                    gen_sql_display = generated_sql
                                    if gen_sql_display and not gen_sql_display.endswith(";"):
                                        gen_sql_display = gen_sql_display
                                    yield gr.Markdown(visible=True, value="âœ… SQLç”Ÿæˆå®Œäº†"), gr.Textbox(value=gen_sql_display)
                        except Exception as e:
                            logger.error(f"_dev_step_generate error: {e}")
                            yield gr.Markdown(visible=True, value=f"âŒ ã‚¨ãƒ©ãƒ¼: {e}"), gr.Textbox(value="")

                    def _dev_step_run_sql(profile, generated_sql):
                        try:
                            yield gr.Markdown(visible=True, value="â³ å®Ÿè¡Œä¸­..."), gr.Dataframe(visible=False, value=pd.DataFrame(), label="å®Ÿè¡Œçµæœ", elem_id="selectai_dev_chat_result_df"), gr.HTML(visible=False, value="")
                            with pool.acquire() as conn:
                                with conn.cursor() as cursor:
                                    s = str(generated_sql or "").strip()
                                    if not s or not re.match(r"^\s*(select|with)\b", s, flags=re.IGNORECASE):
                                        yield gr.Markdown(visible=True, value="â„¹ï¸ ãƒ‡ãƒ¼ã‚¿ã¯è¿”å´ã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ"), gr.Dataframe(visible=False, value=pd.DataFrame(), label="å®Ÿè¡Œçµæœï¼ˆä»¶æ•°: 0ï¼‰", elem_id="selectai_dev_chat_result_df"), gr.HTML(visible=False, value="")
                                        return
                                    run_sql = s
                                    if run_sql.endswith(";"):
                                        run_sql = run_sql[:-1]
                                    cursor.execute(run_sql)
                                    exec_rows = cursor.fetchmany(size=100)
                                    exec_cols = [d[0] for d in cursor.description] if cursor.description else []
                                    if exec_rows:
                                        cleaned_rows = []
                                        for r in exec_rows:
                                            cleaned_rows.append([v.read() if hasattr(v, "read") else v for v in r])
                                        df = pd.DataFrame(cleaned_rows, columns=exec_cols)
                                        widths = []
                                        if len(df) > 0:
                                            sample = df.head(5)
                                            for col in df.columns:
                                                series = sample[col].astype(str)
                                                row_max = series.map(len).max() if len(series) > 0 else 0
                                                length = max(len(str(col)), row_max)
                                                widths.append(length)
                                        else:
                                            widths = [len(str(c)) for c in df.columns]
                                        total = sum(widths) if widths else 0
                                        if total <= 0:
                                            col_widths = None
                                        else:
                                            col_widths = [max(5, int(100 * w / total)) for w in widths]
                                            diff = 100 - sum(col_widths)
                                            if diff != 0 and len(col_widths) > 0:
                                                col_widths[0] = max(5, col_widths[0] + diff)
                                        df_component = gr.Dataframe(
                                            visible=True,
                                            value=df,
                                            label=f"å®Ÿè¡Œçµæœï¼ˆä»¶æ•°: {len(df)}ï¼‰",
                                            elem_id="selectai_dev_chat_result_df",
                                        )
                                        style_value = ""
                                        if col_widths:
                                            rules = []
                                            rules.append("#selectai_dev_chat_result_df { width: 100% !important; }")
                                            rules.append("#selectai_dev_chat_result_df .wrap { overflow-x: auto !important; }")
                                            rules.append("#selectai_dev_chat_result_df table { table-layout: fixed !important; width: 100% !important; border-collapse: collapse !important; }")
                                            for idx, pct in enumerate(col_widths, start=1):
                                                rules.append(
                                                    f"#selectai_dev_chat_result_df table th:nth-child({idx}), #selectai_dev_chat_result_df table td:nth-child({idx}) {{ width: {pct}% !important; overflow: hidden !important; text-overflow: ellipsis !important; }}"
                                                )
                                            style_value = "<style>" + "\n".join(rules) + "</style>"
                                        style_component = gr.HTML(visible=bool(style_value), value=style_value)
                                        yield gr.Markdown(visible=True, value=f"âœ… {len(df)}ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¾ã—ãŸ"), df_component, style_component
                                        return
                                    yield gr.Markdown(visible=True, value="â„¹ï¸ ãƒ‡ãƒ¼ã‚¿ã¯è¿”å´ã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ"), gr.Dataframe(visible=False, value=pd.DataFrame(), label="å®Ÿè¡Œçµæœï¼ˆä»¶æ•°: 0ï¼‰", elem_id="selectai_dev_chat_result_df"), gr.HTML(visible=False, value="")
                        except Exception as e:
                            logger.error(f"_dev_step_run_sql error: {e}")
                            yield gr.Markdown(visible=True, value=f"âŒ ã‚¨ãƒ©ãƒ¼: {str(e)}"), gr.Dataframe(visible=False, value=pd.DataFrame(), label="å®Ÿè¡Œçµæœ", elem_id="selectai_dev_chat_result_df"), gr.HTML(visible=False, value="")

                    async def _dev_ai_analyze_async(model_name, sql_text):
                        try:
                            from utils.chat_util import get_oci_region, get_compartment_id
                            region = get_oci_region()
                            compartment_id = get_compartment_id()
                            if not region or not compartment_id:
                                return gr.Markdown(visible=True, value="âš ï¸ OCIè¨­å®šãŒä¸è¶³ã—ã¦ã„ã¾ã™"), gr.Textbox(value=""), gr.Textbox(value="")
                            s = str(sql_text or "").strip()
                            if not s:
                                return gr.Markdown(visible=True, value="âš ï¸ SQLæ–‡ãŒç©ºã§ã™"), gr.Textbox(value=""), gr.Textbox(value="")
                            
                            if str(model_name).startswith("gpt-"):
                                from openai import AsyncOpenAI
                                client = AsyncOpenAI()
                            else:
                                from oci_openai import AsyncOciOpenAI, OciUserPrincipalAuth
                                client = AsyncOciOpenAI(
                                    service_endpoint=f"https://inference.generativeai.{region}.oci.oraclecloud.com",
                                    auth=OciUserPrincipalAuth(),
                                    compartment_id=compartment_id,
                                )

                            prompt = (
                                "Extract ONLY JOIN and WHERE conditions from the SQL query below.\n"
                                "Output in STRICT format (no explanations, no markdown, no extra text):\n\n"
                                "JOIN:\n"
                                "[JOIN_TYPE] alias1(schema.table1).column1 = alias2(schema.table2).column2\n"
                                "[JOIN_TYPE] alias3(schema.table3).column3 = alias4(schema.table4).column4\n\n"
                                "WHERE:\n"
                                "alias(schema.table).column operator value\n\n"
                                "Rules:\n"
                                "- Format: alias(schema.table_name).column or schema.table_name.column (if no alias)\n"
                                "- JOIN_TYPE must be one of: INNER JOIN, LEFT JOIN, RIGHT JOIN, FULL JOIN, CROSS JOIN, JOIN\n"
                                "- Include schema name if present (e.g., ADMIN.USER_ROLE)\n"
                                "- One condition per line\n"
                                "- Keep original operators (=, >, <, LIKE, IN, etc.)\n"
                                "- Preserve exact column names and values with quotes\n"
                                "- If no JOIN/WHERE exists, output 'JOIN:\\nNone' or 'WHERE:\\nNone'\n\n"
                                "SQL:\n```sql\n" + s + "\n```"
                            )

                            messages = [
                                {
                                    "role": "system", 
                                    "content": "You are a SQL parser. Output ONLY the requested format. No explanations."
                                },
                                {
                                    "role": "user", 
                                    "content": prompt
                                },
                            ]

                            resp = await client.chat.completions.create(model=model_name, messages=messages)
                            join_text = ""
                            where_text = ""
                            if getattr(resp, "choices", None):
                                msg = resp.choices[0].message
                                out = msg.content if hasattr(msg, "content") else ""
                                s = str(out or "")
                                s = re.sub(r"```+\w*", "", s)
                                m = re.search(r"JOIN:\s*([\s\S]*?)\n\s*WHERE:\s*([\s\S]*)$", s, flags=re.IGNORECASE)
                                if m:
                                    join_text = m.group(1).strip()
                                    where_text = m.group(2).strip()
                            if not join_text:
                                join_text = "None"
                            if not where_text:
                                where_text = "None"
                            return gr.Markdown(visible=True, value="âœ… AIåˆ†æå®Œäº†"), gr.Textbox(value=join_text), gr.Textbox(value=where_text)
                        except Exception as e:
                            logger.error(f"_dev_ai_analyze_async error: {e}")
                            return gr.Markdown(visible=True, value=f"âŒ ã‚¨ãƒ©ãƒ¼: {e}"), gr.Textbox(value="None"), gr.Textbox(value="None")

                    def _dev_ai_analyze(model_name, sql_text):
                        import asyncio
                        # å¿…é ˆå…¥åŠ›é …ç›®ã®ãƒã‚§ãƒƒã‚¯
                        if not model_name or not str(model_name).strip():
                            return gr.Markdown(visible=True, value="âš ï¸ ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„"), gr.Textbox(value=""), gr.Textbox(value="")
                        if not sql_text or not str(sql_text).strip():
                            return gr.Markdown(visible=True, value="âš ï¸ SQLæ–‡ãŒç©ºã§ã™ã€‚å…ˆã«SQLæ–‡ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„"), gr.Textbox(value=""), gr.Textbox(value="")
                        
                        loop = asyncio.new_event_loop()
                        asyncio.set_event_loop(loop)
                        try:
                            return loop.run_until_complete(_dev_ai_analyze_async(model_name, sql_text))
                        finally:
                            loop.close()

                    def _on_dev_chat_clear():
                        ch = _dev_profile_names() or [("", "")]
                        return "", gr.Dropdown(choices=ch, value=ch[0][1])

                    def _predict_domain_and_set_profile(text):
                        try:
                            ch = _dev_profile_names() or [("", "")]
                            pdomain = _predict_business_domain_label(text)
                            return _map_domain_to_profile(pdomain, ch)
                        except Exception:
                            ch = _dev_profile_names() or [("", "")]
                            return gr.Dropdown(choices=ch, value=ch[0][1])

                    def _append_comment(current_text: str, template: str):
                        s = str(current_text or "").strip()
                        t = str(template or "").strip()
                        if not s:
                            return t
                        if s.endswith("\n"):
                            return s + t
                        return s + "\n" + t

                    def _get_sql_id_for_text(sql_text: str) -> str:
                            try:
                                s = str(sql_text or "").strip()
                                if not s:
                                    return ""
                                with pool.acquire() as conn:
                                    with conn.cursor() as cursor:
                                        # Try match against SQL_TEXT in v$mapped_sql
                                        try:
                                            cursor.execute(
                                                """
                                                select sql_id
                                                from v$mapped_sql
                                                where regexp_replace(sql_text,'\\s+',' ') = regexp_replace(:t,'\\s+',' ')
                                                order by translation_timestamp desc nulls last, use_count desc
                                                fetch first 1 rows only
                                                """,
                                                t=s,
                                            )
                                            row = cursor.fetchone()
                                            if row and row[0]:
                                                return str(row[0])
                                        except Exception as e:
                                            logger.error(f"_get_sql_id_for_text primary error: {e}")

                                        # Fallback: match against SQL_FULLTEXT (CLOB)
                                        try:
                                            cursor.execute(
                                                """
                                                select sql_id
                                                from v$mapped_sql
                                                where regexp_replace(dbms_lob.substr(sql_fulltext, 4000),'\\s+',' ') = regexp_replace(:t,'\\s+',' ')
                                                order by translation_timestamp desc nulls last, use_count desc
                                                fetch first 1 rows only
                                                """,
                                                t=s,
                                            )
                                            row = cursor.fetchone()
                                            if row and row[0]:
                                                return str(row[0])
                                        except Exception as e:
                                            logger.error(f"_get_sql_id_for_text fallback error: {e}")
                            except Exception as e:
                                logger.error(f"_get_sql_id_for_text outer error: {e}")
                                return ""
                            return ""

                    def _send_feedback(fb_type, response_text, content_text, prompt_text, profile_name):
                        try:
                            yield gr.Markdown(visible=True, value="â³ ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯é€ä¿¡ä¸­..."), gr.Markdown(visible=False), gr.Textbox(value="")
                            with pool.acquire() as conn:
                                with conn.cursor() as cursor:
                                    prof = _resolve_profile_name(pool, str(profile_name or ""))
                                    q = str(prompt_text or "").strip()
                                    if q.endswith(";"):
                                        q = q[:-1]
                                    if not q:
                                        yield gr.Markdown(visible=False), gr.Markdown(visible=True, value="âš ï¸ è³ªå•ãŒæœªå…¥åŠ›ã®ãŸã‚ã€ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’é€ä¿¡ã§ãã¾ã›ã‚“ã§ã—ãŸ"), gr.Textbox(value="")
                                        return
                                    prompt_text = f"select ai showsql {q}"
                                    gen_stmt = "select dbms_cloud_ai.generate(prompt=> :q, profile_name => :name, action=> :a)"
                                    showsql_stmt = _build_showsql_stmt(q)
                                    try:
                                        cursor.execute(gen_stmt, q=showsql_stmt, name=prof, a="showsql")
                                    except Exception as e:
                                        logger.error(f"_send_feedback generate showsql error: {e}")
                                    try:
                                        cursor.execute(showsql_stmt)
                                    except Exception as e:
                                        logger.error(f"_send_feedback execute showsql error: {e}")
                                    t = str(fb_type or "").lower()
                                    resp = ""
                                    fc = ""
                                    if t == "negative":
                                        resp = str(response_text or "").strip()
                                        fc = str(content_text or "")
                                        if not resp:
                                            yield gr.Markdown(visible=False), gr.Markdown(visible=True, value="âš ï¸ ä¿®æ­£SQLãŒæœªå…¥åŠ›ã®ãŸã‚ã€ãƒã‚¬ãƒ†ã‚£ãƒ–ãƒ»ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’é€ä¿¡ã§ãã¾ã›ã‚“ã§ã—ãŸ"), gr.Textbox(value="")
                                            return
                                    cursor.execute(
                                        """
                                        BEGIN
                                        DBMS_CLOUD_AI.FEEDBACK(
                                            profile_name => :p,
                                            sql_text => :st,
                                            feedback_type => :ft,
                                            response => :resp,
                                            feedback_content => :fc,
                                            operation => 'ADD'
                                        );
                                        END;
                                        """,
                                        p=prof,
                                        st=showsql_stmt,
                                        ft=str(fb_type or "").upper(),
                                        resp=resp,
                                        fc=fc,
                                    )
                                    def _lit(x):
                                        s = str(x or "")
                                        return "'" + s.replace("'", "''") + "'"
                                    plsql = (
                                        "BEGIN\n"
                                        "  DBMS_CLOUD_AI.FEEDBACK(\n"
                                        f"    profile_name => {_lit(prof)},\n"
                                        f"    sql_text => {_lit(showsql_stmt)},\n"
                                        f"    feedback_type => {_lit(str(fb_type or '').upper())},\n"
                                        "    response => " + ("NULL" if not resp else _lit(resp)) + ",\n"
                                        "    feedback_content => " + ("NULL" if not fc else _lit(fc)) + ",\n"
                                        "    operation => 'ADD'\n"
                                        "  );\n"
                                        "END;"
                                    )
                                    yield gr.Markdown(visible=False), gr.Markdown(visible=True, value="âœ… ã‚¯ã‚¨ãƒªã«å¯¾ã™ã‚‹ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’é€ä¿¡ã—ã¾ã—ãŸ"), gr.Textbox(value=plsql)
                        except Exception as e:
                            yield gr.Markdown(visible=False), gr.Markdown(visible=True, value=f"âŒ ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯é€ä¿¡ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}"), gr.Textbox(value=str(e))

                    dev_chat_execute_btn.click(
                        fn=_dev_step_generate,
                        inputs=[dev_profile_select, dev_prompt_input, dev_extra_prompt, dev_include_extra_prompt, dev_enable_query_rewrite, dev_rewritten_query],
                        outputs=[dev_chat_status_md, dev_generated_sql_text],
                    ).then(
                        fn=_dev_step_run_sql,
                        inputs=[dev_profile_select, dev_generated_sql_text],
                        outputs=[dev_chat_status_md, dev_chat_result_df, dev_chat_result_style],
                    )

                    dev_ai_analyze_btn.click(
                        fn=_dev_ai_analyze,
                        inputs=[dev_analysis_model_input, dev_generated_sql_text],
                        outputs=[dev_ai_analyze_status, dev_join_conditions_text, dev_where_conditions_text],
                    )

                    dev_chat_clear_btn.click(
                        fn=_on_dev_chat_clear,
                        outputs=[dev_prompt_input, dev_profile_select],
                    )

                    dev_predict_domain_btn.click(
                        fn=_predict_domain_and_set_profile,
                        inputs=[dev_prompt_input],
                        outputs=[dev_profile_select],
                    )
                    
                    # Queryè»¢å†™ãƒœã‚¿ãƒ³ã®ã‚¤ãƒ™ãƒ³ãƒˆãƒãƒ³ãƒ‰ãƒ©
                    dev_rewrite_btn.click(
                        fn=_dev_rewrite_query,
                        inputs=[dev_rewrite_model_select, dev_profile_select, dev_prompt_input, dev_rewrite_use_glossary, dev_rewrite_use_schema],
                        outputs=[dev_rewrite_status, dev_rewritten_query],
                    )

                with gr.TabItem(label="ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ç®¡ç†") as feedback_tab:
                    def _global_profile_names():
                        try:
                            # JSONãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã‚€
                            return _load_profiles_from_json()
                        except Exception as e:
                            logger.error(f"_global_profile_names error: {e}")
                        return []

                    with gr.Accordion(label="1. ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ä¸€è¦§", open=True):
                        with gr.Row():
                            with gr.Column(scale=5):
                                with gr.Row():
                                    with gr.Column(scale=1):
                                        gr.Markdown("Profile", elem_classes="input-label")
                                    with gr.Column(scale=5):
                                        # ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«é¸æŠè‚¢ã‚’å–å¾—ã—ã€ç©ºã®å ´åˆã¯ç©ºæ–‡å­—åˆ—ã‚’å«ã‚€ãƒªã‚¹ãƒˆã‚’è¨­å®š
                                        _global_initial_choices = _global_profile_names()
                                        if not _global_initial_choices:
                                            _global_initial_choices = [("", "")]
                                        global_profile_select = gr.Dropdown(
                                            show_label=False,
                                            choices=_global_initial_choices,
                                            value=(
                                                _global_initial_choices[0][1]
                                                if (_global_initial_choices and isinstance(_global_initial_choices[0], tuple))
                                                else (_global_initial_choices[0] if _global_initial_choices else "")
                                            ),
                                            interactive=True,
                                            container=False,
                                        )
                            with gr.Column(scale=5):
                                with gr.Row():
                                    with gr.Column(scale=1):
                                        gr.Markdown("")
                        with gr.Row():
                            global_feedback_index_refresh_btn = gr.Button("æœ€æ–°ã‚¨ãƒ³ãƒˆãƒªã‚’å–å¾—", variant="primary")
                        with gr.Row():
                            global_feedback_index_refresh_status = gr.Markdown(visible=False)

                        with gr.Row():
                            global_feedback_index_df = gr.Dataframe(
                                label="ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ç´¢å¼•ã®æœ€æ–°ã‚¨ãƒ³ãƒˆãƒª",
                                interactive=False,
                                wrap=True,
                                visible=False,
                                value=pd.DataFrame(),
                            )

                        with gr.Row():
                            global_feedback_index_info = gr.Markdown(visible=False)

                        with gr.Row():
                            with gr.Column(scale=5):
                                with gr.Row():
                                    with gr.Column(scale=1):
                                        gr.Markdown("é¸æŠã•ã‚ŒãŸSQL_ID", elem_classes="input-label")
                                    with gr.Column(scale=5):
                                        selected_sql_id = gr.Textbox(show_label=False, interactive=False, container=False)
                            with gr.Column(scale=5):
                                with gr.Row():
                                    with gr.Column(scale=1):
                                        selected_feedback_delete_btn = gr.Button("é¸æŠã—ãŸãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’å‰Šé™¤", variant="stop")
                            
                        with gr.Row():
                            with gr.Column(scale=1):
                                gr.Markdown("å‰Šé™¤çµæœ", elem_classes="input-label")
                            with gr.Column(scale=5):
                                selected_feedback_delete_result = gr.Textbox(show_label=False, interactive=False, lines=2, max_lines=5, container=False)

                    with gr.Accordion(label="2. ãƒ™ã‚¯ãƒˆãƒ«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹", open=True):
                        with gr.Row():
                            with gr.Column(scale=5):
                                with gr.Row():
                                    with gr.Column(scale=1):
                                        gr.Markdown("Similarity_Threshold", elem_classes="input-label")
                                    with gr.Column(scale=4):
                                        vec_similarity_threshold_input = gr.Slider(
                                            show_label=False,
                                            minimum=0.10,
                                            maximum=0.95,
                                            step=0.05,
                                            value=0.90,
                                            interactive=True,
                                            container=False,
                                        )
                            with gr.Column(scale=5):
                                with gr.Row():
                                    with gr.Column(scale=1):
                                        gr.Markdown("Match_Limit", elem_classes="input-label")
                                    with gr.Column(scale=4):
                                        vec_match_limit_input = gr.Slider(
                                            show_label=False,
                                            minimum=1,
                                            maximum=5,
                                            step=1,
                                            value=3,
                                            interactive=True,
                                            container=False,
                                        )

                        with gr.Row():
                            vec_update_btn = gr.Button("ãƒ™ã‚¯ãƒˆãƒ«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’æ›´æ–°", variant="primary")

                    def _view_feedback_index_global(profile_name: str):
                        try:
                            yield gr.Markdown(visible=True, value="â³ ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ç´¢å¼•ã‚’å–å¾—ä¸­..."), gr.Dataframe(visible=False, value=pd.DataFrame()), gr.Markdown(visible=False)
                            with pool.acquire() as conn:
                                with conn.cursor() as cursor:
                                    prof = _resolve_profile_name(pool, str(profile_name or ""))
                                    tab = f"{str(prof).upper()}_FEEDBACK_VECINDEX$VECTAB"
                                    q_no_ctx = (
                                        f'SELECT CONTENT, '
                                        f"JSON_VALUE(ATTRIBUTES, '$.sql_id' RETURNING VARCHAR2(128)) AS SQL_ID, "
                                        f'ATTRIBUTES FROM "{tab}" FETCH FIRST 50 ROWS ONLY'
                                    )
                                    rows = []
                                    cols = []
                                    cursor.execute(q_no_ctx)
                                    rows = cursor.fetchall() or []
                                    cols = [d[0] for d in cursor.description] if cursor.description else []
                                    def _to_plain(val):
                                        v = val.read() if hasattr(val, "read") else val
                                        if isinstance(v, bytes):
                                            try:
                                                v = v.decode("utf-8")
                                            except Exception:
                                                v = v.decode("latin1", errors="ignore")
                                        s = v
                                        if not isinstance(s, str):
                                            s = str(s)
                                        t = s.strip()
                                        if (t.startswith("{") and t.endswith("}")) or (t.startswith("[") and t.endswith("]")):
                                            try:
                                                obj = json.loads(t)
                                                s = json.dumps(obj, ensure_ascii=False)
                                            except Exception:
                                                pass
                                        return s

                                    cleaned_rows = []
                                    for r in rows:
                                        cleaned_rows.append([_to_plain(v) for v in r])
                                    df = pd.DataFrame(cleaned_rows, columns=cols)
                                    if df.empty:
                                        yield gr.Markdown(visible=False), gr.Dataframe(visible=False, value=pd.DataFrame()), gr.Markdown(visible=True, value="â„¹ï¸ ã¾ã ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ç´¢å¼•ãŒã‚ã‚Šã¾ã›ã‚“")
                                        return
                                    yield gr.Markdown(visible=False), gr.Dataframe(visible=True, value=df), gr.Markdown(visible=False)
                        except Exception as e:
                            logger.error(f"_view_feedback_index_global error: {e}")
                            yield gr.Markdown(visible=False), gr.Dataframe(visible=False, value=pd.DataFrame()), gr.Markdown(visible=True, value="â„¹ï¸ ã¾ã ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ç´¢å¼•ãŒã‚ã‚Šã¾ã›ã‚“")

                    def _on_profile_select_change(profile_name: str):
                        try:
                            return (
                                gr.Dataframe(visible=False, value=pd.DataFrame()),
                                gr.Markdown(visible=True, value="â„¹ï¸ Profileé¸æŠå¾Œã¯ã€æœ€æ–°ã‚¨ãƒ³ãƒˆãƒªã‚’å–å¾—ã€ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ãã ã•ã„"),
                            )
                        except Exception:
                            return (
                                gr.Dataframe(visible=False, value=pd.DataFrame()),
                                gr.Markdown(visible=True, value="â„¹ï¸ Profileé¸æŠå¾Œã¯ã€æœ€æ–°ã‚¨ãƒ³ãƒˆãƒªã‚’å–å¾—ã€ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ãã ã•ã„"),
                            )

                    global_profile_select.change(
                        fn=_on_profile_select_change,
                        inputs=[global_profile_select],
                        outputs=[global_feedback_index_df, global_feedback_index_info],
                    )

                    global_feedback_index_refresh_btn.click(
                        fn=_view_feedback_index_global,
                        inputs=[global_profile_select],
                        outputs=[global_feedback_index_refresh_status, global_feedback_index_df, global_feedback_index_info],
                    )

                    def on_index_row_select(evt: gr.SelectData, current_df):
                        try:
                            row_index = evt.index[0]
                            df = current_df
                            if isinstance(df, dict) and "data" in df:
                                df = pd.DataFrame(df["data"], columns=df.get("headers", []))
                            if isinstance(df, pd.DataFrame) and not df.empty and row_index >= 0:
                                row = df.iloc[row_index]
                                sql_id = str(row.get("SQL_ID", ""))
                                return sql_id
                        except Exception as e:
                            logger.error(f"on_index_row_select error: {e}")
                        return ""

                    global_feedback_index_df.select(
                        fn=on_index_row_select,
                        inputs=[global_feedback_index_df],
                        outputs=[selected_sql_id],
                    )

                    def _delete_by_sql_id(profile_name: str, sql_id: str):
                        try:
                            if not sql_id:
                                return _view_feedback_index_global(profile_name)[0], "âŒ å¤±æ•—: SQL_IDãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“"
                            with pool.acquire() as conn:
                                with conn.cursor() as cursor:
                                    prof = _resolve_profile_name(pool, str(profile_name or ""))
                                    cursor.execute(
                                        """
                                        BEGIN
                                        DBMS_CLOUD_AI.FEEDBACK(
                                            profile_name => :p,
                                            sql_id => :sid,
                                            operation => 'DELETE'
                                        );
                                        END;
                                        """,
                                        p=str(prof),
                                        sid=str(sql_id),
                                    )
                            return _view_feedback_index_global(profile_name)[0], "âœ… æˆåŠŸ"
                        except Exception as e:
                            return gr.Dataframe(visible=False, value=pd.DataFrame()), f"âŒ å¤±æ•—: {str(e)}"

                    selected_feedback_delete_btn.click(
                        fn=_delete_by_sql_id,
                        inputs=[global_profile_select, selected_sql_id],
                        outputs=[global_feedback_index_df, selected_feedback_delete_result],
                    )

                    def _update_vector_index(profile_name: str, similarity_threshold: float, match_limit: int):
                        try:
                            prof = _resolve_profile_name(pool, str(profile_name or ""))
                            idx_name = f"{str(prof).upper()}_FEEDBACK_VECINDEX"
                            tab_name = f"{str(prof).upper()}_FEEDBACK_VECINDEX$VECTAB"
                            logger.info(f"Update vector index: profile={profile_name}, index={idx_name}, table={tab_name}, threshold={similarity_threshold}, limit={match_limit}")
                            with pool.acquire() as conn:
                                with conn.cursor() as cursor:
                                    # Verify index table exists
                                    try:
                                        cursor.execute(f'SELECT 1 FROM "{tab_name}" FETCH FIRST 1 ROWS ONLY')
                                        _ = cursor.fetchall()
                                    except Exception as e:
                                        logger.error(f"Index table not found: {tab_name}: {e}")
                                        return gr.Dataframe(visible=False, value=pd.DataFrame()), gr.Markdown(visible=True, value=f"âŒ ç´¢å¼•ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {tab_name}")

                                    vec_attrs = json.dumps({
                                        "similarity_threshold": float(similarity_threshold),
                                        "match_limit": int(match_limit),
                                    }, ensure_ascii=False)
                                    logger.info(f"Calling UPDATE_VECTOR_INDEX with attrs={vec_attrs}")
                                    try:
                                        cursor.execute(
                                            """
                                            BEGIN
                                            DBMS_CLOUD_AI.UPDATE_VECTOR_INDEX(
                                                index_name => :idx,
                                                attributes => :vattrs
                                            );
                                            END;
                                            """,
                                            idx=idx_name,
                                            vattrs=vec_attrs,
                                        )
                                    except Exception as e:
                                        logger.error(f"UPDATE_VECTOR_INDEX failed: index={idx_name}, table={tab_name}, error={e}")
                                        return gr.Dataframe(visible=False, value=pd.DataFrame()), gr.Markdown(visible=True, value=f"âŒ æ›´æ–°ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
                                    logger.info("UPDATE_VECTOR_INDEX succeeded")
                                    return _view_feedback_index_global(profile_name)
                        except Exception as e:
                            logger.error(f"Unexpected error in _update_vector_index: {e}")
                            return gr.Dataframe(visible=False, value=pd.DataFrame()), gr.Markdown(visible=True, value=f"âŒ æ›´æ–°ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")

                    vec_update_btn.click(
                        fn=_update_vector_index,
                        inputs=[global_profile_select, vec_similarity_threshold_input, vec_match_limit_input],
                        outputs=[global_feedback_index_df, global_feedback_index_info],
                    )

                with gr.TabItem(label="ã‚³ãƒ¡ãƒ³ãƒˆç®¡ç†"):
                    with gr.Accordion(label="1. ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆé¸æŠ", open=True):
                        with gr.Row():
                            with gr.Column():                        
                                cm_refresh_btn = gr.Button("ãƒ†ãƒ¼ãƒ–ãƒ«ãƒ»ãƒ“ãƒ¥ãƒ¼ä¸€è¦§ã‚’å–å¾—", variant="primary")
                        with gr.Row():
                            with gr.Column():
                                cm_refresh_status = gr.Markdown(visible=False)
                        with gr.Row():
                            with gr.Column():
                                gr.Markdown("###### ãƒ†ãƒ¼ãƒ–ãƒ«é¸æŠ")
                                cm_tables_input = gr.CheckboxGroup(label="ãƒ†ãƒ¼ãƒ–ãƒ«é¸æŠ", show_label=False, choices=[], visible=False)
                            with gr.Column():
                                gr.Markdown("###### ãƒ“ãƒ¥ãƒ¼é¸æŠ")
                                cm_views_input = gr.CheckboxGroup(label="ãƒ“ãƒ¥ãƒ¼é¸æŠ", show_label=False, choices=[], visible=False)
                        with gr.Row():
                            with gr.Column(scale=5):
                                with gr.Row():
                                    with gr.Column(scale=1):
                                        gr.Markdown("ã‚µãƒ³ãƒ—ãƒ«ä»¶æ•°", elem_classes="input-label")
                                    with gr.Column(scale=5):
                                        cm_sample_limit = gr.Number(show_label=False, minimum=0, maximum=100, value=10, interactive=True, container=False)
                            with gr.Column(scale=5):
                                with gr.Row():
                                    with gr.Column(scale=1):
                                        gr.Markdown("")
                        with gr.Row():
                            with gr.Column():
                                cm_fetch_btn = gr.Button("æƒ…å ±ã‚’å–å¾—", variant="primary")

                    with gr.Accordion(label="2. å…¥åŠ›ç¢ºèª", open=False):
                        with gr.Row():
                            with gr.Column(scale=1):
                                gr.Markdown("æ§‹é€ æƒ…å ±", elem_classes="input-label")
                            with gr.Column(scale=5):
                                cm_structure_text = gr.Textbox(show_label=False, lines=8, max_lines=16, interactive=True, show_copy_button=True, container=False)
                        with gr.Row():
                            with gr.Column(scale=1):
                                gr.Markdown("ä¸»ã‚­ãƒ¼æƒ…å ±", elem_classes="input-label")
                            with gr.Column(scale=5):
                                cm_pk_text = gr.Textbox(show_label=False, lines=4, max_lines=10, interactive=True, show_copy_button=True, container=False)    
                        with gr.Row():
                            with gr.Column(scale=1):
                                gr.Markdown("å¤–éƒ¨ã‚­ãƒ¼æƒ…å ±", elem_classes="input-label")
                            with gr.Column(scale=5):
                                cm_fk_text = gr.Textbox(show_label=False, lines=6, max_lines=14, interactive=True, show_copy_button=True, container=False)
                        with gr.Row():
                            with gr.Column(scale=1):
                                gr.Markdown("ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿", elem_classes="input-label")
                            with gr.Column(scale=5):
                                cm_samples_text = gr.Textbox(show_label=False, lines=8, max_lines=16, interactive=True, show_copy_button=True, container=False)
                        with gr.Row():
                            with gr.Column(scale=1):
                                gr.Markdown("è¿½åŠ å…¥åŠ›(Optional)", elem_classes="input-label")
                            with gr.Column(scale=5):
                                cm_extra_input = gr.Textbox(
                                    show_label=False,
                                    placeholder="è¿½åŠ ã§è€ƒæ…®ã—ã¦ã»ã—ã„èª¬æ˜ã‚„æ¡ä»¶ã‚’è¨˜å…¥",
                                    value=(""),
                                    lines=8,
                                    max_lines=16,
                                    container=False,
                                )

                    with gr.Accordion(label="3. ã‚³ãƒ¡ãƒ³ãƒˆè‡ªå‹•ç”Ÿæˆ", open=False):
                        with gr.Row():
                            with gr.Column(scale=5):
                                with gr.Row():
                                    with gr.Column(scale=1):
                                        gr.Markdown("ãƒ¢ãƒ‡ãƒ«", elem_classes="input-label")
                                    with gr.Column(scale=5):
                                        cm_model_input = gr.Dropdown(
                                            show_label=False,
                                            choices=[
                                                "xai.grok-code-fast-1",
                                                "xai.grok-3",
                                                "xai.grok-3-fast",
                                                "xai.grok-4",
                                                "xai.grok-4-fast-non-reasoning",
                                                "meta.llama-4-scout-17b-16e-instruct",
                                                "gpt-4o",
                                                "gpt-5.1",
                                            ],
                                            value="xai.grok-code-fast-1",
                                            interactive=True,
                                            container=False,
                                        )
                            with gr.Column(scale=5):
                                with gr.Row():
                                    with gr.Column(scale=1):
                                        cm_generate_btn = gr.Button("ç”Ÿæˆ", variant="primary")
                        with gr.Row():
                            with gr.Column(scale=1):
                                gr.Markdown("ç”Ÿæˆã•ã‚ŒãŸSQLæ–‡", elem_classes="input-label")
                            with gr.Column(scale=5):
                                cm_generated_sql = gr.Textbox(show_label=False, lines=15, max_lines=15, interactive=True, show_copy_button=True, container=False)

                    with gr.Accordion(label="4. å®Ÿè¡Œ", open=False):
                        cm_execute_btn = gr.Button("ä¸€æ‹¬å®Ÿè¡Œ", variant="primary")
                        with gr.Row():
                            with gr.Column(scale=1):
                                gr.Markdown("å®Ÿè¡Œçµæœ", elem_classes="input-label")
                            with gr.Column(scale=5):
                                cm_execute_result = gr.Textbox(show_label=False, interactive=False, lines=5, max_lines=8, container=False)

                        with gr.Accordion(label="AIåˆ†æã¨å‡¦ç†", open=True):
                            with gr.Row():
                                with gr.Column(scale=5):
                                    with gr.Row():
                                        with gr.Column(scale=1):
                                            gr.Markdown("ãƒ¢ãƒ‡ãƒ«", elem_classes="input-label")
                                        with gr.Column(scale=5):
                                            cm_ai_model_input = gr.Dropdown(
                                                show_label=False,
                                                choices=[
                                                    "xai.grok-code-fast-1",
                                                    "xai.grok-3",
                                                    "xai.grok-3-fast",
                                                    "xai.grok-4",
                                                    "xai.grok-4-fast-non-reasoning",
                                                    "meta.llama-4-scout-17b-16e-instruct",
                                                ],
                                                value="xai.grok-code-fast-1",
                                                interactive=True,
                                                container=False,
                                            )
                                with gr.Column(scale=5):
                                    with gr.Row():
                                        with gr.Column(scale=1):
                                            cm_ai_analyze_btn = gr.Button("AIåˆ†æ", variant="primary")
                            with gr.Row():
                                cm_ai_status_md = gr.Markdown(visible=False)
                            with gr.Row():
                                cm_ai_result_md = gr.Markdown(visible=False)

                    def _cm_refresh_objects():
                        try:
                            yield gr.Markdown(visible=True, value="â³ ãƒ†ãƒ¼ãƒ–ãƒ«ãƒ»ãƒ“ãƒ¥ãƒ¼ä¸€è¦§ã‚’å–å¾—ä¸­..."), gr.CheckboxGroup(visible=False, choices=[]), gr.CheckboxGroup(visible=False, choices=[])
                            df_tab = _get_table_df_cached(pool, force=True)
                            df_view = _get_view_df_cached(pool, force=True)
                            names = []
                            if not df_tab.empty and "Table Name" in df_tab.columns:
                                names.extend([str(x) for x in df_tab["Table Name"].tolist()])
                            if not df_view.empty and "View Name" in df_view.columns:
                                names.extend([str(x) for x in df_view["View Name"].tolist()])
                            table_names = sorted(set([str(x) for x in (df_tab["Table Name"].tolist() if (not df_tab.empty and "Table Name" in df_tab.columns) else [])]))
                            view_names = sorted(set([str(x) for x in (df_view["View Name"].tolist() if (not df_view.empty and "View Name" in df_view.columns) else [])]))
                            yield gr.Markdown(visible=True, value="âœ… å–å¾—å®Œäº†"), gr.CheckboxGroup(choices=table_names, visible=True), gr.CheckboxGroup(choices=view_names, visible=True)
                        except Exception as e:
                            logger.error(f"_cm_refresh_objects error: {e}")
                            yield gr.Markdown(visible=True, value=f"âŒ å¤±æ•—: {e}"), gr.CheckboxGroup(choices=[]), gr.CheckboxGroup(choices=[])

                    def _cm_build_prompt(struct_text, pk_text, fk_text, samples_text, extra_text):
                        try:
                            prompt = (
                                "ã‚ãªãŸã¯Oracleãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å°‚é–€å®¶ã§ã™ã€‚ä»¥ä¸‹ã®æƒ…å ±ã«åŸºã¥ãã€COMMENTæ–‡ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚\n"
                                "å‡ºåŠ›ã¯SQLã®COMMENTæ–‡ã®ã¿ã€‚\n"
                                "è¡¨ãƒ»ãƒ“ãƒ¥ãƒ¼ã¯A-Zã®é †ã§ã€åˆ—ã¯CREATEæ–‡ã®å®šç¾©é †ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚\n\n"
                                "<æ§‹é€ >\n" + str(struct_text or "") + "\n\n"
                                "<ä¸»ã‚­ãƒ¼>\n" + str(pk_text or "") + "\n\n"
                                "<å¤–éƒ¨ã‚­ãƒ¼>\n" + str(fk_text or "") + "\n\n"
                                "<ã‚µãƒ³ãƒ—ãƒ«>\n" + str(samples_text or "") + "\n\n"
                                + (str(extra_text or "") if extra_text else "")
                            )
                            return prompt
                        except Exception as e:
                            logger.error(f"_cm_build_prompt error: {e}")
                            return str(e)

                    async def _cm_generate_async(obj_name, model_name, extra_text, struct_text, pk_text, fk_text, samples_text):
                        try:
                            prompt = _cm_build_prompt(struct_text, pk_text, fk_text, samples_text, extra_text)
                            from utils.chat_util import get_oci_region, get_compartment_id
                            region = get_oci_region()
                            compartment_id = get_compartment_id()
                            if not region or not compartment_id:
                                return gr.Textbox(value="â„¹ï¸ OCIè¨­å®šãŒä¸è¶³ã—ã¦ã„ã¾ã™")
                            from oci_openai import AsyncOciOpenAI, OciUserPrincipalAuth
                            client = AsyncOciOpenAI(
                                service_endpoint=f"https://inference.generativeai.{region}.oci.oraclecloud.com",
                                auth=OciUserPrincipalAuth(),
                                compartment_id=compartment_id,
                            )
                            messages = [
                                {"role": "system", "content": "Oracleã®COMMENTæ–‡ã®ã¿ã‚’å‡ºåŠ›ã€‚èª¬æ˜æ–‡ã¯200å­—ä»¥å†…ã€‚"},
                                {"role": "user", "content": prompt},
                            ]
                            resp = await client.chat.completions.create(model=model_name, messages=messages)
                            text = ""
                            if resp.choices and len(resp.choices) > 0:
                                msg = resp.choices[0].message
                                text = msg.content if hasattr(msg, 'content') else ''
                            return gr.Textbox(value=text)
                        except Exception as e:
                            logger.error(f"_cm_generate_async error: {e}")
                            return gr.Textbox(value=f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")

                    def _cm_generate(obj_name, model_name, extra_text, struct_text, pk_text, fk_text, samples_text):
                        loop = asyncio.new_event_loop()
                        asyncio.set_event_loop(loop)
                        try:
                            result = loop.run_until_complete(_cm_generate_async(obj_name, model_name, extra_text, struct_text, pk_text, fk_text, samples_text))
                            return result
                        finally:
                            loop.close()

                    def _cm_execute(sql_text):
                        from utils.management_util import execute_comment_sql
                        return execute_comment_sql(pool, sql_text)

                    async def _cm_ai_analyze_async(model_name, sql_text, exec_result_text):
                        from utils.chat_util import get_oci_region, get_compartment_id
                        region = get_oci_region()
                        compartment_id = get_compartment_id()
                        if not region or not compartment_id:
                            return gr.Markdown(visible=True, value="â„¹ï¸ OCIè¨­å®šãŒä¸è¶³ã—ã¦ã„ã¾ã™")
                        try:
                            from oci_openai import AsyncOciOpenAI, OciUserPrincipalAuth
                            s = str(sql_text or "").strip()
                            r = str(exec_result_text or "").strip()
                            prompt = (
                                "ä»¥ä¸‹ã®COMMENTæ–‡ã®ä¸€æ‹¬å®Ÿè¡Œå†…å®¹ã¨å®Ÿè¡Œçµæœã‚’åˆ†æã—ã¦ãã ã•ã„ã€‚å‡ºåŠ›ã¯æ¬¡ã®3ç‚¹ã«é™å®šã—ã¾ã™ã€‚\n"
                                "1) ã‚¨ãƒ©ãƒ¼åŸå› ï¼ˆè©²å½“ã™ã‚‹å ´åˆï¼‰\n"
                                "2) è§£æ±ºæ–¹æ³•ï¼ˆä¿®æ­£æ¡ˆã‚„å…·ä½“çš„æ‰‹é †ï¼‰\n"
                                "3) ç°¡æ½”ãªçµè«–\n\n"
                                + ("SQL:\n```sql\n" + s + "\n```\n" if s else "")
                                + ("å®Ÿè¡Œçµæœ:\n" + r + "\n" if r else "")
                            )
                            client = AsyncOciOpenAI(
                                service_endpoint=f"https://inference.generativeai.{region}.oci.oraclecloud.com",
                                auth=OciUserPrincipalAuth(),
                                compartment_id=compartment_id,
                            )
                            messages = [
                                {"role": "system", "content": "ã‚ãªãŸã¯ã‚·ãƒ‹ã‚¢DBã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã§ã™ã€‚COMMENT ON TABLE/COLUMN ã®è¨ºæ–­ã«ç‰¹åŒ–ã—ã€å¿…è¦æœ€å°é™ã®è¦ç‚¹ã®ã¿ã‚’ç°¡æ½”ã«æç¤ºã—ã¦ãã ã•ã„ã€‚"},
                                {"role": "user", "content": prompt},
                            ]
                            resp = await client.chat.completions.create(model=model_name, messages=messages)
                            text = ""
                            if getattr(resp, "choices", None):
                                msg = resp.choices[0].message
                                text = msg.content if hasattr(msg, "content") else ""
                            return gr.Markdown(visible=True, value=text or "åˆ†æçµæœãŒç©ºã§ã™")
                        except Exception as e:
                            return gr.Markdown(visible=True, value=f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")

                    def _cm_ai_analyze(model_name, sql_text, exec_result_text):
                        import asyncio
                        # å¿…é ˆå…¥åŠ›é …ç›®ã®ãƒã‚§ãƒƒã‚¯
                        if not model_name or not str(model_name).strip():
                            yield gr.Markdown(visible=True, value="âš ï¸ ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„"), gr.Markdown(visible=False)
                            return
                        if not sql_text or not str(sql_text).strip():
                            yield gr.Markdown(visible=True, value="âš ï¸ SQLæ–‡ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„"), gr.Markdown(visible=False)
                            return
                        if not exec_result_text or not str(exec_result_text).strip():
                            yield gr.Markdown(visible=True, value="âš ï¸ å®Ÿè¡ŒçµæœãŒã‚ã‚Šã¾ã›ã‚“ã€‚å…ˆã«ä¸€æ‹¬å®Ÿè¡Œã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„"), gr.Markdown(visible=False)
                            return
                        
                        loop = asyncio.new_event_loop()
                        asyncio.set_event_loop(loop)
                        try:
                            yield gr.Markdown(visible=True, value="â³ AIåˆ†æã‚’å®Ÿè¡Œä¸­..."), gr.Markdown(visible=False)
                            result_md = loop.run_until_complete(_cm_ai_analyze_async(model_name, sql_text, exec_result_text))
                            yield gr.Markdown(visible=True, value="âœ… å®Œäº†"), result_md
                        except Exception as e:
                            yield gr.Markdown(visible=True, value=f"âŒ ã‚¨ãƒ©ãƒ¼: {e}"), gr.Markdown(visible=False)
                        finally:
                            loop.close()

                    cm_refresh_btn.click(
                        fn=_cm_refresh_objects,
                        outputs=[cm_refresh_status, cm_tables_input, cm_views_input],
                    )

                    def _cm_fetch_structure(tables_selected, views_selected):
                        tables_selected = tables_selected or []
                        views_selected = views_selected or []
                        targets = []
                        targets.extend([("TABLE", t) for t in tables_selected])
                        targets.extend([("VIEW", v) for v in views_selected])
                        if not targets:
                            return gr.Textbox(value="", interactive=True)
                        struct_chunks = []
                        for kind, name in targets:
                            if kind == "VIEW":
                                cols_df, _ddl = get_view_details(pool, name)
                            else:
                                cols_df, _ddl = get_table_details(pool, name)
                            lines = [f"OBJECT: {name}", "COLUMNS:"]
                            if isinstance(cols_df, pd.DataFrame) and not cols_df.empty:
                                for _, row in cols_df.iterrows():
                                    lines.append(f"- {row['Column Name']}: {row['Data Type']} NULLABLE={row['Nullable']}")
                            struct_chunks.append("\n".join(lines))
                        struct_text = "\n\n".join(struct_chunks)
                        return gr.Textbox(value=struct_text, interactive=True)

                    def _cm_fetch_pk(tables_selected, views_selected):
                        tables_selected = tables_selected or []
                        views_selected = views_selected or []
                        targets = []
                        targets.extend([("TABLE", t) for t in tables_selected])
                        targets.extend([("VIEW", v) for v in views_selected])
                        if not targets:
                            return gr.Textbox(value="", interactive=True)
                        from utils.management_util import get_primary_key_info
                        pk_chunks = []
                        for _kind, name in targets:
                            pk_info = get_primary_key_info(pool, name) or ""
                            if pk_info:
                                pk_chunks.append(f"OBJECT: {name}\n{pk_info}")
                        pk_text = "\n\n".join(pk_chunks) if pk_chunks else ""
                        return gr.Textbox(value=pk_text, interactive=True)

                    def _cm_fetch_fk(tables_selected, views_selected):
                        tables_selected = tables_selected or []
                        views_selected = views_selected or []
                        targets = []
                        targets.extend([("TABLE", t) for t in tables_selected])
                        targets.extend([("VIEW", v) for v in views_selected])
                        if not targets:
                            return gr.Textbox(value="", interactive=True)
                        from utils.management_util import get_foreign_key_info
                        fk_chunks = []
                        for _kind, name in targets:
                            fk_info = get_foreign_key_info(pool, name) or ""
                            if fk_info:
                                fk_chunks.append(f"OBJECT: {name}\n{fk_info}")
                        fk_text = "\n\n".join(fk_chunks) if fk_chunks else ""
                        return gr.Textbox(value=fk_text, interactive=True)

                    def _cm_fetch_samples(tables_selected, views_selected, sample_limit):
                        tables_selected = tables_selected or []
                        views_selected = views_selected or []
                        targets = []
                        targets.extend([("TABLE", t) for t in tables_selected])
                        targets.extend([("VIEW", v) for v in views_selected])
                        if not targets:
                            return gr.Textbox(value="", interactive=True)
                        from utils.management_util import display_table_data
                        lim = int(sample_limit)
                        samples_chunks = []
                        if lim > 0:
                            for _kind, name in targets:
                                df = display_table_data(pool, name, lim)
                                if isinstance(df, pd.DataFrame) and not df.empty:
                                    samples_chunks.append(f"OBJECT: {name}\n" + df.to_csv(index=False))
                        samples_text = "\n\n".join(samples_chunks) if samples_chunks else ""
                        return gr.Textbox(value=samples_text, interactive=True)

                    cm_fetch_btn.click(
                        fn=_cm_fetch_structure,
                        inputs=[cm_tables_input, cm_views_input],
                        outputs=[cm_structure_text],
                    ).then(
                        fn=_cm_fetch_pk,
                        inputs=[cm_tables_input, cm_views_input],
                        outputs=[cm_pk_text],
                    ).then(
                        fn=_cm_fetch_fk,
                        inputs=[cm_tables_input, cm_views_input],
                        outputs=[cm_fk_text],
                    ).then(
                        fn=_cm_fetch_samples,
                        inputs=[cm_tables_input, cm_views_input, cm_sample_limit],
                        outputs=[cm_samples_text],
                    )

                    cm_generate_btn.click(
                        fn=_cm_generate,
                        inputs=[cm_tables_input, cm_model_input, cm_extra_input, cm_structure_text, cm_pk_text, cm_fk_text, cm_samples_text],
                        outputs=[cm_generated_sql],
                    )

                    cm_execute_btn.click(
                        fn=_cm_execute,
                        inputs=[cm_generated_sql],
                        outputs=[cm_execute_result],
                    )

                    cm_ai_analyze_btn.click(
                        fn=_cm_ai_analyze,
                        inputs=[cm_ai_model_input, cm_generated_sql, cm_execute_result],
                        outputs=[cm_ai_status_md, cm_ai_result_md],
                    )

                    def _on_feedback_type_change(fb_type):
                        t = str(fb_type or "").lower()
                        if t == "positive":
                            return gr.Textbox(value="", interactive=False), gr.Textbox(value="", interactive=False)
                        return gr.Textbox(interactive=True), gr.Textbox(interactive=True)

                    dev_feedback_type_select.change(
                        fn=_on_feedback_type_change,
                        inputs=[dev_feedback_type_select],
                        outputs=[dev_feedback_response_text, dev_feedback_content_text],
                    )

                    dev_feedback_send_btn.click(
                        fn=_send_feedback,
                        inputs=[dev_feedback_type_select, dev_feedback_response_text, dev_feedback_content_text, dev_prompt_input, dev_profile_select],
                        outputs=[dev_feedback_status, dev_feedback_result, dev_feedback_used_sql_text],
                    )

                with gr.TabItem(label="ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ç®¡ç†"):
                    with gr.Accordion(label="1. ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆé¸æŠ", open=True):
                        with gr.Row():
                            am_refresh_btn = gr.Button("ãƒ†ãƒ¼ãƒ–ãƒ«ãƒ»ãƒ“ãƒ¥ãƒ¼ä¸€è¦§ã‚’å–å¾—", variant="primary")
                        with gr.Row():
                            am_refresh_status = gr.Markdown(visible=False)
                        with gr.Row():
                            with gr.Column():
                                gr.Markdown("###### ãƒ†ãƒ¼ãƒ–ãƒ«é¸æŠ")
                                am_tables_input = gr.CheckboxGroup(label="ãƒ†ãƒ¼ãƒ–ãƒ«é¸æŠ", show_label=False, choices=[], visible=False)
                            with gr.Column():
                                gr.Markdown("###### ãƒ“ãƒ¥ãƒ¼é¸æŠ")
                                am_views_input = gr.CheckboxGroup(label="ãƒ“ãƒ¥ãƒ¼é¸æŠ", show_label=False, choices=[], visible=False)
                        with gr.Row():
                            with gr.Column(scale=5):
                                with gr.Row():
                                    with gr.Column(scale=1):
                                        gr.Markdown("ã‚µãƒ³ãƒ—ãƒ«ä»¶æ•°", elem_classes="input-label")
                                    with gr.Column(scale=5):
                                        am_sample_limit = gr.Number(show_label=False, minimum=0, maximum=100, value=10, interactive=True, container=False)
                            with gr.Column(scale=5):
                                with gr.Row():
                                    with gr.Column(scale=1):
                                        gr.Markdown("")
                        with gr.Row():
                            with gr.Column():
                                am_fetch_btn = gr.Button("æƒ…å ±ã‚’å–å¾—", variant="primary")

                    with gr.Accordion(label="2. å…¥åŠ›ç¢ºèª", open=False):
                        with gr.Row():
                            with gr.Column(scale=1):
                                gr.Markdown("æ§‹é€ æƒ…å ±", elem_classes="input-label")
                            with gr.Column(scale=5):
                                am_structure_text = gr.Textbox(show_label=False, lines=8, max_lines=16, interactive=True, show_copy_button=True, container=False)
                        with gr.Row():
                            with gr.Column(scale=1):
                                gr.Markdown("ä¸»ã‚­ãƒ¼æƒ…å ±", elem_classes="input-label")
                            with gr.Column(scale=5):
                                am_pk_text = gr.Textbox(show_label=False, lines=4, max_lines=10, interactive=True, show_copy_button=True, container=False)
                        with gr.Row():
                            with gr.Column(scale=1):
                                gr.Markdown("å¤–éƒ¨ã‚­ãƒ¼æƒ…å ±", elem_classes="input-label")
                            with gr.Column(scale=5):
                                am_fk_text = gr.Textbox(show_label=False, lines=6, max_lines=14, interactive=True, show_copy_button=True, container=False)
                        with gr.Row():
                            with gr.Column(scale=1):
                                gr.Markdown("ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿", elem_classes="input-label")
                            with gr.Column(scale=5):
                                am_samples_text = gr.Textbox(show_label=False, lines=8, max_lines=16, interactive=True, show_copy_button=True, container=False)
                        with gr.Row():
                            with gr.Column(scale=1):
                                gr.Markdown("è¿½åŠ å…¥åŠ›(Optional)", elem_classes="input-label")
                            with gr.Column(scale=5):
                                am_extra_input = gr.Textbox(
                                    show_label=False,
                                    placeholder="è¿½åŠ ã§è€ƒæ…®ã—ã¦ã»ã—ã„èª¬æ˜ã‚„æ¡ä»¶ã‚’è¨˜å…¥",
                                    value=(
                                        "ANNOTATIONSã®å®‰å…¨ãªé©ç”¨ã‚¬ã‚¤ãƒ‰:\n"
                                        "- DROPã¨ADDã¯åŒä¸€æ–‡ã§æ··åœ¨ã•ã›ãšã€åˆ¥ã€…ã®ALTERæ–‡ã«åˆ†å‰²\n"
                                        "- ä¸€æ‹¬å®Ÿè¡Œã§ã¯é‡è¤‡å(DROP/ADDåŒæ™‚æŒ‡å®š)ãŒORA-11562ã®åŸå› ã€é †æ¬¡å€‹åˆ¥ã«å®Ÿè¡Œ\n"
                                        "- å¯èƒ½ãªã‚‰DROPå¾Œã¯ADD IF NOT EXISTSã§å†è¿½åŠ ã€é‡è¤‡ã‚’å›é¿\n"
                                        "- å€¤ã®'ã¯''ã¸ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ã€äºˆç´„èª/ç©ºç™½ã¯æ³¨é‡ˆåã‚’äºŒé‡å¼•ç”¨ç¬¦\n"
                                        "ä¾‹(è¡¨): ALTER TABLE USERS ANNOTATIONS (DROP IF EXISTS sample_header);\n"
                                        "ä¾‹(åˆ—): ALTER TABLE USERS MODIFY (ID ANNOTATIONS (ADD IF NOT EXISTS ui_display 'ID'));\n"
                                        "å†è¿½åŠ ä¾‹: ALTER TABLE USERS ANNOTATIONS (ADD sample_data 'value');\n"
                                    ),
                                    lines=8,
                                    max_lines=16,
                                    container=False,
                                )

                    with gr.Accordion(label="3. ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³è‡ªå‹•ç”Ÿæˆ", open=False):
                        with gr.Row():
                            with gr.Column(scale=5):
                                with gr.Row():
                                    with gr.Column(scale=1):
                                        gr.Markdown("ãƒ¢ãƒ‡ãƒ«", elem_classes="input-label")
                                    with gr.Column(scale=5):
                                        am_model_input = gr.Dropdown(
                                            show_label=False,
                                            choices=[
                                                "xai.grok-code-fast-1",
                                                "xai.grok-3",
                                                "xai.grok-3-fast",
                                                "xai.grok-4",
                                                "xai.grok-4-fast-non-reasoning",
                                                "meta.llama-4-scout-17b-16e-instruct",
                                                "gpt-4o",
                                                "gpt-5.1",
                                            ],
                                            value="xai.grok-code-fast-1",
                                            interactive=True,
                                            container=False,
                                        )
                            with gr.Column(scale=5):
                                with gr.Row():
                                    with gr.Column(scale=1):
                                        am_generate_btn = gr.Button("ç”Ÿæˆ", variant="primary")
                        with gr.Row():
                            with gr.Column(scale=1):
                                gr.Markdown("ç”Ÿæˆã•ã‚ŒãŸSQLæ–‡", elem_classes="input-label")
                            with gr.Column(scale=5):
                                am_generated_sql = gr.Textbox(show_label=False, lines=15, max_lines=15, interactive=True, show_copy_button=True, container=False)

                    with gr.Accordion(label="4. å®Ÿè¡Œ", open=False):
                        am_execute_btn = gr.Button("ä¸€æ‹¬å®Ÿè¡Œ", variant="primary")
                        with gr.Row():
                            with gr.Column(scale=1):
                                gr.Markdown("å®Ÿè¡Œçµæœ", elem_classes="input-label")
                            with gr.Column(scale=5):
                                am_execute_result = gr.Textbox(show_label=False, interactive=False, lines=5, max_lines=8, container=False)

                        with gr.Accordion(label="AIåˆ†æã¨å‡¦ç†", open=True):
                            with gr.Row():
                                with gr.Column(scale=5):
                                    with gr.Row():
                                        with gr.Column(scale=1):
                                            gr.Markdown("ãƒ¢ãƒ‡ãƒ«", elem_classes="input-label")
                                        with gr.Column(scale=5):
                                            am_ai_model_input = gr.Dropdown(
                                                show_label=False,
                                                choices=[
                                                    "xai.grok-code-fast-1",
                                                    "xai.grok-3",
                                                    "xai.grok-3-fast",
                                                    "xai.grok-4",
                                                    "xai.grok-4-fast-non-reasoning",
                                                    "meta.llama-4-scout-17b-16e-instruct",
                                                ],
                                                value="xai.grok-code-fast-1",
                                                interactive=True,
                                                container=False,
                                            )
                                with gr.Column(scale=5):
                                    with gr.Row():
                                        with gr.Column(scale=1):
                                            am_ai_analyze_btn = gr.Button("AIåˆ†æ", variant="primary")
                            with gr.Row():
                                am_ai_status_md = gr.Markdown(visible=False)
                            with gr.Row():
                                am_ai_result_md = gr.Markdown(visible=False)

                    def _am_refresh_objects():
                        try:
                            yield gr.Markdown(visible=True, value="â³ ãƒ†ãƒ¼ãƒ–ãƒ«ãƒ»ãƒ“ãƒ¥ãƒ¼ä¸€è¦§ã‚’å–å¾—ä¸­..."), gr.CheckboxGroup(visible=False, choices=[]), gr.CheckboxGroup(visible=False, choices=[])
                            df_tab = _get_table_df_cached(pool, force=True)
                            df_view = _get_view_df_cached(pool, force=True)
                            table_names = sorted(set([str(x) for x in (df_tab["Table Name"].tolist() if (not df_tab.empty and "Table Name" in df_tab.columns) else [])]))
                            view_names = sorted(set([str(x) for x in (df_view["View Name"].tolist() if (not df_view.empty and "View Name" in df_view.columns) else [])]))
                            yield gr.Markdown(visible=True, value="âœ… å–å¾—å®Œäº†"), gr.CheckboxGroup(choices=table_names, visible=True), gr.CheckboxGroup(choices=view_names, visible=True)
                        except Exception as e:
                            yield gr.Markdown(visible=True, value=f"âŒ å¤±æ•—: {e}"), gr.CheckboxGroup(choices=[]), gr.CheckboxGroup(choices=[])

                    def _am_fetch_structure(tables_selected, views_selected):
                        tables_selected = tables_selected or []
                        views_selected = views_selected or []
                        targets = []
                        targets.extend([("TABLE", t) for t in tables_selected])
                        targets.extend([("VIEW", v) for v in views_selected])
                        if not targets:
                            return gr.Textbox(value="", interactive=True)
                        struct_chunks = []
                        for kind, name in targets:
                            if kind == "VIEW":
                                cols_df, _ddl = get_view_details(pool, name)
                            else:
                                cols_df, _ddl = get_table_details(pool, name)
                            lines = [f"OBJECT: {name}", "COLUMNS:"]
                            if isinstance(cols_df, pd.DataFrame) and not cols_df.empty:
                                for _, row in cols_df.iterrows():
                                    lines.append(f"- {row['Column Name']}: {row['Data Type']} NULLABLE={row['Nullable']}")
                            struct_chunks.append("\n".join(lines))
                        struct_text = "\n\n".join(struct_chunks)
                        return gr.Textbox(value=struct_text, interactive=True)

                    def _am_fetch_pk(tables_selected, views_selected):
                        tables_selected = tables_selected or []
                        views_selected = views_selected or []
                        targets = []
                        targets.extend([("TABLE", t) for t in tables_selected])
                        targets.extend([("VIEW", v) for v in views_selected])
                        if not targets:
                            return gr.Textbox(value="", interactive=True)
                        from utils.management_util import get_primary_key_info
                        pk_chunks = []
                        for _kind, name in targets:
                            pk_info = get_primary_key_info(pool, name) or ""
                            if pk_info:
                                pk_chunks.append(f"OBJECT: {name}\n{pk_info}")
                        pk_text = "\n\n".join(pk_chunks) if pk_chunks else ""
                        return gr.Textbox(value=pk_text, interactive=True)

                    def _am_fetch_fk(tables_selected, views_selected):
                        tables_selected = tables_selected or []
                        views_selected = views_selected or []
                        targets = []
                        targets.extend([("TABLE", t) for t in tables_selected])
                        targets.extend([("VIEW", v) for v in views_selected])
                        if not targets:
                            return gr.Textbox(value="", interactive=True)
                        from utils.management_util import get_foreign_key_info
                        fk_chunks = []
                        for _kind, name in targets:
                            fk_info = get_foreign_key_info(pool, name) or ""
                            if fk_info:
                                fk_chunks.append(f"OBJECT: {name}\n{fk_info}")
                        fk_text = "\n\n".join(fk_chunks) if fk_chunks else ""
                        return gr.Textbox(value=fk_text, interactive=True)

                    def _am_fetch_samples(tables_selected, views_selected, sample_limit):
                        tables_selected = tables_selected or []
                        views_selected = views_selected or []
                        targets = []
                        targets.extend([("TABLE", t) for t in tables_selected])
                        targets.extend([("VIEW", v) for v in views_selected])
                        if not targets:
                            return gr.Textbox(value="", interactive=True)
                        from utils.management_util import display_table_data
                        lim = int(sample_limit)
                        samples_chunks = []
                        if lim > 0:
                            for _kind, name in targets:
                                df = display_table_data(pool, name, lim)
                                if isinstance(df, pd.DataFrame) and not df.empty:
                                    samples_chunks.append(f"OBJECT: {name}\n" + df.to_csv(index=False))
                        samples_text = "\n\n".join(samples_chunks) if samples_chunks else ""
                        return gr.Textbox(value=samples_text, interactive=True)

                    def _am_build_prompt(struct_text, pk_text, fk_text, samples_text, extra_text):
                        has_samples = bool(str(samples_text or "").strip())
                        prompt = (
                            "ã‚ãªãŸã¯Oracleãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å°‚é–€å®¶ã§ã™ã€‚ä»¥ä¸‹ã®æƒ…å ±ã«åŸºã¥ãã€ALTER TABLE/ALTER VIEW ã® ANNOTATIONS æ–‡ã®ã¿ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚\n"
                            "å‡ºåŠ›ã¯SQLã®ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³æ–‡ã®ã¿ã€‚èª¬æ˜ã‚„ä½™è¨ˆãªæ–‡ã¯å‡ºåŠ›ã—ãªã„ã§ãã ã•ã„ã€‚\n"
                            "ãƒ†ãƒ¼ãƒ–ãƒ«ãƒ»ãƒ“ãƒ¥ãƒ¼ã¯A-Zã®é †ã€åˆ—ã¯å®šç¾©é †ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚\n"
                            "ãƒ“ãƒ¥ãƒ¼ã®åˆ—ãƒ¬ãƒ™ãƒ«ã®ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã¯ç”Ÿæˆã—ãªã„ã§ãã ã•ã„ï¼ˆåˆ—ã¯ãƒ†ãƒ¼ãƒ–ãƒ«åˆ—ã«å¯¾ã—ã¦ã®ã¿ç”Ÿæˆï¼‰ã€‚\n\n"
                            "å‚è€ƒæ§‹æ–‡ã¨ãƒ«ãƒ¼ãƒ«:\n"
                            "- å¯¾è±¡: TABLE / VIEW / MATERIALIZED VIEW / INDEXï¼ˆæœ¬ãƒ„ãƒ¼ãƒ«ã§ã¯ TABLE åˆ—ã¨ VIEW æœ¬ä½“ã‚’å¯¾è±¡ï¼‰\n"
                            "- æ“ä½œ: ADD / DROP / REPLACEï¼ˆCREATE æ™‚ã¯ ADD/ADD IF NOT EXISTS ã®ã¿ï¼‰\n"
                            "- æ³¨é‡ˆå: è‹±æ•°å­—ã¨ $, _, # ã‚’ç„¡å¼•ç”¨ã§è¨±å®¹ã€‚äºˆç´„èªã‚„ç©ºç™½ã‚’å«ã‚€å ´åˆã¯äºŒé‡å¼•ç”¨ç¬¦ã€‚æœ€å¤§1024æ–‡å­—ã€‚\n"
                            "- å€¤: æœ€å¤§4000æ–‡å­—ã€‚å˜ä¸€å¼•ç”¨ç¬¦ã¯ '' ã«ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ã€‚\n"
                            "- è¤‡æ•°æ³¨é‡ˆã¯åŒä¸€æ–‡ã§åˆ—æŒ™å¯èƒ½ã€‚\n"
                            + ("- ã‚µãƒ³ãƒ—ãƒ«ãŒå–å¾—ã§ããŸå ´åˆã®ã¿ 'sample_header' ã¨ 'sample_data' ã‚’ç”Ÿæˆã™ã‚‹ã€‚\n" if has_samples else "- ã‚µãƒ³ãƒ—ãƒ«ãŒç„¡ã„å ´åˆã¯ 'sample_header' ã¨ 'sample_data' ã‚’ç”Ÿæˆã—ãªã„ã€‚\n")
                            + "ä¾‹:\n"
                            + "  ALTER TABLE T1 ANNOTATIONS (Operations '[\"Sort\", \"Group\"]', Hidden);\n"
                            + "  ALTER TABLE T1 MODIFY (ID ANNOTATIONS (UI_Display 'ID', Classification 'Doc Info'));\n"
                            + "  ALTER VIEW SALES_V ANNOTATIONS (UI_Display 'Sales View');\n\n"
                            + "<æ§‹é€ >\n" + str(struct_text or "") + "\n\n"
                            + "<ä¸»ã‚­ãƒ¼>\n" + str(pk_text or "") + "\n\n"
                            + "<å¤–éƒ¨ã‚­ãƒ¼>\n" + str(fk_text or "") + "\n\n"
                            + "<ã‚µãƒ³ãƒ—ãƒ«>\n" + str(samples_text or "") + "\n\n"
                            + (str(extra_text or "") if extra_text else "")
                        )
                        return prompt

                    async def _am_generate_async(model_name, struct_text, pk_text, fk_text, samples_text, extra_text):
                        try:
                            prompt = _am_build_prompt(struct_text, pk_text, fk_text, samples_text, extra_text)
                            from utils.chat_util import get_oci_region, get_compartment_id
                            region = get_oci_region()
                            compartment_id = get_compartment_id()
                            if not region or not compartment_id:
                                logger.error("_am_generate_async missing OCI configuration: region or compartment_id is empty")
                                return gr.Textbox(value="â„¹ï¸ OCIè¨­å®šãŒä¸è¶³ã—ã¦ã„ã¾ã™")
                            
                            if str(model_name).startswith("gpt-"):
                                from openai import AsyncOpenAI
                                client = AsyncOpenAI()
                            else:
                                from oci_openai import AsyncOciOpenAI, OciUserPrincipalAuth
                                client = AsyncOciOpenAI(
                                    service_endpoint=f"https://inference.generativeai.{region}.oci.oraclecloud.com",
                                    auth=OciUserPrincipalAuth(),
                                    compartment_id=compartment_id,
                                )
                            messages = [
                                {
                                    "role": "system",
                                    "content": (
                                        "å‡ºåŠ›ã¯æ¬¡ã®å½¢å¼ã®ã¿: \n"
                                        "- ãƒ†ãƒ¼ãƒ–ãƒ«: ALTER TABLE <è¡¨> ANNOTATIONS (<name> '<value>'[, ...]);\n"
                                        "- åˆ—: ALTER TABLE <è¡¨> MODIFY (<åˆ—> ANNOTATIONS (<name> '<value>'[, ...]));\n"
                                        "- ãƒ“ãƒ¥ãƒ¼: ALTER VIEW <ãƒ“ãƒ¥ãƒ¼> ANNOTATIONS (<name> '<value>'[, ...]);\n"
                                        "åˆ¶ç´„: ãƒ“ãƒ¥ãƒ¼åˆ—ã®ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã¯ç”Ÿæˆã—ãªã„ã€‚'data_type' ã¨ 'nullable' ã‚’å„ªå…ˆçš„ã«ä½¿ç”¨ã€‚'sample_header' ã¨ 'sample_data' ã¯ã‚µãƒ³ãƒ—ãƒ«ãŒå­˜åœ¨ã™ã‚‹å ´åˆã®ã¿ç”Ÿæˆã€‚'type' ã¯ä½¿ç”¨ã—ãªã„ã€‚å€¤å†…ã®å˜ä¸€å¼•ç”¨ç¬¦ã¯ '' ã«ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ã€‚ä½™è¨ˆãªèª¬æ˜ã¯å‡ºåŠ›ã—ãªã„ã€‚\n\n"
                                        "Oracleå…¬å¼ã® annotations_clause ãƒ«ãƒ¼ãƒ«:\n"
                                        "- ADD / DROP / REPLACE ã‚’ã‚µãƒãƒ¼ãƒˆï¼ˆCREATE ã¯ ADD/ADD IF NOT EXISTSï¼‰ã€‚\n"
                                        "- æ³¨é‡ˆåã¯è­˜åˆ¥å­ã€‚äºˆç´„èªã‚„ç©ºç™½ã‚’å«ã‚€å ´åˆã¯äºŒé‡å¼•ç”¨ç¬¦ã€‚\n"
                                        "- å€¤ã¯æœ€å¤§4000æ–‡å­—ã€‚è¤‡æ•°æ³¨é‡ˆã¯åŒä¸€æ–‡ã§åˆ—æŒ™å¯èƒ½ã€‚\n"
                                        "ä¾‹: ALTER TABLE T1 ANNOTATIONS (Operations '[\"Sort\", \"Group\"]', Hidden);\n"
                                        "ä¾‹: ALTER TABLE T1 MODIFY (ID ANNOTATIONS (UI_Display 'ID'));\n"
                                        "ä¾‹: ALTER VIEW V1 ANNOTATIONS (UI_Display 'Sales View');"
                                    ),
                                },
                                {"role": "user", "content": prompt},
                            ]
                            resp = await client.chat.completions.create(model=model_name, messages=messages, temperature=0.0)
                            text = ""
                            if resp.choices and len(resp.choices) > 0:
                                msg = resp.choices[0].message
                                text = msg.content if hasattr(msg, "content") else ""
                            # ã‚µãƒ³ãƒ—ãƒ«ãŒç„¡ã„å ´åˆã¯ã€å‡ºåŠ›ã‹ã‚‰ sample_header / sample_data ã‚’é™¤å»
                            if not str(samples_text or "").strip():
                                try:
                                    s = str(text or "")
                                    def _split_items(inner):
                                        items = []
                                        current = []
                                        in_quote = False
                                        quote = ''
                                        i = 0
                                        n = len(inner)
                                        while i < n:
                                            ch = inner[i]
                                            if in_quote:
                                                current.append(ch)
                                                if ch == quote:
                                                    if quote == "'" and i + 1 < n and inner[i + 1] == "'":
                                                        current.append("'")
                                                        i += 1
                                                    else:
                                                        in_quote = False
                                                        quote = ''
                                            else:
                                                if ch == "'" or ch == '"':
                                                    in_quote = True
                                                    quote = ch
                                                    current.append(ch)
                                                elif ch == ',':
                                                    items.append(''.join(current).strip())
                                                    current = []
                                                else:
                                                    current.append(ch)
                                            i += 1
                                        items.append(''.join(current).strip())
                                        return [it for it in items if it]
                                    def _extract_name(part):
                                        m = re.match(r'^\s*("([^"]+)"|([A-Za-z0-9_\$#]+))', part)
                                        if not m:
                                            return ''
                                        return (m.group(2) or m.group(3) or '').strip()
                                    out_lines = []
                                    for ln in s.splitlines():
                                        up = ln.upper()
                                        if 'ANNOTATIONS' in up:
                                            m = re.search(r'ANNOTATIONS\s*\((.*)\)', ln, flags=re.IGNORECASE)
                                            if m:
                                                inner = m.group(1)
                                                items = _split_items(inner)
                                                kept = []
                                                for it in items:
                                                    nm = _extract_name(it)
                                                    if nm.lower() in ('sample_header', 'sample_data'):
                                                        continue
                                                    kept.append(it)
                                                if kept:
                                                    new_inner = ', '.join(kept)
                                                    new_ln = re.sub(r'(ANNOTATIONS\s*)\((.*)\)', r"\1(" + new_inner + ")", ln, flags=re.IGNORECASE)
                                                    out_lines.append(new_ln)
                                                else:
                                                    continue
                                            else:
                                                out_lines.append(ln)
                                        else:
                                            out_lines.append(ln)
                                    text = "\n".join(out_lines)
                                except Exception:
                                    pass
                            return gr.Textbox(value=text)
                        except Exception as e:
                            logger.error(f"_am_generate_async error: {e}")
                            return gr.Textbox(value=f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")

                    async def _am_ai_analyze_async(model_name, sql_text, exec_result_text):
                        from utils.chat_util import get_oci_region, get_compartment_id
                        region = get_oci_region()
                        compartment_id = get_compartment_id()
                        if not region or not compartment_id:
                            return gr.Markdown(visible=True, value="â„¹ï¸ OCIè¨­å®šãŒä¸è¶³ã—ã¦ã„ã¾ã™")
                        try:
                            s = str(sql_text or "").strip()
                            r = str(exec_result_text or "").strip()
                            prompt = (
                                "ä»¥ä¸‹ã®ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³æ–‡ã®ä¸€æ‹¬å®Ÿè¡Œå†…å®¹ã¨å®Ÿè¡Œçµæœã‚’åˆ†æã—ã¦ãã ã•ã„ã€‚å‡ºåŠ›ã¯æ¬¡ã®3ç‚¹ã«é™å®šã—ã¾ã™ã€‚\n"
                                "1) ã‚¨ãƒ©ãƒ¼åŸå› ï¼ˆè©²å½“ã™ã‚‹å ´åˆï¼‰\n"
                                "2) è§£æ±ºæ–¹æ³•ï¼ˆä¿®æ­£æ¡ˆã‚„å…·ä½“çš„æ‰‹é †ï¼‰\n"
                                "3) ç°¡æ½”ãªçµè«–\n\n"
                                + ("SQL:\n```sql\n" + s + "\n```\n" if s else "")
                                + ("å®Ÿè¡Œçµæœ:\n" + r + "\n" if r else "")
                            )
                            
                            if str(model_name).startswith("gpt-"):
                                from openai import AsyncOpenAI
                                client = AsyncOpenAI()
                            else:
                                from oci_openai import AsyncOciOpenAI, OciUserPrincipalAuth
                                client = AsyncOciOpenAI(
                                    service_endpoint=f"https://inference.generativeai.{region}.oci.oraclecloud.com",
                                    auth=OciUserPrincipalAuth(),
                                    compartment_id=compartment_id,
                                )
                            
                            messages = [
                                {"role": "system", "content": "ã‚ãªãŸã¯ã‚·ãƒ‹ã‚¢DBã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã§ã™ã€‚ALTER ... ANNOTATIONS ã®è¨ºæ–­ã«ç‰¹åŒ–ã—ã€å¿…è¦æœ€å°é™ã®è¦ç‚¹ã®ã¿ã‚’ç°¡æ½”ã«æç¤ºã—ã¦ãã ã•ã„ã€‚"},
                                {"role": "user", "content": prompt},
                            ]
                            resp = await client.chat.completions.create(model=model_name, messages=messages)
                            text = ""
                            if getattr(resp, "choices", None):
                                msg = resp.choices[0].message
                                text = msg.content if hasattr(msg, "content") else ""
                            return gr.Markdown(visible=True, value=text or "åˆ†æçµæœãŒç©ºã§ã™")
                        except Exception as e:
                            return gr.Markdown(visible=True, value=f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")

                    def _am_ai_analyze(model_name, sql_text, exec_result_text):
                        import asyncio
                        # å¿…é ˆå…¥åŠ›é …ç›®ã®ãƒã‚§ãƒƒã‚¯
                        if not model_name or not str(model_name).strip():
                            yield gr.Markdown(visible=True, value="âš ï¸ ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„"), gr.Markdown(visible=False)
                            return
                        if not sql_text or not str(sql_text).strip():
                            yield gr.Markdown(visible=True, value="âš ï¸ SQLæ–‡ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„"), gr.Markdown(visible=False)
                            return
                        if not exec_result_text or not str(exec_result_text).strip():
                            yield gr.Markdown(visible=True, value="âš ï¸ å®Ÿè¡ŒçµæœãŒã‚ã‚Šã¾ã›ã‚“ã€‚å…ˆã«ä¸€æ‹¬å®Ÿè¡Œã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„"), gr.Markdown(visible=False)
                            return
                        
                        loop = asyncio.new_event_loop()
                        asyncio.set_event_loop(loop)
                        try:
                            yield gr.Markdown(visible=True, value="â³ AIåˆ†æã‚’å®Ÿè¡Œä¸­..."), gr.Markdown(visible=False)
                            result_md = loop.run_until_complete(_am_ai_analyze_async(model_name, sql_text, exec_result_text))
                            yield gr.Markdown(visible=True, value="âœ… å®Œäº†"), result_md
                        except Exception as e:
                            yield gr.Markdown(visible=True, value=f"âŒ ã‚¨ãƒ©ãƒ¼: {e}"), gr.Markdown(visible=False)
                        finally:
                            loop.close()

                    def _am_generate(model_name, struct_text, pk_text, fk_text, samples_text, extra_text):
                        loop = asyncio.new_event_loop()
                        asyncio.set_event_loop(loop)
                        try:
                            result = loop.run_until_complete(_am_generate_async(model_name, struct_text, pk_text, fk_text, samples_text, extra_text))
                            return result
                        finally:
                            loop.close()

                    def _am_execute(sql_text):
                        def _prep(s):
                            txt = str(s or "")
                            parts = [p.strip() for p in txt.split(';') if p.strip()]
                            out = []
                            for p in parts:
                                out.append(p)
                            return ";\n".join(out)
                        from utils.management_util import execute_annotation_sql
                        try:
                            return execute_annotation_sql(pool, _prep(sql_text))
                        except Exception as e:
                            logger.error(f"_am_execute error: {e}")
                            return f"âŒ ã‚¨ãƒ©ãƒ¼: {str(e)}"

                    am_refresh_btn.click(
                        fn=_am_refresh_objects,
                        outputs=[am_refresh_status, am_tables_input, am_views_input],
                    )

                    am_fetch_btn.click(
                        fn=_am_fetch_structure,
                        inputs=[am_tables_input, am_views_input],
                        outputs=[am_structure_text],
                    ).then(
                        fn=_am_fetch_pk,
                        inputs=[am_tables_input, am_views_input],
                        outputs=[am_pk_text],
                    ).then(
                        fn=_am_fetch_fk,
                        inputs=[am_tables_input, am_views_input],
                        outputs=[am_fk_text],
                    ).then(
                        fn=_am_fetch_samples,
                        inputs=[am_tables_input, am_views_input, am_sample_limit],
                        outputs=[am_samples_text],
                    )

                    am_generate_btn.click(
                        fn=_am_generate,
                        inputs=[am_model_input, am_structure_text, am_pk_text, am_fk_text, am_samples_text, am_extra_input],
                        outputs=[am_generated_sql],
                    )

                    am_execute_btn.click(
                        fn=_am_execute,
                        inputs=[am_generated_sql],
                        outputs=[am_execute_result],
                    )

                    am_ai_analyze_btn.click(
                        fn=_am_ai_analyze,
                        inputs=[am_ai_model_input, am_generated_sql, am_execute_result],
                        outputs=[am_ai_status_md, am_ai_result_md],
                    )

                with gr.TabItem(label="åˆæˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ") as synthetic_tab:
                    with gr.Accordion(label="1. å¯¾è±¡é¸æŠ", open=True):
                        with gr.Row():
                            with gr.Column(scale=5):
                                with gr.Row():
                                    with gr.Column(scale=1):
                                        gr.Markdown("Profile", elem_classes="input-label")
                                    with gr.Column(scale=5):
                                        # ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«é¸æŠè‚¢ã‚’å–å¾—ã—ã€ç©ºã®å ´åˆã¯ç©ºæ–‡å­—åˆ—ã‚’å«ã‚€ãƒªã‚¹ãƒˆã‚’è¨­å®š
                                        _syn_initial_choices = _load_profiles_from_json()
                                        if not _syn_initial_choices:
                                            _syn_initial_choices = [("", "")]
                                        syn_profile_select = gr.Dropdown(
                                            show_label=False,
                                            choices=_syn_initial_choices,
                                            value=(
                                                _syn_initial_choices[0][1]
                                                if (_syn_initial_choices and isinstance(_syn_initial_choices[0], tuple))
                                                else (_syn_initial_choices[0] if _syn_initial_choices else "")
                                            ),
                                            interactive=True,
                                            container=False
                                        )
                            with gr.Column(scale=5):
                                with gr.Row():
                                    with gr.Column(scale=1):
                                        gr.Markdown("")
                        with gr.Row():
                            with gr.Column():
                                syn_refresh_btn = gr.Button("ãƒ†ãƒ¼ãƒ–ãƒ«ä¸€è¦§ã‚’å–å¾—", variant="primary")
                        with gr.Row():
                            with gr.Column():
                                syn_refresh_status = gr.Markdown(visible=False)
                        with gr.Row():
                            with gr.Column(scale=5):
                                with gr.Row():
                                    with gr.Column(scale=1):
                                        syn_tables_input = gr.CheckboxGroup(label="ãƒ†ãƒ¼ãƒ–ãƒ«é¸æŠ", choices=[], visible=True)
                            with gr.Column(scale=5):
                                with gr.Row():
                                    with gr.Column(scale=1):
                                        gr.Markdown("å„ãƒ†ãƒ¼ãƒ–ãƒ«ã®ç”Ÿæˆä»¶æ•°", elem_classes="input-label")
                                    with gr.Column(scale=5):
                                        syn_rows_per_table = gr.Number(show_label=False, minimum=1, maximum=100, value=1, interactive=True, container=False)
                        with gr.Row():
                            with gr.Column(scale=1):
                                gr.Markdown("ç”Ÿæˆã®æŒ‡ç¤º(ã‚ªãƒ—ã‚·ãƒ§ãƒ³)", elem_classes="input-label")
                            with gr.Column(scale=5):
                                syn_prompt_input = gr.Textbox(show_label=False, placeholder="ã‚¹ã‚­ãƒ¼ãƒç‰¹æ€§ã‚„åˆ†å¸ƒã€åˆ¶ç´„ãªã©ã‚’è‡ªç„¶è¨€èªã§è¨˜è¿°", lines=4, max_lines=10, container=False)
                        with gr.Row():
                            with gr.Column(scale=5):
                                with gr.Row():
                                    with gr.Column(scale=1):
                                        gr.Markdown("ã‚µãƒ³ãƒ—ãƒ«è¡Œæ•°(sample_rows)", elem_classes="input-label")
                                    with gr.Column(scale=5):
                                        syn_sample_rows = gr.Number(show_label=False, minimum=0, maximum=100, value=5, interactive=True, container=False)
                            with gr.Column(scale=5):
                                with gr.Row():
                                    with gr.Column(scale=1):
                                        gr.Markdown("ã‚³ãƒ¡ãƒ³ãƒˆã‚’è€ƒæ…®(comments)", elem_classes="input-label")
                                    with gr.Column(scale=5):
                                        syn_comments = gr.Checkbox(label="", value=True, container=False)

                        with gr.Row():
                            syn_generate_btn = gr.Button("ç”Ÿæˆé–‹å§‹", variant="primary")

                    with gr.Accordion(label="2. é€²æ—ã¨çŠ¶æ…‹", open=True):
                        syn_generate_info = gr.Markdown(visible=True, value="â„¹ï¸ Profileã¨å¯¾è±¡ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’é¸æŠã—ã€ç”Ÿæˆé–‹å§‹ã‚’æŠ¼ä¸‹ã—ã¦ãã ã•ã„")
                        with gr.Row():
                            with gr.Column(scale=5):
                                with gr.Row():
                                    with gr.Column(scale=1):
                                        gr.Markdown("ã‚ªãƒšãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ID", elem_classes="input-label")
                                    with gr.Column(scale=5):
                                        syn_operation_id_text = gr.Textbox(show_label=False, interactive=False, container=False)
                            with gr.Column(scale=5):
                                with gr.Row():
                                    with gr.Column(scale=1):
                                        syn_status_update_btn = gr.Button("ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’æ›´æ–°", variant="primary")
                        with gr.Row():
                            syn_status_df = gr.Dataframe(label="ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹", interactive=False, wrap=True, visible=False, value=pd.DataFrame())
                        with gr.Row():
                            syn_status_style = gr.HTML(visible=False)

                    with gr.Accordion(label="3. çµæœç¢ºèª", open=True):
                        with gr.Row():
                            with gr.Column(scale=5):
                                with gr.Row():
                                    with gr.Column(scale=1):
                                        gr.Markdown("ãƒ†ãƒ¼ãƒ–ãƒ«", elem_classes="input-label")
                                    with gr.Column(scale=5):
                                        syn_result_table_select = gr.Dropdown(show_label=False, choices=[], interactive=True, container=False)
                            with gr.Column(scale=5):
                                with gr.Row():
                                    with gr.Column(scale=1):
                                        gr.Markdown("å–å¾—ä»¶æ•°", elem_classes="input-label")
                                    with gr.Column(scale=5):
                                        syn_result_limit = gr.Number(show_label=False, value=50, minimum=0, maximum=10000, container=False)
                        with gr.Row():
                            syn_result_btn = gr.Button("ãƒ‡ãƒ¼ã‚¿ã‚’è¡¨ç¤º", variant="primary")
                        with gr.Row():
                            syn_result_info = gr.Markdown(visible=True, value="â„¹ï¸ ç”Ÿæˆæ¸ˆã¿ãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’è¡¨ç¤ºã—ã¾ã™")
                        with gr.Row():
                            syn_result_df = gr.Dataframe(label="ãƒ‡ãƒ¼ã‚¿è¡¨ç¤º", interactive=False, wrap=True, visible=False, value=pd.DataFrame(), elem_id="synthetic_data_result_df")
                        with gr.Row():
                            syn_result_style = gr.HTML(visible=False)

                    def _syn_profile_names():
                        try:
                            # JSONãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã‚€
                            return _load_profiles_from_json()
                        except Exception as e:
                            logger.error(f"_syn_profile_names error: {e}")
                        return []

                    def _syn_refresh_objects(profile_name):
                        try:
                            yield gr.Markdown(visible=True, value="â³ ãƒ†ãƒ¼ãƒ–ãƒ«ä¸€è¦§ã‚’å–å¾—ä¸­..."), gr.CheckboxGroup(visible=False, choices=[]), gr.Dropdown(visible=False, choices=[])
                            prof = _resolve_profile_name(pool, str(profile_name or ""))
                            df_tab = _get_table_df_cached(pool, force=True)
                            all_table_names = [str(x) for x in (df_tab["Table Name"].tolist() if (not df_tab.empty and "Table Name" in df_tab.columns) else [])]
                            table_names = sorted(set(all_table_names))
                            try:
                                attrs = _get_profile_attributes(pool, prof) or {}
                                obj_list = attrs.get("object_list") or []
                                prof_tables = sorted(set([str(o.get("name")) for o in obj_list if o and o.get("name")]))
                                if prof_tables:
                                    table_names = [t for t in table_names if t in prof_tables]
                            except Exception as e:
                                logger.error(f"_syn_refresh_objects filter by profile error: {e}")
                            yield gr.Markdown(visible=True, value="âœ… å–å¾—å®Œäº†"), gr.CheckboxGroup(choices=table_names, visible=True), gr.Dropdown(choices=table_names, visible=True)
                        except Exception as e:
                            yield gr.Markdown(visible=True, value=f"âŒ å¤±æ•—: {e}"), gr.CheckboxGroup(choices=[]), gr.Dropdown(choices=[])

                    # def _syn_build_prompt(tables_selected, rows_per_table, extra_text):
                    #     tbls = [str(t) for t in (tables_selected or []) if str(t).strip()]
                    #     rp = int(rows_per_table or 0)
                    #     base = (
                    #         "ä»¥ä¸‹ã®ãƒ†ãƒ¼ãƒ–ãƒ«ã«å¯¾ã—ã¦åˆæˆãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚è¡Œæ•°ã¯å„ãƒ†ãƒ¼ãƒ–ãƒ«ã§æŒ‡å®šå€¤ã«è¿‘ã¥ã‘ã€ã‚¹ã‚­ãƒ¼ãƒã®åˆ¶ç´„ã¨è‡ªç„¶ãªåˆ†å¸ƒã‚’è€ƒæ…®ã—ã¦ãã ã•ã„ã€‚\n"
                    #         + f"å¯¾è±¡ãƒ†ãƒ¼ãƒ–ãƒ«: {', '.join(tbls)}\n"
                    #         + f"è¡Œæ•°ç›®å®‰: {rp} è¡Œ/ãƒ†ãƒ¼ãƒ–ãƒ«\n"
                    #     )
                    #     if str(extra_text or "").strip():
                    #         base += "\nè¿½åŠ æŒ‡ç¤º:\n" + str(extra_text).strip()
                    #     return base

                    def _syn_generate(profile_name, tables_selected, rows_per_table, extra_text, sample_rows, comments):
                        if not profile_name or not str(profile_name).strip():
                            return gr.Markdown(visible=True, value="âš ï¸ Profileã‚’é¸æŠã—ã¦ãã ã•ã„"), gr.Textbox(value=""), gr.Dataframe(visible=False, value=pd.DataFrame()), gr.HTML(visible=False)
                        if not tables_selected:
                            return gr.Markdown(visible=True, value="âš ï¸ ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„"), gr.Textbox(value=""), gr.Dataframe(visible=False, value=pd.DataFrame()), gr.HTML(visible=False)
                        try:
                            prof = _resolve_profile_name(pool, str(profile_name or ""))
                            with pool.acquire() as conn:
                                with conn.cursor() as cursor:
                                    try:
                                        p_base = {
                                            "comments": bool(comments),
                                        }
                                    except Exception:
                                        p_base = {"comments": False}
                                    op_id = None
                                    try:
                                        sel = list(tables_selected or [])
                                        if len(sel) == 1:
                                            obj_name = str(sel[0])
                                            rc = int(rows_per_table or 0)
                                            p_single = dict(p_base)
                                            p_single["sample_rows"] = int(sample_rows or 0)
                                            p_json = json.dumps(p_single, ensure_ascii=False)
                                            cursor.execute(
                                                "BEGIN DBMS_CLOUD_AI.GENERATE_SYNTHETIC_DATA(profile_name => :name, object_name => :obj, owner_name => :owner, record_count => :rc, user_prompt => :up, params => :p); END;",
                                                name=prof,
                                                obj=obj_name,
                                                owner="ADMIN",
                                                rc=rc,
                                                up=str(extra_text or ""),
                                                p=p_json,
                                            )
                                        else:
                                            rc = int(rows_per_table or 0)
                                            sr = int(sample_rows or 0)
                                            obj_list = []
                                            for t in sel:
                                                obj_list.append({"owner": "ADMIN", "name": str(t), "record_count": rc, "sample_rows": sr})
                                            obj_json = json.dumps(obj_list, ensure_ascii=False)
                                            p_json = json.dumps(p_base, ensure_ascii=False)
                                            cursor.execute(
                                                "BEGIN DBMS_CLOUD_AI.GENERATE_SYNTHETIC_DATA(profile_name => :name, object_list => :objlist, params => :p); END;",
                                                name=prof,
                                                objlist=obj_json,
                                                p=p_json,
                                            )
                                        cursor.execute("SELECT max(id) FROM user_load_operations")
                                        rid = cursor.fetchall() or []
                                        if rid and len(rid) > 0:
                                            try:
                                                v0 = rid[0][0]
                                                op_id = str(v0.read() if hasattr(v0, "read") else v0)
                                            except Exception:
                                                try:
                                                    op_id = str(rid[0][0])
                                                except Exception:
                                                    op_id = None
                                    except Exception as e:
                                        op_id = None
                                    info_text = "âœ… åˆæˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆã‚’é–‹å§‹ã—ã¾ã—ãŸ" if op_id else "âš ï¸ åˆæˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆã‚’é–‹å§‹ã—ã¾ã—ãŸ(ã‚ªãƒšãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³IDã®å–å¾—ã«å¤±æ•—)"
                                    return gr.Markdown(visible=True, value=info_text), gr.Textbox(value=str(op_id or "")), gr.Dataframe(visible=False, value=pd.DataFrame()), gr.HTML(visible=False)
                        except Exception as e:
                            return gr.Markdown(visible=True, value=f"âŒ ã‚¨ãƒ©ãƒ¼: {e}"), gr.Textbox(value=""), gr.Dataframe(visible=False, value=pd.DataFrame()), gr.HTML(visible=False)

                    def _syn_update_status(op_id):
                        op = str(op_id or "").strip()
                        if not op:
                            return gr.Markdown(visible=True, value="âš ï¸ ã‚ªãƒšãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³IDã‚’å…¥åŠ›/å–å¾—ã—ã¦ãã ã•ã„"), gr.Dataframe(visible=False, value=pd.DataFrame()), gr.HTML(visible=False)
                        try:
                            with pool.acquire() as conn:
                                with conn.cursor() as cursor:
                                    tab = f"\"SYNTHETIC_DATA${op.upper()}_STATUS\""
                                    sql = f"SELECT * FROM ADMIN.{tab} FETCH FIRST 200 ROWS ONLY"
                                    cursor.execute(sql)
                                    rows = cursor.fetchall() or []
                                    cols = [d[0] for d in cursor.description] if cursor.description else []
                                    df = pd.DataFrame(rows, columns=cols)
                                    keep = [
                                        "ID",
                                        "NAME",
                                        "BYTES",
                                        "ROWS_LOADED",
                                        "STATUS",
                                        "LAST_MODIFIED",
                                    ]
                                    show_cols = [c for c in keep if c in df.columns]
                                    if show_cols:
                                        df = df[show_cols]
                                    df_component = gr.Dataframe(visible=True, value=df, label=f"ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ï¼ˆä»¶æ•°: {len(df)}ï¼‰", elem_id="synthetic_data_status_df")
                                    style_value = ""
                                    if len(cols) > 0:
                                        sample = df.head(5)
                                        widths = []
                                        for col in df.columns:
                                            series = sample[col].astype(str) if not sample.empty else pd.Series([], dtype=str)
                                            row_max = series.map(len).max() if len(series) > 0 else 0
                                            length = max(len(str(col)), row_max)
                                            widths.append(length)
                                        total = sum(widths) if widths else 0
                                        if total > 0:
                                            col_widths = [max(5, int(100 * w / total)) for w in widths]
                                            diff = 100 - sum(col_widths)
                                            if diff != 0 and len(col_widths) > 0:
                                                col_widths[0] = max(5, col_widths[0] + diff)
                                            rules = []
                                            rules.append("#synthetic_data_status_df { width: 100% !important; }")
                                            rules.append("#synthetic_data_status_df .wrap { overflow-x: auto !important; }")
                                            rules.append("#synthetic_data_status_df table { table-layout: fixed !important; width: 100% !important; border-collapse: collapse !important; }")
                                            for idx, pct in enumerate(col_widths, start=1):
                                                rules.append(f"#synthetic_data_status_df table th:nth-child({idx}), #synthetic_data_status_df table td:nth-child({idx}) {{ width: {pct}% !important; overflow: hidden !important; text-overflow: ellipsis !important; }}")
                                            style_value = "<style>" + "\n".join(rules) + "</style>"
                                    return gr.Markdown(visible=True, value="âœ… ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹æ›´æ–°å®Œäº†"), df_component, gr.HTML(visible=bool(style_value), value=style_value)
                        except Exception as e:
                            return gr.Markdown(visible=True, value=f"âŒ ã‚¨ãƒ©ãƒ¼: {e}"), gr.Dataframe(visible=False, value=pd.DataFrame()), gr.HTML(visible=False)

                    def _syn_display_result(table_name, limit_value):
                        try:
                            from utils.management_util import display_table_data
                            df = display_table_data(pool, table_name, int(limit_value))
                            if isinstance(df, pd.DataFrame) and not df.empty:
                                widths = []
                                cols = df.columns.tolist()
                                sample = df.head(5)
                                for col in cols:
                                    series = sample[col].astype(str)
                                    row_max = series.map(len).max() if len(series) > 0 else 0
                                    length = max(len(str(col)), row_max)
                                    widths.append(length)
                                total = sum(widths) if widths else 0
                                style_value = ""
                                if total > 0:
                                    col_widths = [max(5, int(100 * w / total)) for w in widths]
                                    diff = 100 - sum(col_widths)
                                    if diff != 0 and len(col_widths) > 0:
                                        col_widths[0] = max(5, col_widths[0] + diff)
                                    rules = []
                                    rules.append("#synthetic_data_result_df { width: 100% !important; }")
                                    rules.append("#synthetic_data_result_df .wrap { overflow-x: auto !important; }")
                                    rules.append("#synthetic_data_result_df table { table-layout: fixed !important; width: 100% !important; border-collapse: collapse !important; }")
                                    for idx, pct in enumerate(col_widths, start=1):
                                        rules.append(f"#synthetic_data_result_df table th:nth-child({idx}), #synthetic_data_result_df table td:nth-child({idx}) {{ width: {pct}% !important; overflow: hidden !important; text-overflow: ellipsis !important; }}")
                                    style_value = "<style>" + "\n".join(rules) + "</style>"
                                return gr.Markdown(visible=True, value="âœ… è¡¨ç¤ºå®Œäº†"), gr.Dataframe(visible=True, value=df, label=f"ãƒ‡ãƒ¼ã‚¿è¡¨ç¤ºï¼ˆä»¶æ•°: {len(df)}ï¼‰", elem_id="synthetic_data_result_df"), gr.HTML(visible=bool(style_value), value=style_value)
                            else:
                                return gr.Markdown(visible=True, value="âœ… è¡¨ç¤ºå®Œäº†(ãƒ‡ãƒ¼ã‚¿ãªã—)"), gr.Dataframe(visible=False, value=pd.DataFrame(), label="ãƒ‡ãƒ¼ã‚¿è¡¨ç¤ºï¼ˆä»¶æ•°: 0ï¼‰", elem_id="synthetic_data_result_df"), gr.HTML(visible=False, value="")
                        except Exception as e:
                            return gr.Markdown(visible=True, value=f"âŒ ã‚¨ãƒ©ãƒ¼: {e}"), gr.Dataframe(visible=False, value=pd.DataFrame(), label="ãƒ‡ãƒ¼ã‚¿è¡¨ç¤º", elem_id="synthetic_data_result_df"), gr.HTML(visible=False, value="")

                    syn_refresh_btn.click(
                        fn=_syn_refresh_objects,
                        inputs=[syn_profile_select],
                        outputs=[syn_refresh_status, syn_tables_input, syn_result_table_select],
                    )

                    syn_generate_btn.click(
                        fn=_syn_generate,
                        inputs=[syn_profile_select, syn_tables_input, syn_rows_per_table, syn_prompt_input, syn_sample_rows, syn_comments],
                        outputs=[syn_generate_info, syn_operation_id_text, syn_status_df, syn_status_style],
                    )

                    syn_status_update_btn.click(
                        fn=_syn_update_status,
                        inputs=[syn_operation_id_text],
                        outputs=[syn_generate_info, syn_status_df, syn_status_style],
                    )

                    syn_result_btn.click(
                        fn=_syn_display_result,
                        inputs=[syn_result_table_select, syn_result_limit],
                        outputs=[syn_result_info, syn_result_df, syn_result_style],
                    )

                with gr.TabItem(label="SQLâ†’è³ªå• é€†ç”Ÿæˆ") as reverse_tab:
                    with gr.Accordion(label="1. å…¥åŠ›", open=True):
                        with gr.Row():
                            with gr.Column(scale=5):
                                with gr.Row():
                                    with gr.Column(scale=1):
                                        gr.Markdown("Profile", elem_classes="input-label")
                                    with gr.Column(scale=5):
                                        # ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«é¸æŠè‚¢ã‚’å–å¾—ã—ã€ç©ºã®å ´åˆã¯ç©ºæ–‡å­—åˆ—ã‚’å«ã‚€ãƒªã‚¹ãƒˆã‚’è¨­å®š
                                        _rev_initial_choices = _load_profiles_from_json()
                                        if not _rev_initial_choices:
                                            _rev_initial_choices = [("", "")]
                                        rev_profile_select = gr.Dropdown(
                                            show_label=False,
                                            choices=_rev_initial_choices,
                                            value=(
                                                _rev_initial_choices[0][1]
                                                if (_rev_initial_choices and isinstance(_rev_initial_choices[0], tuple))
                                                else (_rev_initial_choices[0] if _rev_initial_choices else "")
                                            ),
                                            interactive=True,
                                            container=False
                                        )
                            with gr.Column(scale=5):
                                with gr.Row():
                                    with gr.Column(scale=1):
                                        gr.Markdown("")
                        with gr.Row():
                            with gr.Column(scale=1):
                                gr.Markdown("å¯¾è±¡SQL", elem_classes="input-label")
                            with gr.Column(scale=5):
                                rev_sql_input = gr.Textbox(show_label=False, lines=8, max_lines=15, show_copy_button=True, container=False)

                    with gr.Accordion(label="2. å‚ç…§ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ", open=True):
                        with gr.Row():
                            with gr.Column(scale=1):
                                gr.Markdown("é€ä¿¡ã™ã‚‹ãƒ¡ã‚¿æƒ…å ±", elem_classes="input-label")
                            with gr.Column(scale=5):
                                rev_context_text = gr.Textbox(show_label=False, lines=15, max_lines=15, interactive=True, show_copy_button=True, autoscroll=False, container=False)

                    with gr.Accordion(label="3. ç”Ÿæˆ", open=True):
                        with gr.Row():
                            with gr.Column(scale=5):
                                with gr.Row():
                                    with gr.Column(scale=1):
                                        gr.Markdown("ãƒ¢ãƒ‡ãƒ«", elem_classes="input-label")
                                    with gr.Column(scale=5):
                                        rev_model_input = gr.Dropdown(
                                            show_label=False,
                                            choices=[
                                                "xai.grok-code-fast-1",
                                                "xai.grok-3",
                                                "xai.grok-3-fast",
                                                "xai.grok-4",
                                                "xai.grok-4-fast-non-reasoning",
                                                "meta.llama-4-scout-17b-16e-instruct",
                                                "gpt-4o",
                                                "gpt-5.1",
                                            ],
                                            value="xai.grok-code-fast-1",
                                            interactive=True,
                                            container=False,
                                        )
                            with gr.Column(scale=5):
                                with gr.Row():
                                    with gr.Column(scale=1):
                                        gr.Markdown("")
                        with gr.Row():
                            with gr.Column(scale=1):
                                gr.Markdown("ç”¨èªé›†ã‚’åˆ©ç”¨", elem_classes="input-label")
                            with gr.Column(scale=5):
                                rev_use_glossary = gr.Checkbox(label="", value=False, container=False)
                        with gr.Row():
                            rev_generate_btn = gr.Button("è‡ªç„¶è¨€èªã‚’ç”Ÿæˆ", variant="primary")
                        with gr.Row():
                            with gr.Column(scale=1):
                                gr.Markdown("æ¨å¥¨è³ªå•(æ—¥æœ¬èª)", elem_classes="input-label")
                            with gr.Column(scale=5):
                                rev_question_output = gr.Textbox(show_label=False, lines=4, max_lines=10, interactive=False, show_copy_button=True, container=False)

                    def _rev_build_context_text(profile_name):
                        try:
                            prof = _resolve_profile_name(pool, str(profile_name or ""))
                            attrs = _get_profile_attributes(pool, prof) or {}
                            obj_list = attrs.get("object_list") or []
                            tables = []
                            views = []
                            try:
                                df_tab = _get_table_df_cached(pool)
                                df_view = _get_view_df_cached(pool)
                                tab_names = set(df_tab["Table Name"].tolist() if (isinstance(df_tab, pd.DataFrame) and "Table Name" in df_tab.columns) else [])
                                view_names = set(df_view["View Name"].tolist() if (isinstance(df_view, pd.DataFrame) and "View Name" in df_view.columns) else [])
                            except Exception:
                                view_names = set()
                            for o in obj_list:
                                name = str((o or {}).get("name") or "")
                                if not name:
                                    continue
                                if name in view_names:
                                    views.append(name)
                                elif name in tab_names:
                                    tables.append(name)
                            chunks = []
                            # CREATE DDL + COMMENT statements (column level)
                            for t in sorted(set(tables)):
                                try:
                                    _, ddl = get_table_details(pool, t)
                                except Exception:
                                    ddl = ""
                                if ddl:
                                    chunks.append(str(ddl).strip())
                            for v in sorted(set(views)):
                                try:
                                    _, ddl = get_view_details(pool, v)
                                except Exception:
                                    ddl = ""
                                if ddl:
                                    chunks.append(str(ddl).strip())
                            return "\n\n".join([c for c in chunks if c]) or ""
                        except Exception as e:
                            logger.error(f"_rev_build_context error: {e}")
                            return f"âŒ ã‚¨ãƒ©ãƒ¼: {e}"

                    def _rev_build_context(profile_name):
                        try:
                            txt = _rev_build_context_text(profile_name)
                            return gr.Textbox(value=txt)
                        except Exception as e:
                            return gr.Textbox(value=f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")

                    async def _rev_generate_async(model_name, context_text, sql_text, use_glossary):
                        """SQLâ†’è³ªå•é€†ç”Ÿæˆå‡¦ç†.
                        
                        Args:
                            model_name: ä½¿ç”¨ã™ã‚‹LLMãƒ¢ãƒ‡ãƒ«
                            context_text: ã‚¹ã‚­ãƒ¼ãƒã‚„DDLã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
                            sql_text: å¯¾è±¡SQL
                            use_glossary: ç”¨èªé›†ã‚’åˆ©ç”¨ã™ã‚‹ã‹
                        
                        Returns:
                            gr.Textbox: ç”Ÿæˆã•ã‚ŒãŸè³ªå•æ–‡
                        """
                        try:
                            from utils.chat_util import get_oci_region, get_compartment_id
                            region = get_oci_region()
                            compartment_id = get_compartment_id()
                            if not region or not compartment_id:
                                return gr.Textbox(value="â„¹ï¸ OCIè¨­å®šãŒä¸è¶³ã—ã¦ã„ã¾ã™")
                            ctx_comp = str(context_text or "")
                            
                            # ã‚³ãƒ¡ãƒ³ãƒˆã‚’é™¤å»
                            s = remove_comments(str(sql_text or "").strip())
                            
                            prompt = (
                                "ä¸ãˆã‚‰ã‚ŒãŸSQLã¨ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®æ–‡è„ˆã‹ã‚‰ã€ãã®SQLãŒç”Ÿæˆã•ã‚Œã‚‹ã‚ˆã†ãªæœ€é©ãªæ—¥æœ¬èªã®è³ªå•ã‚’1ã¤ã ã‘ä½œæˆã—ã¦ãã ã•ã„ã€‚\n"
                                "å‡ºåŠ›ã¯è³ªå•æ–‡ã®ã¿ã€‚æ¥é ­è¾ã‚„èª¬æ˜ã€ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã€Markdownã¯ç¦æ­¢ã€‚\n\n"
                                "å‰æã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ:\n" + str(ctx_comp or "") + "\n\n"
                                "å¯¾è±¡SQL:\n```sql\n" + s + "\n```"
                            )
                            
                            if str(model_name).startswith("gpt-"):
                                from openai import AsyncOpenAI
                                client = AsyncOpenAI()
                            else:
                                from oci_openai import AsyncOciOpenAI, OciUserPrincipalAuth
                                client = AsyncOciOpenAI(
                                    service_endpoint=f"https://inference.generativeai.{region}.oci.oraclecloud.com",
                                    auth=OciUserPrincipalAuth(),
                                    compartment_id=compartment_id,
                                )
                            
                            messages = [
                                {"role": "system", "content": "ã‚ãªãŸã¯BIã‚¢ãƒŠãƒªã‚¹ãƒˆã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒSQLç”Ÿæˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«æŠ•ã’ã‚‹è‡ªç„¶è¨€èªã®è³ªå•æ–‡ã‚’çŸ­ãå…·ä½“çš„ã«ä½œã‚‹ã“ã¨ãŒä»•äº‹ã§ã™ã€‚å‡ºåŠ›ã¯è³ªå•æ–‡ã®ã¿ã€‚"},
                                {"role": "user", "content": prompt},
                            ]
                            resp = await client.chat.completions.create(model=model_name, messages=messages, temperature=0.0)
                            out_text = ""
                            if getattr(resp, "choices", None):
                                msg = resp.choices[0].message
                                out_text = msg.content if hasattr(msg, "content") else ""
                            import re as _re
                            out_text = _re.sub(r"^```.*?\n|\n```$", "", str(out_text or ""), flags=_re.DOTALL).strip()
                            
                            # ç”¨èªé›†ã‚’åˆ©ç”¨ã™ã‚‹å ´åˆã¯é€†å‡¦ç†ã‚’é©ç”¨
                            if use_glossary:
                                terms = _load_terminology()
                                if terms:
                                    # ç”¨èªé›†ã‚’ä½¿ã£ã¦LLMã§æ›¸ãæ›ãˆï¼ˆé€†å‡¦ç†ï¼‰
                                    terms_text = "\n".join([f"- {k}: {v}" for k, v in terms.items()])
                                    glossary_prompt = f"""ã‚ãªãŸã¯ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¯ã‚¨ãƒªã®å°‚é–€å®¶ã§ã™ã€‚ä»¥ä¸‹ã®ç”¨èªé›†ã¯é€šå¸¸ã€ŒAï¼ˆTERMï¼‰â†’Bï¼ˆå®šç¾©ãƒ»æ¨å¥¨è¡¨ç¾ï¼‰ã€ã®æœ€é©åŒ–æŒ‡é‡ã§ã™ã€‚æœ¬ã‚¿ã‚¹ã‚¯ã§ã¯é€†æœ€é©åŒ–ã‚’è¡Œã„ã€å…ƒã®è³ªå•ã«å«ã¾ã‚Œã‚‹Bå´ã®è¡¨ç¾ã‚’Aå´ã®æ­£å¼ç”¨èªï¼ˆTERMï¼‰ã¸æ­£è¦åŒ–ã—ã¦ãã ã•ã„ã€‚

ç”¨èªé›†:
{terms_text}

å…ƒã®è³ªå•:
{out_text}

æŒ‡ç¤º:
1. å®šç¾©ã‚„æ¨å¥¨è¡¨ç¾ã€åˆ¥åã€ç•¥ç§°ãªã©Bå´ã«è©²å½“ã™ã‚‹èªå¥ã¯å¯¾å¿œã™ã‚‹æ­£å¼ç”¨èªï¼ˆA/TERMï¼‰ã«ç½®æ›ã—ã¦ãã ã•ã„ã€‚
2. æ„å›³ãƒ»æ¡ä»¶ãƒ»å¯¾è±¡ã¯ç¶­æŒã—ã€èªå½™ã®ã¿ã‚’æ­£è¦åŒ–ã—ã¦ãã ã•ã„ã€‚
3. æ•°å€¤ãƒ»æ—¥ä»˜ãƒ»ç¯„å›²ãªã©ã®å…·ä½“å€¤ã¯å¤‰æ›´ã—ãªã„ã§ãã ã•ã„ã€‚
4. å‡ºåŠ›ã¯æ­£è¦åŒ–å¾Œã®è³ªå•æ–‡ã®ã¿ã€‚èª¬æ˜ã‚„å‰ç½®ãã¯ä¸è¦ã§ã™ã€‚

æ­£è¦åŒ–å¾Œã®è³ªå•:"""
                                    
                                    messages = [{"role": "user", "content": glossary_prompt}]
                                    glossary_resp = await client.chat.completions.create(model=model_name, messages=messages)
                                    if glossary_resp.choices and len(glossary_resp.choices) > 0:
                                        glossary_result = glossary_resp.choices[0].message.content.strip()
                                        # å…ƒã®è³ªå•ã¨ç”¨èªé›†é©ç”¨å¾Œã®è³ªå•ã‚’\n\nã§é€£çµ
                                        out_text = str(out_text) + "\n\n" + glossary_result
                            
                            return gr.Textbox(value=out_text)
                        except Exception as e:
                            logger.error(f"_rev_generate_async error: {e}")
                            import traceback
                            logger.error(traceback.format_exc())
                            return gr.Textbox(value=f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")

                    def _rev_generate(model_name, context_text, sql_text, use_glossary):
                        """SQLâ†’è³ªå•é€†ç”Ÿæˆã®ãƒ©ãƒƒãƒ‘ãƒ¼é–¢æ•°.
                        
                        Args:
                            model_name: ä½¿ç”¨ã™ã‚‹LLMãƒ¢ãƒ‡ãƒ«
                            context_text: ã‚¹ã‚­ãƒ¼ãƒã‚„DDLã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
                            sql_text: å¯¾è±¡SQL
                            use_glossary: ç”¨èªé›†ã‚’åˆ©ç”¨ã™ã‚‹ã‹
                        
                        Returns:
                            gr.Textbox: ç”Ÿæˆã•ã‚ŒãŸè³ªå•æ–‡
                        """
                        import asyncio
                        loop = asyncio.new_event_loop()
                        asyncio.set_event_loop(loop)
                        try:
                            return loop.run_until_complete(_rev_generate_async(model_name, context_text, sql_text, use_glossary))
                        finally:
                            loop.close()

                    def _on_profile_change_set_context(p):
                        return _rev_build_context(p)

                    rev_profile_select.select(
                        fn=_on_profile_change_set_context,
                        inputs=[rev_profile_select],
                        outputs=[rev_context_text],
                    )

                    rev_generate_btn.click(
                        fn=_rev_generate,
                        inputs=[rev_model_input, rev_context_text, rev_sql_input, rev_use_glossary],
                        outputs=[rev_question_output],
                    )

        with gr.TabItem(label="ãƒ¦ãƒ¼ã‚¶ãƒ¼æ©Ÿèƒ½"):
            with gr.Tabs():
                with gr.TabItem(label="åŸºæœ¬æ©Ÿèƒ½") as user_basic_tab:
                    with gr.Accordion(label="1. ãƒãƒ£ãƒƒãƒˆ", open=True):
                        def _profile_names():
                            try:
                                pairs = _load_profiles_from_json()
                                return [(str(bd), str(pf)) for bd, pf in pairs]
                            except Exception as e:
                                logger.error(f"_profile_names error: {e}")
                            return [("", "")]

                        with gr.Row():
                            with gr.Column(scale=1):
                                gr.Markdown("è‡ªç„¶è¨€èªã®è³ªå•", elem_classes="input-label")
                            with gr.Column(scale=5):
                                prompt_input = gr.Textbox(
                                    show_label=False,
                                    placeholder="ä¾‹: å¤§é˜ªã®é¡§å®¢æ•°ã‚’æ•™ãˆã¦",
                                    lines=3,
                                    max_lines=10,
                                    show_copy_button=True,
                                    container=False,
                                )

                        with gr.Row():
                            with gr.Column(scale=5):
                                user_predict_domain_btn = gr.Button("æ¥­å‹™ãƒ‰ãƒ¡ã‚¤ãƒ³äºˆæ¸¬ â‡’", variant="secondary")
                            with gr.Column(scale=5):
                                with gr.Row():
                                    with gr.Column(scale=1):
                                        # ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«é¸æŠè‚¢ã‚’å–å¾—ã—ã€ç©ºã®å ´åˆã¯ç©ºæ–‡å­—åˆ—ã‚’å«ã‚€ãƒªã‚¹ãƒˆã‚’è¨­å®š
                                        _initial_choices = _profile_names()
                                        if not _initial_choices:
                                            _initial_choices = [("", "")]
                                        profile_select = gr.Dropdown(
                                            show_label=False,
                                            choices=_initial_choices,
                                            value=_initial_choices[0][1] if _initial_choices and isinstance(_initial_choices[0], tuple) else "",
                                            interactive=True,
                                            container=False,
                                        )

                        with gr.Row():
                            with gr.Column(scale=1):
                                gr.Markdown("ã‚¯ã‚¨ãƒªæ›¸ãæ›ãˆã‚’æœ‰åŠ¹åŒ–", elem_classes="input-label")
                            with gr.Column(scale=5):
                                enable_query_rewrite = gr.Checkbox(label="", value=False, container=False)
                        
                        with gr.Row():
                            with gr.Accordion(label="", open=True, visible=False) as query_rewrite_section:
                                with gr.Row():
                                    with gr.Column(scale=5):
                                        with gr.Row():
                                            with gr.Column(scale=1):
                                                gr.Markdown("æ›¸ãæ›ãˆç”¨ãƒ¢ãƒ‡ãƒ«", elem_classes="input-label")
                                            with gr.Column(scale=5):
                                                rewrite_model_select = gr.Dropdown(
                                                    show_label=False,
                                                    choices=[
                                                        "xai.grok-code-fast-1",
                                                        "xai.grok-3",
                                                        "xai.grok-3-fast",
                                                        "xai.grok-4",
                                                        "xai.grok-4-fast-non-reasoning",
                                                        "meta.llama-4-scout-17b-16e-instruct",
                                                    ],
                                                    value="xai.grok-code-fast-1",
                                                    interactive=True,
                                                    container=False,
                                                )
                                    with gr.Column(scale=5):
                                        with gr.Row():
                                            with gr.Column(scale=1):
                                                gr.Markdown("")
                                with gr.Row():
                                    with gr.Column(scale=1):
                                        gr.Markdown("ã‚¹ãƒ†ãƒƒãƒ—1: ç”¨èªé›†ã‚’åˆ©ç”¨", elem_classes="input-label")
                                    with gr.Column(scale=5):
                                        rewrite_use_glossary = gr.Checkbox(label="", value=True, container=False)
                                with gr.Row():
                                    with gr.Column(scale=1):
                                        gr.Markdown("ã‚¹ãƒ†ãƒƒãƒ—2: ã‚¹ã‚­ãƒ¼ãƒæƒ…å ±ã‚’åˆ©ç”¨", elem_classes="input-label")
                                    with gr.Column(scale=5):
                                        rewrite_use_schema = gr.Checkbox(label="", value=False, container=False)
                                with gr.Row():
                                    rewrite_btn = gr.Button("æ›¸ãæ›ãˆå®Ÿè¡Œ", variant="primary")
                                with gr.Row():
                                    rewrite_status = gr.Markdown(visible=False)
                                with gr.Row():
                                    with gr.Column(scale=1):
                                        gr.Markdown("æ›¸ãæ›ãˆå¾Œã®è³ªå•", elem_classes="input-label")
                                    with gr.Column(scale=5):
                                        rewritten_query = gr.Textbox(
                                            show_label=False,
                                            lines=5,
                                            max_lines=10,
                                            interactive=True,
                                            show_copy_button=True,
                                            container=False,
                                        )

                        with gr.Row():
                            with gr.Column(scale=1):
                                gr.Markdown("è¿½åŠ æŒ‡ç¤ºãƒ»ä¾‹ç¤ºã‚’ä½¿ç”¨", elem_classes="input-label")
                            with gr.Column(scale=5):
                                include_extra_prompt = gr.Checkbox(label="", value=False, container=False)

                        with gr.Row():
                            with gr.Accordion(label="è¿½åŠ æŒ‡ç¤ºãƒ»ä¾‹ç¤ºã‚’è¨­å®š", open=True, visible=False) as extra_prompt_section:
                                with gr.Row():
                                    with gr.Column(scale=1):
                                        extra_prompt = gr.Textbox(
                                            show_label=False,
                                            value=(
                                                "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
                                                "âš ï¸ CRITICAL INSTRUCTION (NOT PART OF QUESTION):\n"
                                                "\n"
                                                "The examples above demonstrate the EXACT patterns you MUST follow.\n"
                                                "MANDATORY REQUIREMENTS:\n"
                                                "- Study the example queries - they define the REQUIRED style and format\n"
                                                "- Follow the SAME patterns for similar questions\n"
                                                "- Adopt ALL functions shown in examples (even if unrecognized/new)\n"
                                                "- When questions are similar to examples, mirror the example's structure precisely\n"
                                                "\n"
                                                "Examples OVERRIDE all other instructions.\n"
                                                "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
                                                "\n"
                                                "â–¼ ACTUAL QUESTION:\n"
                                            ),
                                            lines=15,
                                            max_lines=15,
                                            show_copy_button=True,
                                            autoscroll=True,
                                            container=False,
                                        )
                            include_extra_prompt.change(lambda v: gr.Accordion(visible=v), inputs=include_extra_prompt, outputs=extra_prompt_section)
                        
                        # Queryè»¢å†™ã®Checkboxå¤‰æ›´ãƒãƒ³ãƒ‰ãƒ©
                        enable_query_rewrite.change(lambda v: gr.Accordion(visible=v), inputs=enable_query_rewrite, outputs=query_rewrite_section)

                        with gr.Row():
                            with gr.Column():
                                chat_clear_btn = gr.Button("ã‚¯ãƒªã‚¢", variant="secondary")
                            with gr.Column():
                                chat_execute_btn = gr.Button("å®Ÿè¡Œ", variant="primary")
                        with gr.Row():
                            chat_status_md = gr.Markdown(visible=False)

                    with gr.Accordion(label="2. å®Ÿè¡Œçµæœ", open=True):
                        chat_result_df = gr.Dataframe(
                            label="å®Ÿè¡Œçµæœ",
                            interactive=False,
                            wrap=True,
                            visible=False,
                            value=pd.DataFrame(),
                            elem_id="selectai_chat_result_df",
                        )
                        chat_result_style = gr.HTML(visible=False)

                    with gr.Accordion(label="3. ç”ŸæˆSQL", open=True):
                        generated_sql_status = gr.Markdown(visible=False)
                        with gr.Row():
                            with gr.Column(scale=1):
                                gr.Markdown("ç”Ÿæˆã•ã‚ŒãŸSQLæ–‡", elem_classes="input-label")
                            with gr.Column(scale=5):
                                generated_sql_text = gr.Textbox(
                                    show_label=False,
                                    lines=8,
                                    max_lines=15,
                                    interactive=False,
                                    show_copy_button=True,
                                    container=False,
                                )

                build_sql_learning_tab(pool)

            def _user_step_generate(profile, prompt, extra_prompt, include_extra, enable_rewrite, rewritten_query):
                """SQLç”Ÿæˆå‡¦ç†.
                
                Args:
                    profile: Profileå
                    prompt: å…ƒã®è‡ªç„¶è¨€èªã®è³ªå•
                    extra_prompt: è¿½åŠ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
                    include_extra: è¿½åŠ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å«ã‚ã‚‹ã‹
                    enable_rewrite: Queryè»¢å†™ãŒæœ‰åŠ¹ã‹
                    rewritten_query: æ›¸ãæ›ãˆå¾Œã®è³ªå•
                
                Yields:
                    tuple: (status_md, generated_sql_textbox)
                """
                # Queryè»¢å†™ãŒæœ‰åŠ¹ãªå ´åˆã¯è»¢å†™å¾Œã®è³ªå•ã‚’ä½¿ç”¨
                if enable_rewrite and rewritten_query and str(rewritten_query).strip():
                    s = str(rewritten_query).strip()
                else:
                    s = str(prompt or "").strip()
                
                ep = str(extra_prompt or "").strip()
                inc = bool(include_extra)
                final = s if not inc or not ep else (ep + "\n\n" + s)
                
                if not profile or not str(profile).strip():
                    yield gr.Markdown(visible=True, value="âš ï¸ Profileã‚’é¸æŠã—ã¦ãã ã•ã„"), gr.Textbox(value="")
                    return
                if not final:
                    yield gr.Markdown(visible=True, value="âš ï¸ è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„"), gr.Textbox(value="")
                    return
                
                q = final
                if q.endswith(";"):
                    q = q[:-1]
                try:
                    yield gr.Markdown(visible=True, value="â³ SQLç”Ÿæˆä¸­..."), gr.Textbox(value="")
                    with pool.acquire() as conn:
                        with conn.cursor() as cursor:
                            try:
                                prof = _resolve_profile_name(pool, str(profile or ""))
                                cursor.execute("BEGIN DBMS_CLOUD_AI.SET_PROFILE(profile_name => :name); END;", name=prof)
                            except Exception as e:
                                logger.error(f"SET_PROFILE failed: {e}")
                            gen_stmt = "select dbms_cloud_ai.generate(prompt=> :q, profile_name => :name, action=> :a)"
                            showsql_stmt = _build_showsql_stmt(q)
                            show_text = ""
                            show_cells = []
                            try:
                                cursor.execute(gen_stmt, q=showsql_stmt, name=prof, a="showsql")
                                rows = cursor.fetchmany(size=200)
                                if rows:
                                    for r in rows:
                                        for v in r:
                                            try:
                                                s2 = v.read() if hasattr(v, "read") else str(v)
                                            except Exception:
                                                s2 = str(v)
                                            if s2:
                                                show_cells.append(s2)
                                    show_text = "\n".join(show_cells)
                            except Exception as e:
                                logger.error(f"user showsql generate error: {e}")
                                yield gr.Markdown(visible=True, value=f"âŒ ã‚¨ãƒ©ãƒ¼: {e}"), gr.Textbox(value="")
                                show_text = ""
                                return
                            try:
                                cursor.execute(showsql_stmt)
                            except Exception as e:
                                logger.error(f"user showsql execute error: {e}")
                                yield gr.Markdown(visible=True, value=f"âŒ ã‚¨ãƒ©ãƒ¼: {e}"), gr.Textbox(value="")
                                return
                            _ = _get_sql_id_for_text(showsql_stmt)
                            def _extract_sql(text: str) -> str:
                                if not text:
                                    return ""
                                m = re.search(r"```sql\s*([\s\S]*?)```", text, flags=re.IGNORECASE)
                                if m:
                                    s3 = m.group(1).strip()
                                    return s3
                                m2 = re.search(r"SQL\s*:([\s\S]+)$", text, flags=re.IGNORECASE)
                                if m2:
                                    s3 = m2.group(1).strip()
                                    return s3
                                m3 = re.search(r"\b(SELECT|WITH)\b[\s\S]*", text, flags=re.IGNORECASE)
                                if m3:
                                    s3 = m3.group(0).strip()
                                    return s3
                                return ""
                            generated_sql = _extract_sql(show_text)
                            if not generated_sql and show_cells:
                                for cell in show_cells:
                                    c = str(cell)
                                    try:
                                        obj = json.loads(c)
                                        if isinstance(obj, dict):
                                            for k in ["sql", "SQL", "generated_sql", "query", "Query"]:
                                                if k in obj and obj[k]:
                                                    generated_sql = str(obj[k]).strip()
                                                    break
                                        if generated_sql:
                                            break
                                    except Exception as e:
                                        logger.error(f"generated_sql JSON parse error: {e}")
                                    m = re.search(r"\b(SELECT|WITH)\b[\s\S]*", c, flags=re.IGNORECASE)
                                    if m:
                                        generated_sql = m.group(0).strip()
                                        break
                            gen_sql_display = generated_sql
                            yield gr.Markdown(visible=True, value="âœ… SQLç”Ÿæˆå®Œäº†"), gr.Textbox(value=gen_sql_display)
                except Exception as e:
                    yield gr.Markdown(visible=True, value=f"âŒ ã‚¨ãƒ©ãƒ¼: {e}"), gr.Textbox(value="")

            def _user_step_run_sql(profile, sql_text):
                if not profile or not str(profile).strip():
                    yield gr.Markdown(visible=True, value="âš ï¸ Profileã‚’é¸æŠã—ã¦ãã ã•ã„"), gr.Dataframe(visible=False, value=pd.DataFrame(), label="å®Ÿè¡Œçµæœ", elem_id="selectai_chat_result_df"), gr.HTML(visible=False, value="")
                    return
                try:
                    yield gr.Markdown(visible=True, value="â³ å®Ÿè¡Œä¸­..."), gr.Dataframe(visible=False, value=pd.DataFrame(), label="å®Ÿè¡Œçµæœ", elem_id="selectai_chat_result_df"), gr.HTML(visible=False, value="")
                    with pool.acquire() as conn:
                        with conn.cursor() as cursor:
                            exec_rows = []
                            exec_cols = []
                            run_sql = str(sql_text or "").strip()
                            if run_sql and re.match(r"^\s*(select|with)\b", run_sql, flags=re.IGNORECASE):
                                if run_sql.endswith(";"):
                                    run_sql = run_sql[:-1]
                                cursor.execute(run_sql)
                                exec_rows = cursor.fetchmany(size=100)
                                exec_cols = [d[0] for d in cursor.description] if cursor.description else []
                            if exec_rows:
                                cleaned_rows = []
                                for r in exec_rows:
                                    cleaned_rows.append([v.read() if hasattr(v, "read") else v for v in r])
                                df = pd.DataFrame(cleaned_rows, columns=exec_cols)
                                widths = []
                                if len(df) > 0:
                                    sample = df.head(5)
                                    for col in df.columns:
                                        series = sample[col].astype(str)
                                        row_max = series.map(len).max() if len(series) > 0 else 0
                                        length = max(len(str(col)), row_max)
                                        widths.append(length)
                                else:
                                    widths = [len(str(c)) for c in df.columns]
                                total = sum(widths) if widths else 0
                                if total <= 0:
                                    col_widths = None
                                else:
                                    col_widths = [max(5, int(100 * w / total)) for w in widths]
                                    diff = 100 - sum(col_widths)
                                    if diff != 0 and len(col_widths) > 0:
                                        col_widths[0] = max(5, col_widths[0] + diff)
                                df_component = gr.Dataframe(
                                    visible=True,
                                    value=df,
                                    label=f"å®Ÿè¡Œçµæœï¼ˆä»¶æ•°: {len(df)}ï¼‰",
                                    elem_id="selectai_chat_result_df",
                                )
                                style_value = ""
                                if col_widths:
                                    rules = []
                                    rules.append("#selectai_chat_result_df { width: 100% !important; }")
                                    rules.append("#selectai_chat_result_df .wrap { overflow-x: auto !important; }")
                                    rules.append("#selectai_chat_result_df table { table-layout: fixed !important; width: 100% !important; border-collapse: collapse !important; }")
                                    for idx, pct in enumerate(col_widths, start=1):
                                        rules.append(
                                            f"#selectai_chat_result_df table th:nth-child({idx}), #selectai_chat_result_df table td:nth-child({idx}) {{ width: {pct}% !important; overflow: hidden !important; text-overflow: ellipsis !important; }}"
                                        )
                                    style_value = "<style>" + "\n".join(rules) + "</style>"
                                style_component = gr.HTML(visible=bool(style_value), value=style_value)
                                yield gr.Markdown(visible=True, value=f"âœ… {len(df)}ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¾ã—ãŸ"), df_component, style_component
                                return
                            yield gr.Markdown(visible=True, value="â„¹ï¸ ãƒ‡ãƒ¼ã‚¿ã¯è¿”å´ã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ"), gr.Dataframe(visible=False, value=pd.DataFrame(), label="å®Ÿè¡Œçµæœï¼ˆä»¶æ•°: 0ï¼‰", elem_id="selectai_chat_result_df"), gr.HTML(visible=False, value="")
                except Exception as e:
                    yield gr.Markdown(visible=True, value=f"âŒ ã‚¨ãƒ©ãƒ¼: {str(e)}"), gr.Dataframe(visible=False, value=pd.DataFrame(), label="å®Ÿè¡Œçµæœ", elem_id="selectai_chat_result_df"), gr.HTML(visible=False, value="")

            def _on_chat_clear():
                ch = _profile_names() or [("", "")]
                return "", gr.Dropdown(choices=ch, value=ch[0][1]), gr.Textbox(value="")
            
            def _user_rewrite_query(model_name, profile_name, original_query, use_glossary, use_schema):
                """ãƒ¦ãƒ¼ã‚¶ãƒ¼å‘ã‘ã‚¯ã‚¨ãƒªæ›¸ãæ›ãˆå‡¦ç†.
                
                Args:
                    model_name: ä½¿ç”¨ã™ã‚‹LLMãƒ¢ãƒ‡ãƒ«
                    profile_name: Profileå
                    original_query: å…ƒã®è‡ªç„¶è¨€èªã®è³ªå•
                    use_schema: ç¬¬2ã‚¹ãƒ†ãƒƒãƒ—ã‚’å®Ÿè¡Œã™ã‚‹ã‹
                
                Yields:
                    tuple: (status_md, rewritten_text)
                """
                # é–‹ç™ºè€…æ©Ÿèƒ½ã¨åŒã˜ãƒ­ã‚¸ãƒƒã‚¯ã‚’ä½¿ç”¨
                yield from _dev_rewrite_query(model_name, profile_name, original_query, use_glossary, use_schema)

            def _user_predict_domain_and_set_profile(text):
                try:
                    ch = _load_profiles_from_json() or [("", "")]
                    pdomain = _predict_business_domain_label(text)
                    return _map_domain_to_profile(pdomain, ch)
                except Exception:
                    ch = _profile_names() or [("", "")]
                    return gr.Dropdown(choices=ch, value=ch[0][1])

            chat_execute_btn.click(
                fn=_user_step_generate,
                inputs=[profile_select, prompt_input, extra_prompt, include_extra_prompt, enable_query_rewrite, rewritten_query],
                outputs=[chat_status_md, generated_sql_text],
            ).then(
                fn=_user_step_run_sql,
                inputs=[profile_select, generated_sql_text],
                outputs=[chat_status_md, chat_result_df, chat_result_style],
            )

            chat_clear_btn.click(
                fn=_on_chat_clear,
                outputs=[prompt_input, profile_select, generated_sql_text],
            )

            user_predict_domain_btn.click(
                fn=_user_predict_domain_and_set_profile,
                inputs=[prompt_input],
                outputs=[profile_select],
            )
            
            # Queryè»¢å†™ãƒœã‚¿ãƒ³ã®ã‚¤ãƒ™ãƒ³ãƒˆãƒãƒ³ãƒ‰ãƒ©
            rewrite_btn.click(
                fn=_user_rewrite_query,
                inputs=[rewrite_model_select, profile_select, prompt_input, rewrite_use_glossary, rewrite_use_schema],
                outputs=[rewrite_status, rewritten_query],
            )

        # å„ã‚¿ãƒ–é¸æŠæ™‚ã®Profileãƒ‰ãƒ­ãƒƒãƒ—ãƒ€ã‚¦ãƒ³æ›´æ–°ã‚¤ãƒ™ãƒ³ãƒˆãƒãƒ³ãƒ‰ãƒ©ãƒ¼
        def _update_dropdown_from_json(current_value):
            choices = _load_profiles_from_json() or [("", "")]
            if choices and isinstance(choices[0], tuple):
                values = [c[1] for c in choices]
                if current_value in values:
                    return gr.Dropdown(choices=choices, value=current_value)
                return gr.Dropdown(choices=choices, value=values[0])
            if not choices:
                choices = [""]
            if current_value in choices:
                return gr.Dropdown(choices=choices, value=current_value)
            return gr.Dropdown(choices=choices, value=choices[0])

        # ãƒãƒ£ãƒƒãƒˆãƒ»åˆ†æã‚¿ãƒ–
        dev_chat_tab.select(
            fn=_update_dropdown_from_json,
            inputs=[dev_profile_select],
            outputs=[dev_profile_select],
        )

        # ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ç®¡ç†ã‚¿ãƒ–
        feedback_tab.select(
            fn=_update_dropdown_from_json,
            inputs=[global_profile_select],
            outputs=[global_profile_select],
        )

        # åˆæˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆã‚¿ãƒ–
        synthetic_tab.select(
            fn=_update_dropdown_from_json,
            inputs=[syn_profile_select],
            outputs=[syn_profile_select],
        )

        # SQLâ†’è³ªå• é€†ç”Ÿæˆã‚¿ãƒ–
        reverse_tab.select(
            fn=_update_dropdown_from_json,
            inputs=[rev_profile_select],
            outputs=[rev_profile_select],
        )

        # ãƒ¦ãƒ¼ã‚¶ãƒ¼æ©Ÿèƒ½ â†’ åŸºæœ¬æ©Ÿèƒ½ã‚¿ãƒ–
        user_basic_tab.select(
            fn=_update_dropdown_from_json,
            inputs=[profile_select],
            outputs=[profile_select],
        )
